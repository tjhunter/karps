{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "import importlib\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.DEBUG)\n",
    "importlib.reload(logging)\n",
    "logging.basicConfig(format='%(asctime)s %(levelname)s:%(message)s', level=logging.DEBUG, datefmt='%I:%M:%S')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import karps as ks\n",
    "import karps.functions as f\n",
    "from karps.display import show_phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "/my_input@org.spark.DistributedLiteral:double"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = ks.dataframe([1.0, 2.0], name=\"my_input\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s = f.sum(df)\n",
    "c = f.as_double(f.count(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "/divide3!org.spark.LocalStructuredTransform:double"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = s / c\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04:14:15 DEBUG:compute graph: nodes {\n",
      "  locality: DISTRIBUTED\n",
      "  path {\n",
      "    path: \"my_input\"\n",
      "  }\n",
      "  op_name: \"org.spark.DistributedLiteral\"\n",
      "  op_extra {\n",
      "    content: \"\\n\\030R\\026\\n\\t)\\000\\000\\000\\000\\000\\000\\360?\\n\\t)\\000\\000\\000\\000\\000\\000\\000@\\022\\004\\022\\002\\010\\002\"\n",
      "    content_debug: \"cell {  array_value {    values {      double_value: 1.0    }    values {      double_value: 2.0    }  }}cell_type {  array_type {    basic_type: DOUBLE  }}\"\n",
      "  }\n",
      "  infered_type {\n",
      "    basic_type: DOUBLE\n",
      "  }\n",
      "}\n",
      "nodes {\n",
      "  path {\n",
      "    path: \"count1\"\n",
      "  }\n",
      "  op_name: \"org.spark.StructuredReduce\"\n",
      "  op_extra {\n",
      "    content: \"\\n\\013\\n\\t\\n\\005count\\022\\000\"\n",
      "    content_debug: \"agg_op {  op {    function_name: \\\"count\\\"    inputs {    }  }}\"\n",
      "  }\n",
      "  parents {\n",
      "    path: \"my_input\"\n",
      "  }\n",
      "  infered_type {\n",
      "    basic_type: INT\n",
      "  }\n",
      "}\n",
      "nodes {\n",
      "  path {\n",
      "    path: \"cast_double2\"\n",
      "  }\n",
      "  op_name: \"org.spark.LocalStructuredTransform\"\n",
      "  op_extra {\n",
      "    content: \"\\n\\027\\022\\025\\n\\013cast_double\\022\\006\\\"\\000R\\002_0\"\n",
      "    content_debug: \"col_op {  function {    function_name: \\\"cast_double\\\"    inputs {      broadcast {      }      field_name: \\\"_0\\\"    }  }}\"\n",
      "  }\n",
      "  parents {\n",
      "    path: \"count1\"\n",
      "  }\n",
      "  infered_type {\n",
      "    basic_type: DOUBLE\n",
      "  }\n",
      "}\n",
      "nodes {\n",
      "  path {\n",
      "    path: \"sum0\"\n",
      "  }\n",
      "  op_name: \"org.spark.StructuredReduce\"\n",
      "  op_extra {\n",
      "    content: \"\\n\\t\\n\\007\\n\\003sum\\022\\000\"\n",
      "    content_debug: \"agg_op {  op {    function_name: \\\"sum\\\"    inputs {    }  }}\"\n",
      "  }\n",
      "  parents {\n",
      "    path: \"my_input\"\n",
      "  }\n",
      "  infered_type {\n",
      "    basic_type: DOUBLE\n",
      "  }\n",
      "}\n",
      "nodes {\n",
      "  path {\n",
      "    path: \"divide3\"\n",
      "  }\n",
      "  op_name: \"org.spark.LocalStructuredTransform\"\n",
      "  op_extra {\n",
      "    content: \"\\n\\034\\022\\032\\n\\006divide\\022\\006\\\"\\000R\\002_0\\022\\010\\\"\\002\\010\\001R\\002_1\"\n",
      "    content_debug: \"col_op {  function {    function_name: \\\"divide\\\"    inputs {      broadcast {      }      field_name: \\\"_0\\\"    }    inputs {      broadcast {        observable_index: 1      }      field_name: \\\"_1\\\"    }  }}\"\n",
      "  }\n",
      "  parents {\n",
      "    path: \"sum0\"\n",
      "  }\n",
      "  parents {\n",
      "    path: \"cast_double2\"\n",
      "  }\n",
      "  infered_type {\n",
      "    basic_type: DOUBLE\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "s = ks.session(\"test3\", address=\"ec2-52-35-61-191.us-west-2.compute.amazonaws.com\", port=6006)\n",
    "comp = s.compute(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04:14:15 WARNING:Could not find compiler step initial. Available steps are [] and []\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe seamless style=\"width:1000px;height:620px;border:0\" srcdoc=\"\n",
       "        <script src=&quot;//cdnjs.cloudflare.com/ajax/libs/polymer/0.3.3/platform.js&quot;></script>\n",
       "        <script>\n",
       "          function load() {\n",
       "            document.getElementById(&quot;graph0.6878306373039764&quot;).pbtxt = 'None';\n",
       "          }\n",
       "        </script>\n",
       "        <link rel=&quot;import&quot; href=&quot;https://tensorboard.appspot.com/tf-graph-basic.build.html&quot; onload=load()>\n",
       "        <div style=&quot;height:600px&quot;>\n",
       "          <tf-graph-basic id=&quot;graph0.6878306373039764&quot;></tf-graph-basic>\n",
       "        </div>\n",
       "    \"></iframe>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_phase(comp, \"initial\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04:14:15 WARNING:Could not find compiler step REMOVE_OBSERVABLE_BROADCASTS. Available steps are [] and []\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe seamless style=\"width:1000px;height:620px;border:0\" srcdoc=\"\n",
       "        <script src=&quot;//cdnjs.cloudflare.com/ajax/libs/polymer/0.3.3/platform.js&quot;></script>\n",
       "        <script>\n",
       "          function load() {\n",
       "            document.getElementById(&quot;graph0.3795969056532923&quot;).pbtxt = 'None';\n",
       "          }\n",
       "        </script>\n",
       "        <link rel=&quot;import&quot; href=&quot;https://tensorboard.appspot.com/tf-graph-basic.build.html&quot; onload=load()>\n",
       "        <div style=&quot;height:600px&quot;>\n",
       "          <tf-graph-basic id=&quot;graph0.3795969056532923&quot;></tf-graph-basic>\n",
       "        </div>\n",
       "    \"></iframe>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_phase(comp, \"REMOVE_OBSERVABLE_BROADCASTS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04:14:15 WARNING:Could not find compiler step MERGE_AGGREGATIONS. Available steps are [] and []\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe seamless style=\"width:1000px;height:620px;border:0\" srcdoc=\"\n",
       "        <script src=&quot;//cdnjs.cloudflare.com/ajax/libs/polymer/0.3.3/platform.js&quot;></script>\n",
       "        <script>\n",
       "          function load() {\n",
       "            document.getElementById(&quot;graph0.9421262425568468&quot;).pbtxt = 'None';\n",
       "          }\n",
       "        </script>\n",
       "        <link rel=&quot;import&quot; href=&quot;https://tensorboard.appspot.com/tf-graph-basic.build.html&quot; onload=load()>\n",
       "        <div style=&quot;height:600px&quot;>\n",
       "          <tf-graph-basic id=&quot;graph0.9421262425568468&quot;></tf-graph-basic>\n",
       "        </div>\n",
       "    \"></iframe>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_phase(comp, \"MERGE_AGGREGATIONS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe seamless style=\"width:1000px;height:620px;border:0\" srcdoc=\"\n",
       "        <script src=&quot;//cdnjs.cloudflare.com/ajax/libs/polymer/0.3.3/platform.js&quot;></script>\n",
       "        <script>\n",
       "          function load() {\n",
       "            document.getElementById(&quot;graph0.5758467266718279&quot;).pbtxt = 'node {\\n  name: &quot;my_input&quot;\\n  op: &quot;org.spark.DistributedLiteral&quot;\\n  device: &quot;/spark:0&quot;\\n  attr {\\n    key: &quot;locality&quot;\\n    value {\\n      s: &quot;Distributed&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;type&quot;\\n    value {\\n      s: &quot;double&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;zextra&quot;\\n    value {\\n      s: &quot;cell {  array_value {    values { double_value: 1.0 } values { double_value: 2.0 }  }}cell_type { array_type { basic_type: DOUBLE } }&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;my_input_karps_merged_agg&quot;\\n  op: &quot;org.spark.StructuredReduce&quot;\\n  input: &quot;my_input&quot;\\n  device: &quot;/spark:0&quot;\\n  attr {\\n    key: &quot;locality&quot;\\n    value {\\n      s: &quot;Local&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;type&quot;\\n    value {\\n      s: &quot;{_1:int _2:double}&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;zextra&quot;\\n    value {\\n      s: &quot;agg_op {  struct {    fields {      op {        function_name: .count. inputs { } expected_type { basic_type: INT }      }      field_name: ._1.    }    fields {      op {        function_name: .sum.        inputs { }        expected_type { basic_type: DOUBLE }      }      field_name: ._2.    }  }}&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;count1&quot;\\n  op: &quot;org.spark.LocalStructuredTransform&quot;\\n  input: &quot;my_input_karps_merged_agg&quot;\\n  device: &quot;/spark:0&quot;\\n  attr {\\n    key: &quot;locality&quot;\\n    value {\\n      s: &quot;Local&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;type&quot;\\n    value {\\n      s: &quot;int&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;zextra&quot;\\n    value {\\n      s: &quot;col_op { extraction { path: ._1. } }&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;cast_double2&quot;\\n  op: &quot;org.spark.LocalStructuredTransform&quot;\\n  input: &quot;count1&quot;\\n  device: &quot;/spark:0&quot;\\n  attr {\\n    key: &quot;locality&quot;\\n    value {\\n      s: &quot;Local&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;type&quot;\\n    value {\\n      s: &quot;double&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;zextra&quot;\\n    value {\\n      s: &quot;col_op {  function {    function_name: .cast_double.    inputs { extraction { } }    expected_type { basic_type: DOUBLE }  }}&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;sum0&quot;\\n  op: &quot;org.spark.LocalStructuredTransform&quot;\\n  input: &quot;my_input_karps_merged_agg&quot;\\n  device: &quot;/spark:0&quot;\\n  attr {\\n    key: &quot;locality&quot;\\n    value {\\n      s: &quot;Local&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;type&quot;\\n    value {\\n      s: &quot;double&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;zextra&quot;\\n    value {\\n      s: &quot;col_op { extraction { path: ._2. } }&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;divide3_karps_localpack&quot;\\n  op: &quot;org.spark.LocalPack&quot;\\n  input: &quot;sum0&quot;\\n  input: &quot;cast_double2&quot;\\n  device: &quot;/spark:0&quot;\\n  attr {\\n    key: &quot;locality&quot;\\n    value {\\n      s: &quot;Local&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;type&quot;\\n    value {\\n      s: &quot;{_1:double _2:double}&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;zextra&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;divide3&quot;\\n  op: &quot;org.spark.LocalStructuredTransform&quot;\\n  input: &quot;divide3_karps_localpack&quot;\\n  device: &quot;/spark:0&quot;\\n  attr {\\n    key: &quot;locality&quot;\\n    value {\\n      s: &quot;Local&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;type&quot;\\n    value {\\n      s: &quot;double&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;zextra&quot;\\n    value {\\n      s: &quot;col_op {  function {    function_name: .divide.    inputs { extraction { path: ._1. } }    inputs { extraction { path: ._2. } }    expected_type { basic_type: DOUBLE }  }}&quot;\\n    }\\n  }\\n}\\n';\n",
       "          }\n",
       "        </script>\n",
       "        <link rel=&quot;import&quot; href=&quot;https://tensorboard.appspot.com/tf-graph-basic.build.html&quot; onload=load()>\n",
       "        <div style=&quot;height:600px&quot;>\n",
       "          <tf-graph-basic id=&quot;graph0.5758467266718279&quot;></tf-graph-basic>\n",
       "        </div>\n",
       "    \"></iframe>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_phase(comp, \"final\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04:14:15 DEBUG:Calling _progress\n",
      "04:14:16 DEBUG:channel: got value <class 'karps.proto.interface_pb2.ComputationStreamResponse'>: session {\n",
      "  id: \"test3\"\n",
      "}\n",
      "computation {\n",
      "  id: \"1\"\n",
      "}\n",
      "start_graph {\n",
      "  nodes {\n",
      "    locality: DISTRIBUTED\n",
      "    path {\n",
      "      path: \"my_input\"\n",
      "    }\n",
      "    op_name: \"org.spark.DistributedLiteral\"\n",
      "    op_extra {\n",
      "      content: \"\\n\\030R\\026\\n\\t)\\000\\000\\000\\000\\000\\000\\360?\\n\\t)\\000\\000\\000\\000\\000\\000\\000@\\022\\004\\022\\002\\010\\002\"\n",
      "      content_debug: \"cell {  array_value {    values {      double_value: 1.0    }    values {      double_value: 2.0    }  }}cell_type {  array_type {    basic_type: DOUBLE  }}\"\n",
      "    }\n",
      "    infered_type {\n",
      "      basic_type: DOUBLE\n",
      "    }\n",
      "  }\n",
      "  nodes {\n",
      "    path {\n",
      "      path: \"count1\"\n",
      "    }\n",
      "    op_name: \"org.spark.StructuredReduce\"\n",
      "    op_extra {\n",
      "      content: \"\\n\\013\\n\\t\\n\\005count\\022\\000\"\n",
      "      content_debug: \"agg_op {  op {    function_name: \\\"count\\\"    inputs {    }  }}\"\n",
      "    }\n",
      "    parents {\n",
      "      path: \"my_input\"\n",
      "    }\n",
      "    infered_type {\n",
      "      basic_type: INT\n",
      "    }\n",
      "  }\n",
      "  nodes {\n",
      "    path {\n",
      "      path: \"cast_double2\"\n",
      "    }\n",
      "    op_name: \"org.spark.LocalStructuredTransform\"\n",
      "    op_extra {\n",
      "      content: \"\\n\\027\\022\\025\\n\\013cast_double\\022\\006\\\"\\000R\\002_0\"\n",
      "      content_debug: \"col_op {  function {    function_name: \\\"cast_double\\\"    inputs {      broadcast {      }      field_name: \\\"_0\\\"    }  }}\"\n",
      "    }\n",
      "    parents {\n",
      "      path: \"count1\"\n",
      "    }\n",
      "    infered_type {\n",
      "      basic_type: DOUBLE\n",
      "    }\n",
      "  }\n",
      "  nodes {\n",
      "    path {\n",
      "      path: \"sum0\"\n",
      "    }\n",
      "    op_name: \"org.spark.StructuredReduce\"\n",
      "    op_extra {\n",
      "      content: \"\\n\\t\\n\\007\\n\\003sum\\022\\000\"\n",
      "      content_debug: \"agg_op {  op {    function_name: \\\"sum\\\"    inputs {    }  }}\"\n",
      "    }\n",
      "    parents {\n",
      "      path: \"my_input\"\n",
      "    }\n",
      "    infered_type {\n",
      "      basic_type: DOUBLE\n",
      "    }\n",
      "  }\n",
      "  nodes {\n",
      "    path {\n",
      "      path: \"divide3\"\n",
      "    }\n",
      "    op_name: \"org.spark.LocalStructuredTransform\"\n",
      "    op_extra {\n",
      "      content: \"\\n\\034\\022\\032\\n\\006divide\\022\\006\\\"\\000R\\002_0\\022\\010\\\"\\002\\010\\001R\\002_1\"\n",
      "      content_debug: \"col_op {  function {    function_name: \\\"divide\\\"    inputs {      broadcast {      }      field_name: \\\"_0\\\"    }    inputs {      broadcast {        observable_index: 1      }      field_name: \\\"_1\\\"    }  }}\"\n",
      "    }\n",
      "    parents {\n",
      "      path: \"sum0\"\n",
      "    }\n",
      "    parents {\n",
      "      path: \"cast_double2\"\n",
      "    }\n",
      "    infered_type {\n",
      "      basic_type: DOUBLE\n",
      "    }\n",
      "  }\n",
      "}\n",
      "pinned_graph {\n",
      "  nodes {\n",
      "    locality: DISTRIBUTED\n",
      "    path {\n",
      "      path: \"my_input\"\n",
      "    }\n",
      "    op_name: \"org.spark.DistributedLiteral\"\n",
      "    op_extra {\n",
      "      content: \"\\n\\030R\\026\\n\\t)\\000\\000\\000\\000\\000\\000\\360?\\n\\t)\\000\\000\\000\\000\\000\\000\\000@\\022\\004\\022\\002\\010\\002\"\n",
      "      content_debug: \"cell {\\n  array_value {\\n    values { double_value: 1.0 } values { double_value: 2.0 }\\n  }\\n}\\ncell_type { array_type { basic_type: DOUBLE } }\"\n",
      "      content_base64: \"ChhSFgoJKQAAAAAAAPA/CgkpAAAAAAAAAEASBBICCAI=\"\n",
      "    }\n",
      "    infered_type {\n",
      "      basic_type: DOUBLE\n",
      "    }\n",
      "  }\n",
      "  nodes {\n",
      "    path {\n",
      "      path: \"my_input_karps_merged_agg\"\n",
      "    }\n",
      "    op_name: \"org.spark.StructuredReduce\"\n",
      "    op_extra {\n",
      "      content: \"\\n*\\022(\\n\\023\\n\\r\\n\\005count\\022\\000\\032\\002\\010\\001\\032\\002_1\\n\\021\\n\\013\\n\\003sum\\022\\000\\032\\002\\010\\002\\032\\002_2\"\n",
      "      content_debug: \"agg_op {\\n  struct {\\n    fields {\\n      op {\\n        function_name: \\\"count\\\" inputs { } expected_type { basic_type: INT }\\n      }\\n      field_name: \\\"_1\\\"\\n    }\\n    fields {\\n      op {\\n        function_name: \\\"sum\\\"\\n        inputs { }\\n        expected_type { basic_type: DOUBLE }\\n      }\\n      field_name: \\\"_2\\\"\\n    }\\n  }\\n}\"\n",
      "      content_base64: \"CioSKAoTCg0KBWNvdW50EgAaAggBGgJfMQoRCgsKA3N1bRIAGgIIAhoCXzI=\"\n",
      "    }\n",
      "    parents {\n",
      "      path: \"my_input\"\n",
      "    }\n",
      "    infered_type {\n",
      "      struct_type {\n",
      "        fields {\n",
      "          field_name: \"_1\"\n",
      "          field_type {\n",
      "            basic_type: INT\n",
      "          }\n",
      "        }\n",
      "        fields {\n",
      "          field_name: \"_2\"\n",
      "          field_type {\n",
      "            basic_type: DOUBLE\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  nodes {\n",
      "    path {\n",
      "      path: \"count1\"\n",
      "    }\n",
      "    op_name: \"org.spark.LocalStructuredTransform\"\n",
      "    op_extra {\n",
      "      content: \"\\n\\006\\032\\004\\n\\002_1\"\n",
      "      content_debug: \"col_op { extraction { path: \\\"_1\\\" } }\"\n",
      "      content_base64: \"CgYaBAoCXzE=\"\n",
      "    }\n",
      "    parents {\n",
      "      path: \"my_input_karps_merged_agg\"\n",
      "    }\n",
      "    infered_type {\n",
      "      basic_type: INT\n",
      "    }\n",
      "  }\n",
      "  nodes {\n",
      "    path {\n",
      "      path: \"cast_double2\"\n",
      "    }\n",
      "    op_name: \"org.spark.LocalStructuredTransform\"\n",
      "    op_extra {\n",
      "      content: \"\\n\\027\\022\\025\\n\\013cast_double\\022\\002\\032\\000\\032\\002\\010\\002\"\n",
      "      content_debug: \"col_op {\\n  function {\\n    function_name: \\\"cast_double\\\"\\n    inputs { extraction { } }\\n    expected_type { basic_type: DOUBLE }\\n  }\\n}\"\n",
      "      content_base64: \"ChcSFQoLY2FzdF9kb3VibGUSAhoAGgIIAg==\"\n",
      "    }\n",
      "    parents {\n",
      "      path: \"count1\"\n",
      "    }\n",
      "    infered_type {\n",
      "      basic_type: DOUBLE\n",
      "    }\n",
      "  }\n",
      "  nodes {\n",
      "    path {\n",
      "      path: \"sum0\"\n",
      "    }\n",
      "    op_name: \"org.spark.LocalStructuredTransform\"\n",
      "    op_extra {\n",
      "      content: \"\\n\\006\\032\\004\\n\\002_2\"\n",
      "      content_debug: \"col_op { extraction { path: \\\"_2\\\" } }\"\n",
      "      content_base64: \"CgYaBAoCXzI=\"\n",
      "    }\n",
      "    parents {\n",
      "      path: \"my_input_karps_merged_agg\"\n",
      "    }\n",
      "    infered_type {\n",
      "      basic_type: DOUBLE\n",
      "    }\n",
      "  }\n",
      "  nodes {\n",
      "    path {\n",
      "      path: \"divide3_karps_localpack\"\n",
      "    }\n",
      "    op_name: \"org.spark.LocalPack\"\n",
      "    op_extra {\n",
      "    }\n",
      "    parents {\n",
      "      path: \"sum0\"\n",
      "    }\n",
      "    parents {\n",
      "      path: \"cast_double2\"\n",
      "    }\n",
      "    infered_type {\n",
      "      struct_type {\n",
      "        fields {\n",
      "          field_name: \"_1\"\n",
      "          field_type {\n",
      "            basic_type: DOUBLE\n",
      "          }\n",
      "        }\n",
      "        fields {\n",
      "          field_name: \"_2\"\n",
      "          field_type {\n",
      "            basic_type: DOUBLE\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  nodes {\n",
      "    path {\n",
      "      path: \"divide3\"\n",
      "    }\n",
      "    op_name: \"org.spark.LocalStructuredTransform\"\n",
      "    op_extra {\n",
      "      content: \"\\n\\036\\022\\034\\n\\006divide\\022\\006\\032\\004\\n\\002_1\\022\\006\\032\\004\\n\\002_2\\032\\002\\010\\002\"\n",
      "      content_debug: \"col_op {\\n  function {\\n    function_name: \\\"divide\\\"\\n    inputs { extraction { path: \\\"_1\\\" } }\\n    inputs { extraction { path: \\\"_2\\\" } }\\n    expected_type { basic_type: DOUBLE }\\n  }\\n}\"\n",
      "      content_base64: \"Ch4SHAoGZGl2aWRlEgYaBAoCXzESBhoECgJfMhoCCAI=\"\n",
      "    }\n",
      "    parents {\n",
      "      path: \"divide3_karps_localpack\"\n",
      "    }\n",
      "    infered_type {\n",
      "      basic_type: DOUBLE\n",
      "    }\n",
      "  }\n",
      "}\n",
      "compilation_result {\n",
      "  compilation_graph {\n",
      "    phase_name: \"INITIAL\"\n",
      "    graph {\n",
      "      nodes {\n",
      "        locality: DISTRIBUTED\n",
      "        path {\n",
      "          path: \"my_input\"\n",
      "        }\n",
      "        op_name: \"org.spark.DistributedLiteral\"\n",
      "        op_extra {\n",
      "          content: \"\\n\\030R\\026\\n\\t)\\000\\000\\000\\000\\000\\000\\360?\\n\\t)\\000\\000\\000\\000\\000\\000\\000@\\022\\004\\022\\002\\010\\002\"\n",
      "          content_debug: \"cell {\\n  array_value {\\n    values { double_value: 1.0 } values { double_value: 2.0 }\\n  }\\n}\\ncell_type { array_type { basic_type: DOUBLE } }\"\n",
      "          content_base64: \"ChhSFgoJKQAAAAAAAPA/CgkpAAAAAAAAAEASBBICCAI=\"\n",
      "        }\n",
      "        infered_type {\n",
      "          basic_type: DOUBLE\n",
      "        }\n",
      "      }\n",
      "      nodes {\n",
      "        path {\n",
      "          path: \"count1\"\n",
      "        }\n",
      "        op_name: \"org.spark.StructuredReduce\"\n",
      "        op_extra {\n",
      "          content: \"\\n\\017\\n\\r\\n\\005count\\022\\000\\032\\002\\010\\001\"\n",
      "          content_debug: \"agg_op {\\n  op {\\n    function_name: \\\"count\\\" inputs { } expected_type { basic_type: INT }\\n  }\\n}\"\n",
      "          content_base64: \"Cg8KDQoFY291bnQSABoCCAE=\"\n",
      "        }\n",
      "        parents {\n",
      "          path: \"my_input\"\n",
      "        }\n",
      "        infered_type {\n",
      "          basic_type: INT\n",
      "        }\n",
      "      }\n",
      "      nodes {\n",
      "        path {\n",
      "          path: \"cast_double2\"\n",
      "        }\n",
      "        op_name: \"org.spark.LocalStructuredTransform\"\n",
      "        op_extra {\n",
      "          content: \"\\n\\027\\022\\025\\n\\013cast_double\\022\\002\\\"\\000\\032\\002\\010\\002\"\n",
      "          content_debug: \"col_op {\\n  function {\\n    function_name: \\\"cast_double\\\"\\n    inputs { broadcast { } }\\n    expected_type { basic_type: DOUBLE }\\n  }\\n}\"\n",
      "          content_base64: \"ChcSFQoLY2FzdF9kb3VibGUSAiIAGgIIAg==\"\n",
      "        }\n",
      "        parents {\n",
      "          path: \"count1\"\n",
      "        }\n",
      "        infered_type {\n",
      "          basic_type: DOUBLE\n",
      "        }\n",
      "      }\n",
      "      nodes {\n",
      "        path {\n",
      "          path: \"sum0\"\n",
      "        }\n",
      "        op_name: \"org.spark.StructuredReduce\"\n",
      "        op_extra {\n",
      "          content: \"\\n\\r\\n\\013\\n\\003sum\\022\\000\\032\\002\\010\\002\"\n",
      "          content_debug: \"agg_op {\\n  op {\\n    function_name: \\\"sum\\\"\\n    inputs { }\\n    expected_type { basic_type: DOUBLE }\\n  }\\n}\"\n",
      "          content_base64: \"Cg0KCwoDc3VtEgAaAggC\"\n",
      "        }\n",
      "        parents {\n",
      "          path: \"my_input\"\n",
      "        }\n",
      "        infered_type {\n",
      "          basic_type: DOUBLE\n",
      "        }\n",
      "      }\n",
      "      nodes {\n",
      "        path {\n",
      "          path: \"divide3\"\n",
      "        }\n",
      "        op_name: \"org.spark.LocalStructuredTransform\"\n",
      "        op_extra {\n",
      "          content: \"\\n\\030\\022\\026\\n\\006divide\\022\\002\\\"\\000\\022\\004\\\"\\002\\010\\001\\032\\002\\010\\002\"\n",
      "          content_debug: \"col_op {\\n  function {\\n    function_name: \\\"divide\\\"\\n    inputs { broadcast { } }\\n    inputs { broadcast { observable_index: 1 } }\\n    expected_type { basic_type: DOUBLE }\\n  }\\n}\"\n",
      "          content_base64: \"ChgSFgoGZGl2aWRlEgIiABIEIgIIARoCCAI=\"\n",
      "        }\n",
      "        parents {\n",
      "          path: \"sum0\"\n",
      "        }\n",
      "        parents {\n",
      "          path: \"cast_double2\"\n",
      "        }\n",
      "        infered_type {\n",
      "          basic_type: DOUBLE\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    graph_def {\n",
      "      node {\n",
      "        name: \"my_input\"\n",
      "        op: \"org.spark.DistributedLiteral\"\n",
      "        device: \"/spark:0\"\n",
      "        attr {\n",
      "          key: \"locality\"\n",
      "          value {\n",
      "            s: \"Distributed\"\n",
      "          }\n",
      "        }\n",
      "        attr {\n",
      "          key: \"type\"\n",
      "          value {\n",
      "            s: \"double\"\n",
      "          }\n",
      "        }\n",
      "        attr {\n",
      "          key: \"zextra\"\n",
      "          value {\n",
      "            s: \"cell {  array_value {    values { double_value: 1.0 } values { double_value: 2.0 }  }}cell_type { array_type { basic_type: DOUBLE } }\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      node {\n",
      "        name: \"count1\"\n",
      "        op: \"org.spark.StructuredReduce\"\n",
      "        input: \"my_input\"\n",
      "        device: \"/spark:0\"\n",
      "        attr {\n",
      "          key: \"locality\"\n",
      "          value {\n",
      "            s: \"Local\"\n",
      "          }\n",
      "        }\n",
      "        attr {\n",
      "          key: \"type\"\n",
      "          value {\n",
      "            s: \"int\"\n",
      "          }\n",
      "        }\n",
      "        attr {\n",
      "          key: \"zextra\"\n",
      "          value {\n",
      "            s: \"agg_op {  op {    function_name: .count. inputs { } expected_type { basic_type: INT }  }}\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      node {\n",
      "        name: \"cast_double2\"\n",
      "        op: \"org.spark.LocalStructuredTransform\"\n",
      "        input: \"count1\"\n",
      "        device: \"/spark:0\"\n",
      "        attr {\n",
      "          key: \"locality\"\n",
      "          value {\n",
      "            s: \"Local\"\n",
      "          }\n",
      "        }\n",
      "        attr {\n",
      "          key: \"type\"\n",
      "          value {\n",
      "            s: \"double\"\n",
      "          }\n",
      "        }\n",
      "        attr {\n",
      "          key: \"zextra\"\n",
      "          value {\n",
      "            s: \"col_op {  function {    function_name: .cast_double.    inputs { broadcast { } }    expected_type { basic_type: DOUBLE }  }}\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      node {\n",
      "        name: \"sum0\"\n",
      "        op: \"org.spark.StructuredReduce\"\n",
      "        input: \"my_input\"\n",
      "        device: \"/spark:0\"\n",
      "        attr {\n",
      "          key: \"locality\"\n",
      "          value {\n",
      "            s: \"Local\"\n",
      "          }\n",
      "        }\n",
      "        attr {\n",
      "          key: \"type\"\n",
      "          value {\n",
      "            s: \"double\"\n",
      "          }\n",
      "        }\n",
      "        attr {\n",
      "          key: \"zextra\"\n",
      "          value {\n",
      "            s: \"agg_op {  op {    function_name: .sum.    inputs { }    expected_type { basic_type: DOUBLE }  }}\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      node {\n",
      "        name: \"divide3\"\n",
      "        op: \"org.spark.LocalStructuredTransform\"\n",
      "        input: \"sum0\"\n",
      "        input: \"cast_double2\"\n",
      "        device: \"/spark:0\"\n",
      "        attr {\n",
      "          key: \"locality\"\n",
      "          value {\n",
      "            s: \"Local\"\n",
      "          }\n",
      "        }\n",
      "        attr {\n",
      "          key: \"type\"\n",
      "          value {\n",
      "            s: \"double\"\n",
      "          }\n",
      "        }\n",
      "        attr {\n",
      "          key: \"zextra\"\n",
      "          value {\n",
      "            s: \"col_op {  function {    function_name: .divide.    inputs { broadcast { } }    inputs { broadcast { observable_index: 1 } }    expected_type { basic_type: DOUBLE }  }}\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  compilation_graph {\n",
      "    phase_name: \"REMOVE_OBSERVABLE_BROADCASTS\"\n",
      "    graph {\n",
      "      nodes {\n",
      "        locality: DISTRIBUTED\n",
      "        path {\n",
      "          path: \"my_input\"\n",
      "        }\n",
      "        op_name: \"org.spark.DistributedLiteral\"\n",
      "        op_extra {\n",
      "          content: \"\\n\\030R\\026\\n\\t)\\000\\000\\000\\000\\000\\000\\360?\\n\\t)\\000\\000\\000\\000\\000\\000\\000@\\022\\004\\022\\002\\010\\002\"\n",
      "          content_debug: \"cell {\\n  array_value {\\n    values { double_value: 1.0 } values { double_value: 2.0 }\\n  }\\n}\\ncell_type { array_type { basic_type: DOUBLE } }\"\n",
      "          content_base64: \"ChhSFgoJKQAAAAAAAPA/CgkpAAAAAAAAAEASBBICCAI=\"\n",
      "        }\n",
      "        infered_type {\n",
      "          basic_type: DOUBLE\n",
      "        }\n",
      "      }\n",
      "      nodes {\n",
      "        path {\n",
      "          path: \"count1\"\n",
      "        }\n",
      "        op_name: \"org.spark.StructuredReduce\"\n",
      "        op_extra {\n",
      "          content: \"\\n\\017\\n\\r\\n\\005count\\022\\000\\032\\002\\010\\001\"\n",
      "          content_debug: \"agg_op {\\n  op {\\n    function_name: \\\"count\\\" inputs { } expected_type { basic_type: INT }\\n  }\\n}\"\n",
      "          content_base64: \"Cg8KDQoFY291bnQSABoCCAE=\"\n",
      "        }\n",
      "        parents {\n",
      "          path: \"my_input\"\n",
      "        }\n",
      "        infered_type {\n",
      "          basic_type: INT\n",
      "        }\n",
      "      }\n",
      "      nodes {\n",
      "        path {\n",
      "          path: \"cast_double2\"\n",
      "        }\n",
      "        op_name: \"org.spark.LocalStructuredTransform\"\n",
      "        op_extra {\n",
      "          content: \"\\n\\027\\022\\025\\n\\013cast_double\\022\\002\\032\\000\\032\\002\\010\\002\"\n",
      "          content_debug: \"col_op {\\n  function {\\n    function_name: \\\"cast_double\\\"\\n    inputs { extraction { } }\\n    expected_type { basic_type: DOUBLE }\\n  }\\n}\"\n",
      "          content_base64: \"ChcSFQoLY2FzdF9kb3VibGUSAhoAGgIIAg==\"\n",
      "        }\n",
      "        parents {\n",
      "          path: \"count1\"\n",
      "        }\n",
      "        infered_type {\n",
      "          basic_type: DOUBLE\n",
      "        }\n",
      "      }\n",
      "      nodes {\n",
      "        path {\n",
      "          path: \"sum0\"\n",
      "        }\n",
      "        op_name: \"org.spark.StructuredReduce\"\n",
      "        op_extra {\n",
      "          content: \"\\n\\r\\n\\013\\n\\003sum\\022\\000\\032\\002\\010\\002\"\n",
      "          content_debug: \"agg_op {\\n  op {\\n    function_name: \\\"sum\\\"\\n    inputs { }\\n    expected_type { basic_type: DOUBLE }\\n  }\\n}\"\n",
      "          content_base64: \"Cg0KCwoDc3VtEgAaAggC\"\n",
      "        }\n",
      "        parents {\n",
      "          path: \"my_input\"\n",
      "        }\n",
      "        infered_type {\n",
      "          basic_type: DOUBLE\n",
      "        }\n",
      "      }\n",
      "      nodes {\n",
      "        path {\n",
      "          path: \"divide3_karps_localpack\"\n",
      "        }\n",
      "        op_name: \"org.spark.LocalPack\"\n",
      "        op_extra {\n",
      "        }\n",
      "        parents {\n",
      "          path: \"sum0\"\n",
      "        }\n",
      "        parents {\n",
      "          path: \"cast_double2\"\n",
      "        }\n",
      "        infered_type {\n",
      "          struct_type {\n",
      "            fields {\n",
      "              field_name: \"_1\"\n",
      "              field_type {\n",
      "                basic_type: DOUBLE\n",
      "              }\n",
      "            }\n",
      "            fields {\n",
      "              field_name: \"_2\"\n",
      "              field_type {\n",
      "                basic_type: DOUBLE\n",
      "              }\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      nodes {\n",
      "        path {\n",
      "          path: \"divide3\"\n",
      "        }\n",
      "        op_name: \"org.spark.LocalStructuredTransform\"\n",
      "        op_extra {\n",
      "          content: \"\\n\\036\\022\\034\\n\\006divide\\022\\006\\032\\004\\n\\002_1\\022\\006\\032\\004\\n\\002_2\\032\\002\\010\\002\"\n",
      "          content_debug: \"col_op {\\n  function {\\n    function_name: \\\"divide\\\"\\n    inputs { extraction { path: \\\"_1\\\" } }\\n    inputs { extraction { path: \\\"_2\\\" } }\\n    expected_type { basic_type: DOUBLE }\\n  }\\n}\"\n",
      "          content_base64: \"Ch4SHAoGZGl2aWRlEgYaBAoCXzESBhoECgJfMhoCCAI=\"\n",
      "        }\n",
      "        parents {\n",
      "          path: \"divide3_karps_localpack\"\n",
      "        }\n",
      "        infered_type {\n",
      "          basic_type: DOUBLE\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    graph_def {\n",
      "      node {\n",
      "        name: \"my_input\"\n",
      "        op: \"org.spark.DistributedLiteral\"\n",
      "        device: \"/spark:0\"\n",
      "        attr {\n",
      "          key: \"locality\"\n",
      "          value {\n",
      "            s: \"Distributed\"\n",
      "          }\n",
      "        }\n",
      "        attr {\n",
      "          key: \"type\"\n",
      "          value {\n",
      "            s: \"double\"\n",
      "          }\n",
      "        }\n",
      "        attr {\n",
      "          key: \"zextra\"\n",
      "          value {\n",
      "            s: \"cell {  array_value {    values { double_value: 1.0 } values { double_value: 2.0 }  }}cell_type { array_type { basic_type: DOUBLE } }\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      node {\n",
      "        name: \"count1\"\n",
      "        op: \"org.spark.StructuredReduce\"\n",
      "        input: \"my_input\"\n",
      "        device: \"/spark:0\"\n",
      "        attr {\n",
      "          key: \"locality\"\n",
      "          value {\n",
      "            s: \"Local\"\n",
      "          }\n",
      "        }\n",
      "        attr {\n",
      "          key: \"type\"\n",
      "          value {\n",
      "            s: \"int\"\n",
      "          }\n",
      "        }\n",
      "        attr {\n",
      "          key: \"zextra\"\n",
      "          value {\n",
      "            s: \"agg_op {  op {    function_name: .count. inputs { } expected_type { basic_type: INT }  }}\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      node {\n",
      "        name: \"cast_double2\"\n",
      "        op: \"org.spark.LocalStructuredTransform\"\n",
      "        input: \"count1\"\n",
      "        device: \"/spark:0\"\n",
      "        attr {\n",
      "          key: \"locality\"\n",
      "          value {\n",
      "            s: \"Local\"\n",
      "          }\n",
      "        }\n",
      "        attr {\n",
      "          key: \"type\"\n",
      "          value {\n",
      "            s: \"double\"\n",
      "          }\n",
      "        }\n",
      "        attr {\n",
      "          key: \"zextra\"\n",
      "          value {\n",
      "            s: \"col_op {  function {    function_name: .cast_double.    inputs { extraction { } }    expected_type { basic_type: DOUBLE }  }}\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      node {\n",
      "        name: \"sum0\"\n",
      "        op: \"org.spark.StructuredReduce\"\n",
      "        input: \"my_input\"\n",
      "        device: \"/spark:0\"\n",
      "        attr {\n",
      "          key: \"locality\"\n",
      "          value {\n",
      "            s: \"Local\"\n",
      "          }\n",
      "        }\n",
      "        attr {\n",
      "          key: \"type\"\n",
      "          value {\n",
      "            s: \"double\"\n",
      "          }\n",
      "        }\n",
      "        attr {\n",
      "          key: \"zextra\"\n",
      "          value {\n",
      "            s: \"agg_op {  op {    function_name: .sum.    inputs { }    expected_type { basic_type: DOUBLE }  }}\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      node {\n",
      "        name: \"divide3_karps_localpack\"\n",
      "        op: \"org.spark.LocalPack\"\n",
      "        input: \"sum0\"\n",
      "        input: \"cast_double2\"\n",
      "        device: \"/spark:0\"\n",
      "        attr {\n",
      "          key: \"locality\"\n",
      "          value {\n",
      "            s: \"Local\"\n",
      "          }\n",
      "        }\n",
      "        attr {\n",
      "          key: \"type\"\n",
      "          value {\n",
      "            s: \"{_1:double _2:double}\"\n",
      "          }\n",
      "        }\n",
      "        attr {\n",
      "          key: \"zextra\"\n",
      "          value {\n",
      "            s: \"\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      node {\n",
      "        name: \"divide3\"\n",
      "        op: \"org.spark.LocalStructuredTransform\"\n",
      "        input: \"divide3_karps_localpack\"\n",
      "        device: \"/spark:0\"\n",
      "        attr {\n",
      "          key: \"locality\"\n",
      "          value {\n",
      "            s: \"Local\"\n",
      "          }\n",
      "        }\n",
      "        attr {\n",
      "          key: \"type\"\n",
      "          value {\n",
      "            s: \"double\"\n",
      "          }\n",
      "        }\n",
      "        attr {\n",
      "          key: \"zextra\"\n",
      "          value {\n",
      "            s: \"col_op {  function {    function_name: .divide.    inputs { extraction { path: ._1. } }    inputs { extraction { path: ._2. } }    expected_type { basic_type: DOUBLE }  }}\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  compilation_graph {\n",
      "    phase_name: \"MERGE_PREAGG_AGGREGATIONS\"\n",
      "    graph {\n",
      "      nodes {\n",
      "        locality: DISTRIBUTED\n",
      "        path {\n",
      "          path: \"my_input\"\n",
      "        }\n",
      "        op_name: \"org.spark.DistributedLiteral\"\n",
      "        op_extra {\n",
      "          content: \"\\n\\030R\\026\\n\\t)\\000\\000\\000\\000\\000\\000\\360?\\n\\t)\\000\\000\\000\\000\\000\\000\\000@\\022\\004\\022\\002\\010\\002\"\n",
      "          content_debug: \"cell {\\n  array_value {\\n    values { double_value: 1.0 } values { double_value: 2.0 }\\n  }\\n}\\ncell_type { array_type { basic_type: DOUBLE } }\"\n",
      "          content_base64: \"ChhSFgoJKQAAAAAAAPA/CgkpAAAAAAAAAEASBBICCAI=\"\n",
      "        }\n",
      "        infered_type {\n",
      "          basic_type: DOUBLE\n",
      "        }\n",
      "      }\n",
      "      nodes {\n",
      "        path {\n",
      "          path: \"count1\"\n",
      "        }\n",
      "        op_name: \"org.spark.StructuredReduce\"\n",
      "        op_extra {\n",
      "          content: \"\\n\\017\\n\\r\\n\\005count\\022\\000\\032\\002\\010\\001\"\n",
      "          content_debug: \"agg_op {\\n  op {\\n    function_name: \\\"count\\\" inputs { } expected_type { basic_type: INT }\\n  }\\n}\"\n",
      "          content_base64: \"Cg8KDQoFY291bnQSABoCCAE=\"\n",
      "        }\n",
      "        parents {\n",
      "          path: \"my_input\"\n",
      "        }\n",
      "        infered_type {\n",
      "          basic_type: INT\n",
      "        }\n",
      "      }\n",
      "      nodes {\n",
      "        path {\n",
      "          path: \"cast_double2\"\n",
      "        }\n",
      "        op_name: \"org.spark.LocalStructuredTransform\"\n",
      "        op_extra {\n",
      "          content: \"\\n\\027\\022\\025\\n\\013cast_double\\022\\002\\032\\000\\032\\002\\010\\002\"\n",
      "          content_debug: \"col_op {\\n  function {\\n    function_name: \\\"cast_double\\\"\\n    inputs { extraction { } }\\n    expected_type { basic_type: DOUBLE }\\n  }\\n}\"\n",
      "          content_base64: \"ChcSFQoLY2FzdF9kb3VibGUSAhoAGgIIAg==\"\n",
      "        }\n",
      "        parents {\n",
      "          path: \"count1\"\n",
      "        }\n",
      "        infered_type {\n",
      "          basic_type: DOUBLE\n",
      "        }\n",
      "      }\n",
      "      nodes {\n",
      "        path {\n",
      "          path: \"sum0\"\n",
      "        }\n",
      "        op_name: \"org.spark.StructuredReduce\"\n",
      "        op_extra {\n",
      "          content: \"\\n\\r\\n\\013\\n\\003sum\\022\\000\\032\\002\\010\\002\"\n",
      "          content_debug: \"agg_op {\\n  op {\\n    function_name: \\\"sum\\\"\\n    inputs { }\\n    expected_type { basic_type: DOUBLE }\\n  }\\n}\"\n",
      "          content_base64: \"Cg0KCwoDc3VtEgAaAggC\"\n",
      "        }\n",
      "        parents {\n",
      "          path: \"my_input\"\n",
      "        }\n",
      "        infered_type {\n",
      "          basic_type: DOUBLE\n",
      "        }\n",
      "      }\n",
      "      nodes {\n",
      "        path {\n",
      "          path: \"divide3_karps_localpack\"\n",
      "        }\n",
      "        op_name: \"org.spark.LocalPack\"\n",
      "        op_extra {\n",
      "        }\n",
      "        parents {\n",
      "          path: \"sum0\"\n",
      "        }\n",
      "        parents {\n",
      "          path: \"cast_double2\"\n",
      "        }\n",
      "        infered_type {\n",
      "          struct_type {\n",
      "            fields {\n",
      "              field_name: \"_1\"\n",
      "              field_type {\n",
      "                basic_type: DOUBLE\n",
      "              }\n",
      "            }\n",
      "            fields {\n",
      "              field_name: \"_2\"\n",
      "              field_type {\n",
      "                basic_type: DOUBLE\n",
      "              }\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      nodes {\n",
      "        path {\n",
      "          path: \"divide3\"\n",
      "        }\n",
      "        op_name: \"org.spark.LocalStructuredTransform\"\n",
      "        op_extra {\n",
      "          content: \"\\n\\036\\022\\034\\n\\006divide\\022\\006\\032\\004\\n\\002_1\\022\\006\\032\\004\\n\\002_2\\032\\002\\010\\002\"\n",
      "          content_debug: \"col_op {\\n  function {\\n    function_name: \\\"divide\\\"\\n    inputs { extraction { path: \\\"_1\\\" } }\\n    inputs { extraction { path: \\\"_2\\\" } }\\n    expected_type { basic_type: DOUBLE }\\n  }\\n}\"\n",
      "          content_base64: \"Ch4SHAoGZGl2aWRlEgYaBAoCXzESBhoECgJfMhoCCAI=\"\n",
      "        }\n",
      "        parents {\n",
      "          path: \"divide3_karps_localpack\"\n",
      "        }\n",
      "        infered_type {\n",
      "          basic_type: DOUBLE\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    graph_def {\n",
      "      node {\n",
      "        name: \"my_input\"\n",
      "        op: \"org.spark.DistributedLiteral\"\n",
      "        device: \"/spark:0\"\n",
      "        attr {\n",
      "          key: \"locality\"\n",
      "          value {\n",
      "            s: \"Distributed\"\n",
      "          }\n",
      "        }\n",
      "        attr {\n",
      "          key: \"type\"\n",
      "          value {\n",
      "            s: \"double\"\n",
      "          }\n",
      "        }\n",
      "        attr {\n",
      "          key: \"zextra\"\n",
      "          value {\n",
      "            s: \"cell {  array_value {    values { double_value: 1.0 } values { double_value: 2.0 }  }}cell_type { array_type { basic_type: DOUBLE } }\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      node {\n",
      "        name: \"count1\"\n",
      "        op: \"org.spark.StructuredReduce\"\n",
      "        input: \"my_input\"\n",
      "        device: \"/spark:0\"\n",
      "        attr {\n",
      "          key: \"locality\"\n",
      "          value {\n",
      "            s: \"Local\"\n",
      "          }\n",
      "        }\n",
      "        attr {\n",
      "          key: \"type\"\n",
      "          value {\n",
      "            s: \"int\"\n",
      "          }\n",
      "        }\n",
      "        attr {\n",
      "          key: \"zextra\"\n",
      "          value {\n",
      "            s: \"agg_op {  op {    function_name: .count. inputs { } expected_type { basic_type: INT }  }}\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      node {\n",
      "        name: \"cast_double2\"\n",
      "        op: \"org.spark.LocalStructuredTransform\"\n",
      "        input: \"count1\"\n",
      "        device: \"/spark:0\"\n",
      "        attr {\n",
      "          key: \"locality\"\n",
      "          value {\n",
      "            s: \"Local\"\n",
      "          }\n",
      "        }\n",
      "        attr {\n",
      "          key: \"type\"\n",
      "          value {\n",
      "            s: \"double\"\n",
      "          }\n",
      "        }\n",
      "        attr {\n",
      "          key: \"zextra\"\n",
      "          value {\n",
      "            s: \"col_op {  function {    function_name: .cast_double.    inputs { extraction { } }    expected_type { basic_type: DOUBLE }  }}\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      node {\n",
      "        name: \"sum0\"\n",
      "        op: \"org.spark.StructuredReduce\"\n",
      "        input: \"my_input\"\n",
      "        device: \"/spark:0\"\n",
      "        attr {\n",
      "          key: \"locality\"\n",
      "          value {\n",
      "            s: \"Local\"\n",
      "          }\n",
      "        }\n",
      "        attr {\n",
      "          key: \"type\"\n",
      "          value {\n",
      "            s: \"double\"\n",
      "          }\n",
      "        }\n",
      "        attr {\n",
      "          key: \"zextra\"\n",
      "          value {\n",
      "            s: \"agg_op {  op {    function_name: .sum.    inputs { }    expected_type { basic_type: DOUBLE }  }}\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      node {\n",
      "        name: \"divide3_karps_localpack\"\n",
      "        op: \"org.spark.LocalPack\"\n",
      "        input: \"sum0\"\n",
      "        input: \"cast_double2\"\n",
      "        device: \"/spark:0\"\n",
      "        attr {\n",
      "          key: \"locality\"\n",
      "          value {\n",
      "            s: \"Local\"\n",
      "          }\n",
      "        }\n",
      "        attr {\n",
      "          key: \"type\"\n",
      "          value {\n",
      "            s: \"{_1:double _2:double}\"\n",
      "          }\n",
      "        }\n",
      "        attr {\n",
      "          key: \"zextra\"\n",
      "          value {\n",
      "            s: \"\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      node {\n",
      "        name: \"divide3\"\n",
      "        op: \"org.spark.LocalStructuredTransform\"\n",
      "        input: \"divide3_karps_localpack\"\n",
      "        device: \"/spark:0\"\n",
      "        attr {\n",
      "          key: \"locality\"\n",
      "          value {\n",
      "            s: \"Local\"\n",
      "          }\n",
      "        }\n",
      "        attr {\n",
      "          key: \"type\"\n",
      "          value {\n",
      "            s: \"double\"\n",
      "          }\n",
      "        }\n",
      "        attr {\n",
      "          key: \"zextra\"\n",
      "          value {\n",
      "            s: \"col_op {  function {    function_name: .divide.    inputs { extraction { path: ._1. } }    inputs { extraction { path: ._2. } }    expected_type { basic_type: DOUBLE }  }}\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  compilation_graph {\n",
      "    phase_name: \"MERGE_AGGREGATIONS\"\n",
      "    graph {\n",
      "      nodes {\n",
      "        locality: DISTRIBUTED\n",
      "        path {\n",
      "          path: \"my_input\"\n",
      "        }\n",
      "        op_name: \"org.spark.DistributedLiteral\"\n",
      "        op_extra {\n",
      "          content: \"\\n\\030R\\026\\n\\t)\\000\\000\\000\\000\\000\\000\\360?\\n\\t)\\000\\000\\000\\000\\000\\000\\000@\\022\\004\\022\\002\\010\\002\"\n",
      "          content_debug: \"cell {\\n  array_value {\\n    values { double_value: 1.0 } values { double_value: 2.0 }\\n  }\\n}\\ncell_type { array_type { basic_type: DOUBLE } }\"\n",
      "          content_base64: \"ChhSFgoJKQAAAAAAAPA/CgkpAAAAAAAAAEASBBICCAI=\"\n",
      "        }\n",
      "        infered_type {\n",
      "          basic_type: DOUBLE\n",
      "        }\n",
      "      }\n",
      "      nodes {\n",
      "        path {\n",
      "          path: \"my_input_karps_merged_agg\"\n",
      "        }\n",
      "        op_name: \"org.spark.StructuredReduce\"\n",
      "        op_extra {\n",
      "          content: \"\\n*\\022(\\n\\023\\n\\r\\n\\005count\\022\\000\\032\\002\\010\\001\\032\\002_1\\n\\021\\n\\013\\n\\003sum\\022\\000\\032\\002\\010\\002\\032\\002_2\"\n",
      "          content_debug: \"agg_op {\\n  struct {\\n    fields {\\n      op {\\n        function_name: \\\"count\\\" inputs { } expected_type { basic_type: INT }\\n      }\\n      field_name: \\\"_1\\\"\\n    }\\n    fields {\\n      op {\\n        function_name: \\\"sum\\\"\\n        inputs { }\\n        expected_type { basic_type: DOUBLE }\\n      }\\n      field_name: \\\"_2\\\"\\n    }\\n  }\\n}\"\n",
      "          content_base64: \"CioSKAoTCg0KBWNvdW50EgAaAggBGgJfMQoRCgsKA3N1bRIAGgIIAhoCXzI=\"\n",
      "        }\n",
      "        parents {\n",
      "          path: \"my_input\"\n",
      "        }\n",
      "        infered_type {\n",
      "          struct_type {\n",
      "            fields {\n",
      "              field_name: \"_1\"\n",
      "              field_type {\n",
      "                basic_type: INT\n",
      "              }\n",
      "            }\n",
      "            fields {\n",
      "              field_name: \"_2\"\n",
      "              field_type {\n",
      "                basic_type: DOUBLE\n",
      "              }\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      nodes {\n",
      "        path {\n",
      "          path: \"count1\"\n",
      "        }\n",
      "        op_name: \"org.spark.LocalStructuredTransform\"\n",
      "        op_extra {\n",
      "          content: \"\\n\\006\\032\\004\\n\\002_1\"\n",
      "          content_debug: \"col_op { extraction { path: \\\"_1\\\" } }\"\n",
      "          content_base64: \"CgYaBAoCXzE=\"\n",
      "        }\n",
      "        parents {\n",
      "          path: \"my_input_karps_merged_agg\"\n",
      "        }\n",
      "        infered_type {\n",
      "          basic_type: INT\n",
      "        }\n",
      "      }\n",
      "      nodes {\n",
      "        path {\n",
      "          path: \"cast_double2\"\n",
      "        }\n",
      "        op_name: \"org.spark.LocalStructuredTransform\"\n",
      "        op_extra {\n",
      "          content: \"\\n\\027\\022\\025\\n\\013cast_double\\022\\002\\032\\000\\032\\002\\010\\002\"\n",
      "          content_debug: \"col_op {\\n  function {\\n    function_name: \\\"cast_double\\\"\\n    inputs { extraction { } }\\n    expected_type { basic_type: DOUBLE }\\n  }\\n}\"\n",
      "          content_base64: \"ChcSFQoLY2FzdF9kb3VibGUSAhoAGgIIAg==\"\n",
      "        }\n",
      "        parents {\n",
      "          path: \"count1\"\n",
      "        }\n",
      "        infered_type {\n",
      "          basic_type: DOUBLE\n",
      "        }\n",
      "      }\n",
      "      nodes {\n",
      "        path {\n",
      "          path: \"sum0\"\n",
      "        }\n",
      "        op_name: \"org.spark.LocalStructuredTransform\"\n",
      "        op_extra {\n",
      "          content: \"\\n\\006\\032\\004\\n\\002_2\"\n",
      "          content_debug: \"col_op { extraction { path: \\\"_2\\\" } }\"\n",
      "          content_base64: \"CgYaBAoCXzI=\"\n",
      "        }\n",
      "        parents {\n",
      "          path: \"my_input_karps_merged_agg\"\n",
      "        }\n",
      "        infered_type {\n",
      "          basic_type: DOUBLE\n",
      "        }\n",
      "      }\n",
      "      nodes {\n",
      "        path {\n",
      "          path: \"divide3_karps_localpack\"\n",
      "        }\n",
      "        op_name: \"org.spark.LocalPack\"\n",
      "        op_extra {\n",
      "        }\n",
      "        parents {\n",
      "          path: \"sum0\"\n",
      "        }\n",
      "        parents {\n",
      "          path: \"cast_double2\"\n",
      "        }\n",
      "        infered_type {\n",
      "          struct_type {\n",
      "            fields {\n",
      "              field_name: \"_1\"\n",
      "              field_type {\n",
      "                basic_type: DOUBLE\n",
      "              }\n",
      "            }\n",
      "            fields {\n",
      "              field_name: \"_2\"\n",
      "              field_type {\n",
      "                basic_type: DOUBLE\n",
      "              }\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      nodes {\n",
      "        path {\n",
      "          path: \"divide3\"\n",
      "        }\n",
      "        op_name: \"org.spark.LocalStructuredTransform\"\n",
      "        op_extra {\n",
      "          content: \"\\n\\036\\022\\034\\n\\006divide\\022\\006\\032\\004\\n\\002_1\\022\\006\\032\\004\\n\\002_2\\032\\002\\010\\002\"\n",
      "          content_debug: \"col_op {\\n  function {\\n    function_name: \\\"divide\\\"\\n    inputs { extraction { path: \\\"_1\\\" } }\\n    inputs { extraction { path: \\\"_2\\\" } }\\n    expected_type { basic_type: DOUBLE }\\n  }\\n}\"\n",
      "          content_base64: \"Ch4SHAoGZGl2aWRlEgYaBAoCXzESBhoECgJfMhoCCAI=\"\n",
      "        }\n",
      "        parents {\n",
      "          path: \"divide3_karps_localpack\"\n",
      "        }\n",
      "        infered_type {\n",
      "          basic_type: DOUBLE\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    graph_def {\n",
      "      node {\n",
      "        name: \"my_input\"\n",
      "        op: \"org.spark.DistributedLiteral\"\n",
      "        device: \"/spark:0\"\n",
      "        attr {\n",
      "          key: \"locality\"\n",
      "          value {\n",
      "            s: \"Distributed\"\n",
      "          }\n",
      "        }\n",
      "        attr {\n",
      "          key: \"type\"\n",
      "          value {\n",
      "            s: \"double\"\n",
      "          }\n",
      "        }\n",
      "        attr {\n",
      "          key: \"zextra\"\n",
      "          value {\n",
      "            s: \"cell {  array_value {    values { double_value: 1.0 } values { double_value: 2.0 }  }}cell_type { array_type { basic_type: DOUBLE } }\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      node {\n",
      "        name: \"my_input_karps_merged_agg\"\n",
      "        op: \"org.spark.StructuredReduce\"\n",
      "        input: \"my_input\"\n",
      "        device: \"/spark:0\"\n",
      "        attr {\n",
      "          key: \"locality\"\n",
      "          value {\n",
      "            s: \"Local\"\n",
      "          }\n",
      "        }\n",
      "        attr {\n",
      "          key: \"type\"\n",
      "          value {\n",
      "            s: \"{_1:int _2:double}\"\n",
      "          }\n",
      "        }\n",
      "        attr {\n",
      "          key: \"zextra\"\n",
      "          value {\n",
      "            s: \"agg_op {  struct {    fields {      op {        function_name: .count. inputs { } expected_type { basic_type: INT }      }      field_name: ._1.    }    fields {      op {        function_name: .sum.        inputs { }        expected_type { basic_type: DOUBLE }      }      field_name: ._2.    }  }}\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      node {\n",
      "        name: \"count1\"\n",
      "        op: \"org.spark.LocalStructuredTransform\"\n",
      "        input: \"my_input_karps_merged_agg\"\n",
      "        device: \"/spark:0\"\n",
      "        attr {\n",
      "          key: \"locality\"\n",
      "          value {\n",
      "            s: \"Local\"\n",
      "          }\n",
      "        }\n",
      "        attr {\n",
      "          key: \"type\"\n",
      "          value {\n",
      "            s: \"int\"\n",
      "          }\n",
      "        }\n",
      "        attr {\n",
      "          key: \"zextra\"\n",
      "          value {\n",
      "            s: \"col_op { extraction { path: ._1. } }\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      node {\n",
      "        name: \"cast_double2\"\n",
      "        op: \"org.spark.LocalStructuredTransform\"\n",
      "        input: \"count1\"\n",
      "        device: \"/spark:0\"\n",
      "        attr {\n",
      "          key: \"locality\"\n",
      "          value {\n",
      "            s: \"Local\"\n",
      "          }\n",
      "        }\n",
      "        attr {\n",
      "          key: \"type\"\n",
      "          value {\n",
      "            s: \"double\"\n",
      "          }\n",
      "        }\n",
      "        attr {\n",
      "          key: \"zextra\"\n",
      "          value {\n",
      "            s: \"col_op {  function {    function_name: .cast_double.    inputs { extraction { } }    expected_type { basic_type: DOUBLE }  }}\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      node {\n",
      "        name: \"sum0\"\n",
      "        op: \"org.spark.LocalStructuredTransform\"\n",
      "        input: \"my_input_karps_merged_agg\"\n",
      "        device: \"/spark:0\"\n",
      "        attr {\n",
      "          key: \"locality\"\n",
      "          value {\n",
      "            s: \"Local\"\n",
      "          }\n",
      "        }\n",
      "        attr {\n",
      "          key: \"type\"\n",
      "          value {\n",
      "            s: \"double\"\n",
      "          }\n",
      "        }\n",
      "        attr {\n",
      "          key: \"zextra\"\n",
      "          value {\n",
      "            s: \"col_op { extraction { path: ._2. } }\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      node {\n",
      "        name: \"divide3_karps_localpack\"\n",
      "        op: \"org.spark.LocalPack\"\n",
      "        input: \"sum0\"\n",
      "        input: \"cast_double2\"\n",
      "        device: \"/spark:0\"\n",
      "        attr {\n",
      "          key: \"locality\"\n",
      "          value {\n",
      "            s: \"Local\"\n",
      "          }\n",
      "        }\n",
      "        attr {\n",
      "          key: \"type\"\n",
      "          value {\n",
      "            s: \"{_1:double _2:double}\"\n",
      "          }\n",
      "        }\n",
      "        attr {\n",
      "          key: \"zextra\"\n",
      "          value {\n",
      "            s: \"\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      node {\n",
      "        name: \"divide3\"\n",
      "        op: \"org.spark.LocalStructuredTransform\"\n",
      "        input: \"divide3_karps_localpack\"\n",
      "        device: \"/spark:0\"\n",
      "        attr {\n",
      "          key: \"locality\"\n",
      "          value {\n",
      "            s: \"Local\"\n",
      "          }\n",
      "        }\n",
      "        attr {\n",
      "          key: \"type\"\n",
      "          value {\n",
      "            s: \"double\"\n",
      "          }\n",
      "        }\n",
      "        attr {\n",
      "          key: \"zextra\"\n",
      "          value {\n",
      "            s: \"col_op {  function {    function_name: .divide.    inputs { extraction { path: ._1. } }    inputs { extraction { path: ._2. } }    expected_type { basic_type: DOUBLE }  }}\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  compilation_graph {\n",
      "    phase_name: \"DATA_SOURCE_INSERTION\"\n",
      "    graph {\n",
      "      nodes {\n",
      "        locality: DISTRIBUTED\n",
      "        path {\n",
      "          path: \"my_input\"\n",
      "        }\n",
      "        op_name: \"org.spark.DistributedLiteral\"\n",
      "        op_extra {\n",
      "          content: \"\\n\\030R\\026\\n\\t)\\000\\000\\000\\000\\000\\000\\360?\\n\\t)\\000\\000\\000\\000\\000\\000\\000@\\022\\004\\022\\002\\010\\002\"\n",
      "          content_debug: \"cell {\\n  array_value {\\n    values { double_value: 1.0 } values { double_value: 2.0 }\\n  }\\n}\\ncell_type { array_type { basic_type: DOUBLE } }\"\n",
      "          content_base64: \"ChhSFgoJKQAAAAAAAPA/CgkpAAAAAAAAAEASBBICCAI=\"\n",
      "        }\n",
      "        infered_type {\n",
      "          basic_type: DOUBLE\n",
      "        }\n",
      "      }\n",
      "      nodes {\n",
      "        path {\n",
      "          path: \"my_input_karps_merged_agg\"\n",
      "        }\n",
      "        op_name: \"org.spark.StructuredReduce\"\n",
      "        op_extra {\n",
      "          content: \"\\n*\\022(\\n\\023\\n\\r\\n\\005count\\022\\000\\032\\002\\010\\001\\032\\002_1\\n\\021\\n\\013\\n\\003sum\\022\\000\\032\\002\\010\\002\\032\\002_2\"\n",
      "          content_debug: \"agg_op {\\n  struct {\\n    fields {\\n      op {\\n        function_name: \\\"count\\\" inputs { } expected_type { basic_type: INT }\\n      }\\n      field_name: \\\"_1\\\"\\n    }\\n    fields {\\n      op {\\n        function_name: \\\"sum\\\"\\n        inputs { }\\n        expected_type { basic_type: DOUBLE }\\n      }\\n      field_name: \\\"_2\\\"\\n    }\\n  }\\n}\"\n",
      "          content_base64: \"CioSKAoTCg0KBWNvdW50EgAaAggBGgJfMQoRCgsKA3N1bRIAGgIIAhoCXzI=\"\n",
      "        }\n",
      "        parents {\n",
      "          path: \"my_input\"\n",
      "        }\n",
      "        infered_type {\n",
      "          struct_type {\n",
      "            fields {\n",
      "              field_name: \"_1\"\n",
      "              field_type {\n",
      "                basic_type: INT\n",
      "              }\n",
      "            }\n",
      "            fields {\n",
      "              field_name: \"_2\"\n",
      "              field_type {\n",
      "                basic_type: DOUBLE\n",
      "              }\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      nodes {\n",
      "        path {\n",
      "          path: \"count1\"\n",
      "        }\n",
      "        op_name: \"org.spark.LocalStructuredTransform\"\n",
      "        op_extra {\n",
      "          content: \"\\n\\006\\032\\004\\n\\002_1\"\n",
      "          content_debug: \"col_op { extraction { path: \\\"_1\\\" } }\"\n",
      "          content_base64: \"CgYaBAoCXzE=\"\n",
      "        }\n",
      "        parents {\n",
      "          path: \"my_input_karps_merged_agg\"\n",
      "        }\n",
      "        infered_type {\n",
      "          basic_type: INT\n",
      "        }\n",
      "      }\n",
      "      nodes {\n",
      "        path {\n",
      "          path: \"cast_double2\"\n",
      "        }\n",
      "        op_name: \"org.spark.LocalStructuredTransform\"\n",
      "        op_extra {\n",
      "          content: \"\\n\\027\\022\\025\\n\\013cast_double\\022\\002\\032\\000\\032\\002\\010\\002\"\n",
      "          content_debug: \"col_op {\\n  function {\\n    function_name: \\\"cast_double\\\"\\n    inputs { extraction { } }\\n    expected_type { basic_type: DOUBLE }\\n  }\\n}\"\n",
      "          content_base64: \"ChcSFQoLY2FzdF9kb3VibGUSAhoAGgIIAg==\"\n",
      "        }\n",
      "        parents {\n",
      "          path: \"count1\"\n",
      "        }\n",
      "        infered_type {\n",
      "          basic_type: DOUBLE\n",
      "        }\n",
      "      }\n",
      "      nodes {\n",
      "        path {\n",
      "          path: \"sum0\"\n",
      "        }\n",
      "        op_name: \"org.spark.LocalStructuredTransform\"\n",
      "        op_extra {\n",
      "          content: \"\\n\\006\\032\\004\\n\\002_2\"\n",
      "          content_debug: \"col_op { extraction { path: \\\"_2\\\" } }\"\n",
      "          content_base64: \"CgYaBAoCXzI=\"\n",
      "        }\n",
      "        parents {\n",
      "          path: \"my_input_karps_merged_agg\"\n",
      "        }\n",
      "        infered_type {\n",
      "          basic_type: DOUBLE\n",
      "        }\n",
      "      }\n",
      "      nodes {\n",
      "        path {\n",
      "          path: \"divide3_karps_localpack\"\n",
      "        }\n",
      "        op_name: \"org.spark.LocalPack\"\n",
      "        op_extra {\n",
      "        }\n",
      "        parents {\n",
      "          path: \"sum0\"\n",
      "        }\n",
      "        parents {\n",
      "          path: \"cast_double2\"\n",
      "        }\n",
      "        infered_type {\n",
      "          struct_type {\n",
      "            fields {\n",
      "              field_name: \"_1\"\n",
      "              field_type {\n",
      "                basic_type: DOUBLE\n",
      "              }\n",
      "            }\n",
      "            fields {\n",
      "              field_name: \"_2\"\n",
      "              field_type {\n",
      "                basic_type: DOUBLE\n",
      "              }\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      nodes {\n",
      "        path {\n",
      "          path: \"divide3\"\n",
      "        }\n",
      "        op_name: \"org.spark.LocalStructuredTransform\"\n",
      "        op_extra {\n",
      "          content: \"\\n\\036\\022\\034\\n\\006divide\\022\\006\\032\\004\\n\\002_1\\022\\006\\032\\004\\n\\002_2\\032\\002\\010\\002\"\n",
      "          content_debug: \"col_op {\\n  function {\\n    function_name: \\\"divide\\\"\\n    inputs { extraction { path: \\\"_1\\\" } }\\n    inputs { extraction { path: \\\"_2\\\" } }\\n    expected_type { basic_type: DOUBLE }\\n  }\\n}\"\n",
      "          content_base64: \"Ch4SHAoGZGl2aWRlEgYaBAoCXzESBhoECgJfMhoCCAI=\"\n",
      "        }\n",
      "        parents {\n",
      "          path: \"divide3_karps_localpack\"\n",
      "        }\n",
      "        infered_type {\n",
      "          basic_type: DOUBLE\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    graph_def {\n",
      "      node {\n",
      "        name: \"my_input\"\n",
      "        op: \"org.spark.DistributedLiteral\"\n",
      "        device: \"/spark:0\"\n",
      "        attr {\n",
      "          key: \"locality\"\n",
      "          value {\n",
      "            s: \"Distributed\"\n",
      "          }\n",
      "        }\n",
      "        attr {\n",
      "          key: \"type\"\n",
      "          value {\n",
      "            s: \"double\"\n",
      "          }\n",
      "        }\n",
      "        attr {\n",
      "          key: \"zextra\"\n",
      "          value {\n",
      "            s: \"cell {  array_value {    values { double_value: 1.0 } values { double_value: 2.0 }  }}cell_type { array_type { basic_type: DOUBLE } }\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      node {\n",
      "        name: \"my_input_karps_merged_agg\"\n",
      "        op: \"org.spark.StructuredReduce\"\n",
      "        input: \"my_input\"\n",
      "        device: \"/spark:0\"\n",
      "        attr {\n",
      "          key: \"locality\"\n",
      "          value {\n",
      "            s: \"Local\"\n",
      "          }\n",
      "        }\n",
      "        attr {\n",
      "          key: \"type\"\n",
      "          value {\n",
      "            s: \"{_1:int _2:double}\"\n",
      "          }\n",
      "        }\n",
      "        attr {\n",
      "          key: \"zextra\"\n",
      "          value {\n",
      "            s: \"agg_op {  struct {    fields {      op {        function_name: .count. inputs { } expected_type { basic_type: INT }      }      field_name: ._1.    }    fields {      op {        function_name: .sum.        inputs { }        expected_type { basic_type: DOUBLE }      }      field_name: ._2.    }  }}\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      node {\n",
      "        name: \"count1\"\n",
      "        op: \"org.spark.LocalStructuredTransform\"\n",
      "        input: \"my_input_karps_merged_agg\"\n",
      "        device: \"/spark:0\"\n",
      "        attr {\n",
      "          key: \"locality\"\n",
      "          value {\n",
      "            s: \"Local\"\n",
      "          }\n",
      "        }\n",
      "        attr {\n",
      "          key: \"type\"\n",
      "          value {\n",
      "            s: \"int\"\n",
      "          }\n",
      "        }\n",
      "        attr {\n",
      "          key: \"zextra\"\n",
      "          value {\n",
      "            s: \"col_op { extraction { path: ._1. } }\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      node {\n",
      "        name: \"cast_double2\"\n",
      "        op: \"org.spark.LocalStructuredTransform\"\n",
      "        input: \"count1\"\n",
      "        device: \"/spark:0\"\n",
      "        attr {\n",
      "          key: \"locality\"\n",
      "          value {\n",
      "            s: \"Local\"\n",
      "          }\n",
      "        }\n",
      "        attr {\n",
      "          key: \"type\"\n",
      "          value {\n",
      "            s: \"double\"\n",
      "          }\n",
      "        }\n",
      "        attr {\n",
      "          key: \"zextra\"\n",
      "          value {\n",
      "            s: \"col_op {  function {    function_name: .cast_double.    inputs { extraction { } }    expected_type { basic_type: DOUBLE }  }}\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      node {\n",
      "        name: \"sum0\"\n",
      "        op: \"org.spark.LocalStructuredTransform\"\n",
      "        input: \"my_input_karps_merged_agg\"\n",
      "        device: \"/spark:0\"\n",
      "        attr {\n",
      "          key: \"locality\"\n",
      "          value {\n",
      "            s: \"Local\"\n",
      "          }\n",
      "        }\n",
      "        attr {\n",
      "          key: \"type\"\n",
      "          value {\n",
      "            s: \"double\"\n",
      "          }\n",
      "        }\n",
      "        attr {\n",
      "          key: \"zextra\"\n",
      "          value {\n",
      "            s: \"col_op { extraction { path: ._2. } }\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      node {\n",
      "        name: \"divide3_karps_localpack\"\n",
      "        op: \"org.spark.LocalPack\"\n",
      "        input: \"sum0\"\n",
      "        input: \"cast_double2\"\n",
      "        device: \"/spark:0\"\n",
      "        attr {\n",
      "          key: \"locality\"\n",
      "          value {\n",
      "            s: \"Local\"\n",
      "          }\n",
      "        }\n",
      "        attr {\n",
      "          key: \"type\"\n",
      "          value {\n",
      "            s: \"{_1:double _2:double}\"\n",
      "          }\n",
      "        }\n",
      "        attr {\n",
      "          key: \"zextra\"\n",
      "          value {\n",
      "            s: \"\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      node {\n",
      "        name: \"divide3\"\n",
      "        op: \"org.spark.LocalStructuredTransform\"\n",
      "        input: \"divide3_karps_localpack\"\n",
      "        device: \"/spark:0\"\n",
      "        attr {\n",
      "          key: \"locality\"\n",
      "          value {\n",
      "            s: \"Local\"\n",
      "          }\n",
      "        }\n",
      "        attr {\n",
      "          key: \"type\"\n",
      "          value {\n",
      "            s: \"double\"\n",
      "          }\n",
      "        }\n",
      "        attr {\n",
      "          key: \"zextra\"\n",
      "          value {\n",
      "            s: \"col_op {  function {    function_name: .divide.    inputs { extraction { path: ._1. } }    inputs { extraction { path: ._2. } }    expected_type { basic_type: DOUBLE }  }}\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  compilation_graph {\n",
      "    phase_name: \"POINTER_SWAP_1\"\n",
      "    graph {\n",
      "      nodes {\n",
      "        locality: DISTRIBUTED\n",
      "        path {\n",
      "          path: \"my_input\"\n",
      "        }\n",
      "        op_name: \"org.spark.DistributedLiteral\"\n",
      "        op_extra {\n",
      "          content: \"\\n\\030R\\026\\n\\t)\\000\\000\\000\\000\\000\\000\\360?\\n\\t)\\000\\000\\000\\000\\000\\000\\000@\\022\\004\\022\\002\\010\\002\"\n",
      "          content_debug: \"cell {\\n  array_value {\\n    values { double_value: 1.0 } values { double_value: 2.0 }\\n  }\\n}\\ncell_type { array_type { basic_type: DOUBLE } }\"\n",
      "          content_base64: \"ChhSFgoJKQAAAAAAAPA/CgkpAAAAAAAAAEASBBICCAI=\"\n",
      "        }\n",
      "        infered_type {\n",
      "          basic_type: DOUBLE\n",
      "        }\n",
      "      }\n",
      "      nodes {\n",
      "        path {\n",
      "          path: \"my_input_karps_merged_agg\"\n",
      "        }\n",
      "        op_name: \"org.spark.StructuredReduce\"\n",
      "        op_extra {\n",
      "          content: \"\\n*\\022(\\n\\023\\n\\r\\n\\005count\\022\\000\\032\\002\\010\\001\\032\\002_1\\n\\021\\n\\013\\n\\003sum\\022\\000\\032\\002\\010\\002\\032\\002_2\"\n",
      "          content_debug: \"agg_op {\\n  struct {\\n    fields {\\n      op {\\n        function_name: \\\"count\\\" inputs { } expected_type { basic_type: INT }\\n      }\\n      field_name: \\\"_1\\\"\\n    }\\n    fields {\\n      op {\\n        function_name: \\\"sum\\\"\\n        inputs { }\\n        expected_type { basic_type: DOUBLE }\\n      }\\n      field_name: \\\"_2\\\"\\n    }\\n  }\\n}\"\n",
      "          content_base64: \"CioSKAoTCg0KBWNvdW50EgAaAggBGgJfMQoRCgsKA3N1bRIAGgIIAhoCXzI=\"\n",
      "        }\n",
      "        parents {\n",
      "          path: \"my_input\"\n",
      "        }\n",
      "        infered_type {\n",
      "          struct_type {\n",
      "            fields {\n",
      "              field_name: \"_1\"\n",
      "              field_type {\n",
      "                basic_type: INT\n",
      "              }\n",
      "            }\n",
      "            fields {\n",
      "              field_name: \"_2\"\n",
      "              field_type {\n",
      "                basic_type: DOUBLE\n",
      "              }\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      nodes {\n",
      "        path {\n",
      "          path: \"count1\"\n",
      "        }\n",
      "        op_name: \"org.spark.LocalStructuredTransform\"\n",
      "        op_extra {\n",
      "          content: \"\\n\\006\\032\\004\\n\\002_1\"\n",
      "          content_debug: \"col_op { extraction { path: \\\"_1\\\" } }\"\n",
      "          content_base64: \"CgYaBAoCXzE=\"\n",
      "        }\n",
      "        parents {\n",
      "          path: \"my_input_karps_merged_agg\"\n",
      "        }\n",
      "        infered_type {\n",
      "          basic_type: INT\n",
      "        }\n",
      "      }\n",
      "      nodes {\n",
      "        path {\n",
      "          path: \"cast_double2\"\n",
      "        }\n",
      "        op_name: \"org.spark.LocalStructuredTransform\"\n",
      "        op_extra {\n",
      "          content: \"\\n\\027\\022\\025\\n\\013cast_double\\022\\002\\032\\000\\032\\002\\010\\002\"\n",
      "          content_debug: \"col_op {\\n  function {\\n    function_name: \\\"cast_double\\\"\\n    inputs { extraction { } }\\n    expected_type { basic_type: DOUBLE }\\n  }\\n}\"\n",
      "          content_base64: \"ChcSFQoLY2FzdF9kb3VibGUSAhoAGgIIAg==\"\n",
      "        }\n",
      "        parents {\n",
      "          path: \"count1\"\n",
      "        }\n",
      "        infered_type {\n",
      "          basic_type: DOUBLE\n",
      "        }\n",
      "      }\n",
      "      nodes {\n",
      "        path {\n",
      "          path: \"sum0\"\n",
      "        }\n",
      "        op_name: \"org.spark.LocalStructuredTransform\"\n",
      "        op_extra {\n",
      "          content: \"\\n\\006\\032\\004\\n\\002_2\"\n",
      "          content_debug: \"col_op { extraction { path: \\\"_2\\\" } }\"\n",
      "          content_base64: \"CgYaBAoCXzI=\"\n",
      "        }\n",
      "        parents {\n",
      "          path: \"my_input_karps_merged_agg\"\n",
      "        }\n",
      "        infered_type {\n",
      "          basic_type: DOUBLE\n",
      "        }\n",
      "      }\n",
      "      nodes {\n",
      "        path {\n",
      "          path: \"divide3_karps_localpack\"\n",
      "        }\n",
      "        op_name: \"org.spark.LocalPack\"\n",
      "        op_extra {\n",
      "        }\n",
      "        parents {\n",
      "          path: \"sum0\"\n",
      "        }\n",
      "        parents {\n",
      "          path: \"cast_double2\"\n",
      "        }\n",
      "        infered_type {\n",
      "          struct_type {\n",
      "            fields {\n",
      "              field_name: \"_1\"\n",
      "              field_type {\n",
      "                basic_type: DOUBLE\n",
      "              }\n",
      "            }\n",
      "            fields {\n",
      "              field_name: \"_2\"\n",
      "              field_type {\n",
      "                basic_type: DOUBLE\n",
      "              }\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      nodes {\n",
      "        path {\n",
      "          path: \"divide3\"\n",
      "        }\n",
      "        op_name: \"org.spark.LocalStructuredTransform\"\n",
      "        op_extra {\n",
      "          content: \"\\n\\036\\022\\034\\n\\006divide\\022\\006\\032\\004\\n\\002_1\\022\\006\\032\\004\\n\\002_2\\032\\002\\010\\002\"\n",
      "          content_debug: \"col_op {\\n  function {\\n    function_name: \\\"divide\\\"\\n    inputs { extraction { path: \\\"_1\\\" } }\\n    inputs { extraction { path: \\\"_2\\\" } }\\n    expected_type { basic_type: DOUBLE }\\n  }\\n}\"\n",
      "          content_base64: \"Ch4SHAoGZGl2aWRlEgYaBAoCXzESBhoECgJfMhoCCAI=\"\n",
      "        }\n",
      "        parents {\n",
      "          path: \"divide3_karps_localpack\"\n",
      "        }\n",
      "        infered_type {\n",
      "          basic_type: DOUBLE\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    graph_def {\n",
      "      node {\n",
      "        name: \"my_input\"\n",
      "        op: \"org.spark.DistributedLiteral\"\n",
      "        device: \"/spark:0\"\n",
      "        attr {\n",
      "          key: \"locality\"\n",
      "          value {\n",
      "            s: \"Distributed\"\n",
      "          }\n",
      "        }\n",
      "        attr {\n",
      "          key: \"type\"\n",
      "          value {\n",
      "            s: \"double\"\n",
      "          }\n",
      "        }\n",
      "        attr {\n",
      "          key: \"zextra\"\n",
      "          value {\n",
      "            s: \"cell {  array_value {    values { double_value: 1.0 } values { double_value: 2.0 }  }}cell_type { array_type { basic_type: DOUBLE } }\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      node {\n",
      "        name: \"my_input_karps_merged_agg\"\n",
      "        op: \"org.spark.StructuredReduce\"\n",
      "        input: \"my_input\"\n",
      "        device: \"/spark:0\"\n",
      "        attr {\n",
      "          key: \"locality\"\n",
      "          value {\n",
      "            s: \"Local\"\n",
      "          }\n",
      "        }\n",
      "        attr {\n",
      "          key: \"type\"\n",
      "          value {\n",
      "            s: \"{_1:int _2:double}\"\n",
      "          }\n",
      "        }\n",
      "        attr {\n",
      "          key: \"zextra\"\n",
      "          value {\n",
      "            s: \"agg_op {  struct {    fields {      op {        function_name: .count. inputs { } expected_type { basic_type: INT }      }      field_name: ._1.    }    fields {      op {        function_name: .sum.        inputs { }        expected_type { basic_type: DOUBLE }      }      field_name: ._2.    }  }}\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      node {\n",
      "        name: \"count1\"\n",
      "        op: \"org.spark.LocalStructuredTransform\"\n",
      "        input: \"my_input_karps_merged_agg\"\n",
      "        device: \"/spark:0\"\n",
      "        attr {\n",
      "          key: \"locality\"\n",
      "          value {\n",
      "            s: \"Local\"\n",
      "          }\n",
      "        }\n",
      "        attr {\n",
      "          key: \"type\"\n",
      "          value {\n",
      "            s: \"int\"\n",
      "          }\n",
      "        }\n",
      "        attr {\n",
      "          key: \"zextra\"\n",
      "          value {\n",
      "            s: \"col_op { extraction { path: ._1. } }\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      node {\n",
      "        name: \"cast_double2\"\n",
      "        op: \"org.spark.LocalStructuredTransform\"\n",
      "        input: \"count1\"\n",
      "        device: \"/spark:0\"\n",
      "        attr {\n",
      "          key: \"locality\"\n",
      "          value {\n",
      "            s: \"Local\"\n",
      "          }\n",
      "        }\n",
      "        attr {\n",
      "          key: \"type\"\n",
      "          value {\n",
      "            s: \"double\"\n",
      "          }\n",
      "        }\n",
      "        attr {\n",
      "          key: \"zextra\"\n",
      "          value {\n",
      "            s: \"col_op {  function {    function_name: .cast_double.    inputs { extraction { } }    expected_type { basic_type: DOUBLE }  }}\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      node {\n",
      "        name: \"sum0\"\n",
      "        op: \"org.spark.LocalStructuredTransform\"\n",
      "        input: \"my_input_karps_merged_agg\"\n",
      "        device: \"/spark:0\"\n",
      "        attr {\n",
      "          key: \"locality\"\n",
      "          value {\n",
      "            s: \"Local\"\n",
      "          }\n",
      "        }\n",
      "        attr {\n",
      "          key: \"type\"\n",
      "          value {\n",
      "            s: \"double\"\n",
      "          }\n",
      "        }\n",
      "        attr {\n",
      "          key: \"zextra\"\n",
      "          value {\n",
      "            s: \"col_op { extraction { path: ._2. } }\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      node {\n",
      "        name: \"divide3_karps_localpack\"\n",
      "        op: \"org.spark.LocalPack\"\n",
      "        input: \"sum0\"\n",
      "        input: \"cast_double2\"\n",
      "        device: \"/spark:0\"\n",
      "        attr {\n",
      "          key: \"locality\"\n",
      "          value {\n",
      "            s: \"Local\"\n",
      "          }\n",
      "        }\n",
      "        attr {\n",
      "          key: \"type\"\n",
      "          value {\n",
      "            s: \"{_1:double _2:double}\"\n",
      "          }\n",
      "        }\n",
      "        attr {\n",
      "          key: \"zextra\"\n",
      "          value {\n",
      "            s: \"\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      node {\n",
      "        name: \"divide3\"\n",
      "        op: \"org.spark.LocalStructuredTransform\"\n",
      "        input: \"divide3_karps_localpack\"\n",
      "        device: \"/spark:0\"\n",
      "        attr {\n",
      "          key: \"locality\"\n",
      "          value {\n",
      "            s: \"Local\"\n",
      "          }\n",
      "        }\n",
      "        attr {\n",
      "          key: \"type\"\n",
      "          value {\n",
      "            s: \"double\"\n",
      "          }\n",
      "        }\n",
      "        attr {\n",
      "          key: \"zextra\"\n",
      "          value {\n",
      "            s: \"col_op {  function {    function_name: .divide.    inputs { extraction { path: ._1. } }    inputs { extraction { path: ._2. } }    expected_type { basic_type: DOUBLE }  }}\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  compilation_graph {\n",
      "    phase_name: \"FUNCTIONAL_FLATTENING\"\n",
      "    graph {\n",
      "      nodes {\n",
      "        locality: DISTRIBUTED\n",
      "        path {\n",
      "          path: \"my_input\"\n",
      "        }\n",
      "        op_name: \"org.spark.DistributedLiteral\"\n",
      "        op_extra {\n",
      "          content: \"\\n\\030R\\026\\n\\t)\\000\\000\\000\\000\\000\\000\\360?\\n\\t)\\000\\000\\000\\000\\000\\000\\000@\\022\\004\\022\\002\\010\\002\"\n",
      "          content_debug: \"cell {\\n  array_value {\\n    values { double_value: 1.0 } values { double_value: 2.0 }\\n  }\\n}\\ncell_type { array_type { basic_type: DOUBLE } }\"\n",
      "          content_base64: \"ChhSFgoJKQAAAAAAAPA/CgkpAAAAAAAAAEASBBICCAI=\"\n",
      "        }\n",
      "        infered_type {\n",
      "          basic_type: DOUBLE\n",
      "        }\n",
      "      }\n",
      "      nodes {\n",
      "        path {\n",
      "          path: \"my_input_karps_merged_agg\"\n",
      "        }\n",
      "        op_name: \"org.spark.StructuredReduce\"\n",
      "        op_extra {\n",
      "          content: \"\\n*\\022(\\n\\023\\n\\r\\n\\005count\\022\\000\\032\\002\\010\\001\\032\\002_1\\n\\021\\n\\013\\n\\003sum\\022\\000\\032\\002\\010\\002\\032\\002_2\"\n",
      "          content_debug: \"agg_op {\\n  struct {\\n    fields {\\n      op {\\n        function_name: \\\"count\\\" inputs { } expected_type { basic_type: INT }\\n      }\\n      field_name: \\\"_1\\\"\\n    }\\n    fields {\\n      op {\\n        function_name: \\\"sum\\\"\\n        inputs { }\\n        expected_type { basic_type: DOUBLE }\\n      }\\n      field_name: \\\"_2\\\"\\n    }\\n  }\\n}\"\n",
      "          content_base64: \"CioSKAoTCg0KBWNvdW50EgAaAggBGgJfMQoRCgsKA3N1bRIAGgIIAhoCXzI=\"\n",
      "        }\n",
      "        parents {\n",
      "          path: \"my_input\"\n",
      "        }\n",
      "        infered_type {\n",
      "          struct_type {\n",
      "            fields {\n",
      "              field_name: \"_1\"\n",
      "              field_type {\n",
      "                basic_type: INT\n",
      "              }\n",
      "            }\n",
      "            fields {\n",
      "              field_name: \"_2\"\n",
      "              field_type {\n",
      "                basic_type: DOUBLE\n",
      "              }\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      nodes {\n",
      "        path {\n",
      "          path: \"count1\"\n",
      "        }\n",
      "        op_name: \"org.spark.LocalStructuredTransform\"\n",
      "        op_extra {\n",
      "          content: \"\\n\\006\\032\\004\\n\\002_1\"\n",
      "          content_debug: \"col_op { extraction { path: \\\"_1\\\" } }\"\n",
      "          content_base64: \"CgYaBAoCXzE=\"\n",
      "        }\n",
      "        parents {\n",
      "          path: \"my_input_karps_merged_agg\"\n",
      "        }\n",
      "        infered_type {\n",
      "          basic_type: INT\n",
      "        }\n",
      "      }\n",
      "      nodes {\n",
      "        path {\n",
      "          path: \"cast_double2\"\n",
      "        }\n",
      "        op_name: \"org.spark.LocalStructuredTransform\"\n",
      "        op_extra {\n",
      "          content: \"\\n\\027\\022\\025\\n\\013cast_double\\022\\002\\032\\000\\032\\002\\010\\002\"\n",
      "          content_debug: \"col_op {\\n  function {\\n    function_name: \\\"cast_double\\\"\\n    inputs { extraction { } }\\n    expected_type { basic_type: DOUBLE }\\n  }\\n}\"\n",
      "          content_base64: \"ChcSFQoLY2FzdF9kb3VibGUSAhoAGgIIAg==\"\n",
      "        }\n",
      "        parents {\n",
      "          path: \"count1\"\n",
      "        }\n",
      "        infered_type {\n",
      "          basic_type: DOUBLE\n",
      "        }\n",
      "      }\n",
      "      nodes {\n",
      "        path {\n",
      "          path: \"sum0\"\n",
      "        }\n",
      "        op_name: \"org.spark.LocalStructuredTransform\"\n",
      "        op_extra {\n",
      "          content: \"\\n\\006\\032\\004\\n\\002_2\"\n",
      "          content_debug: \"col_op { extraction { path: \\\"_2\\\" } }\"\n",
      "          content_base64: \"CgYaBAoCXzI=\"\n",
      "        }\n",
      "        parents {\n",
      "          path: \"my_input_karps_merged_agg\"\n",
      "        }\n",
      "        infered_type {\n",
      "          basic_type: DOUBLE\n",
      "        }\n",
      "      }\n",
      "      nodes {\n",
      "        path {\n",
      "          path: \"divide3_karps_localpack\"\n",
      "        }\n",
      "        op_name: \"org.spark.LocalPack\"\n",
      "        op_extra {\n",
      "        }\n",
      "        parents {\n",
      "          path: \"sum0\"\n",
      "        }\n",
      "        parents {\n",
      "          path: \"cast_double2\"\n",
      "        }\n",
      "        infered_type {\n",
      "          struct_type {\n",
      "            fields {\n",
      "              field_name: \"_1\"\n",
      "              field_type {\n",
      "                basic_type: DOUBLE\n",
      "              }\n",
      "            }\n",
      "            fields {\n",
      "              field_name: \"_2\"\n",
      "              field_type {\n",
      "                basic_type: DOUBLE\n",
      "              }\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      nodes {\n",
      "        path {\n",
      "          path: \"divide3\"\n",
      "        }\n",
      "        op_name: \"org.spark.LocalStructuredTransform\"\n",
      "        op_extra {\n",
      "          content: \"\\n\\036\\022\\034\\n\\006divide\\022\\006\\032\\004\\n\\002_1\\022\\006\\032\\004\\n\\002_2\\032\\002\\010\\002\"\n",
      "          content_debug: \"col_op {\\n  function {\\n    function_name: \\\"divide\\\"\\n    inputs { extraction { path: \\\"_1\\\" } }\\n    inputs { extraction { path: \\\"_2\\\" } }\\n    expected_type { basic_type: DOUBLE }\\n  }\\n}\"\n",
      "          content_base64: \"Ch4SHAoGZGl2aWRlEgYaBAoCXzESBhoECgJfMhoCCAI=\"\n",
      "        }\n",
      "        parents {\n",
      "          path: \"divide3_karps_localpack\"\n",
      "        }\n",
      "        infered_type {\n",
      "          basic_type: DOUBLE\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    graph_def {\n",
      "      node {\n",
      "        name: \"my_input\"\n",
      "        op: \"org.spark.DistributedLiteral\"\n",
      "        device: \"/spark:0\"\n",
      "        attr {\n",
      "          key: \"locality\"\n",
      "          value {\n",
      "            s: \"Distributed\"\n",
      "          }\n",
      "        }\n",
      "        attr {\n",
      "          key: \"type\"\n",
      "          value {\n",
      "            s: \"double\"\n",
      "          }\n",
      "        }\n",
      "        attr {\n",
      "          key: \"zextra\"\n",
      "          value {\n",
      "            s: \"cell {  array_value {    values { double_value: 1.0 } values { double_value: 2.0 }  }}cell_type { array_type { basic_type: DOUBLE } }\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      node {\n",
      "        name: \"my_input_karps_merged_agg\"\n",
      "        op: \"org.spark.StructuredReduce\"\n",
      "        input: \"my_input\"\n",
      "        device: \"/spark:0\"\n",
      "        attr {\n",
      "          key: \"locality\"\n",
      "          value {\n",
      "            s: \"Local\"\n",
      "          }\n",
      "        }\n",
      "        attr {\n",
      "          key: \"type\"\n",
      "          value {\n",
      "            s: \"{_1:int _2:double}\"\n",
      "          }\n",
      "        }\n",
      "        attr {\n",
      "          key: \"zextra\"\n",
      "          value {\n",
      "            s: \"agg_op {  struct {    fields {      op {        function_name: .count. inputs { } expected_type { basic_type: INT }      }      field_name: ._1.    }    fields {      op {        function_name: .sum.        inputs { }        expected_type { basic_type: DOUBLE }      }      field_name: ._2.    }  }}\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      node {\n",
      "        name: \"count1\"\n",
      "        op: \"org.spark.LocalStructuredTransform\"\n",
      "        input: \"my_input_karps_merged_agg\"\n",
      "        device: \"/spark:0\"\n",
      "        attr {\n",
      "          key: \"locality\"\n",
      "          value {\n",
      "            s: \"Local\"\n",
      "          }\n",
      "        }\n",
      "        attr {\n",
      "          key: \"type\"\n",
      "          value {\n",
      "            s: \"int\"\n",
      "          }\n",
      "        }\n",
      "        attr {\n",
      "          key: \"zextra\"\n",
      "          value {\n",
      "            s: \"col_op { extraction { path: ._1. } }\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      node {\n",
      "        name: \"cast_double2\"\n",
      "        op: \"org.spark.LocalStructuredTransform\"\n",
      "        input: \"count1\"\n",
      "        device: \"/spark:0\"\n",
      "        attr {\n",
      "          key: \"locality\"\n",
      "          value {\n",
      "            s: \"Local\"\n",
      "          }\n",
      "        }\n",
      "        attr {\n",
      "          key: \"type\"\n",
      "          value {\n",
      "            s: \"double\"\n",
      "          }\n",
      "        }\n",
      "        attr {\n",
      "          key: \"zextra\"\n",
      "          value {\n",
      "            s: \"col_op {  function {    function_name: .cast_double.    inputs { extraction { } }    expected_type { basic_type: DOUBLE }  }}\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      node {\n",
      "        name: \"sum0\"\n",
      "        op: \"org.spark.LocalStructuredTransform\"\n",
      "        input: \"my_input_karps_merged_agg\"\n",
      "        device: \"/spark:0\"\n",
      "        attr {\n",
      "          key: \"locality\"\n",
      "          value {\n",
      "            s: \"Local\"\n",
      "          }\n",
      "        }\n",
      "        attr {\n",
      "          key: \"type\"\n",
      "          value {\n",
      "            s: \"double\"\n",
      "          }\n",
      "        }\n",
      "        attr {\n",
      "          key: \"zextra\"\n",
      "          value {\n",
      "            s: \"col_op { extraction { path: ._2. } }\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      node {\n",
      "        name: \"divide3_karps_localpack\"\n",
      "        op: \"org.spark.LocalPack\"\n",
      "        input: \"sum0\"\n",
      "        input: \"cast_double2\"\n",
      "        device: \"/spark:0\"\n",
      "        attr {\n",
      "          key: \"locality\"\n",
      "          value {\n",
      "            s: \"Local\"\n",
      "          }\n",
      "        }\n",
      "        attr {\n",
      "          key: \"type\"\n",
      "          value {\n",
      "            s: \"{_1:double _2:double}\"\n",
      "          }\n",
      "        }\n",
      "        attr {\n",
      "          key: \"zextra\"\n",
      "          value {\n",
      "            s: \"\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      node {\n",
      "        name: \"divide3\"\n",
      "        op: \"org.spark.LocalStructuredTransform\"\n",
      "        input: \"divide3_karps_localpack\"\n",
      "        device: \"/spark:0\"\n",
      "        attr {\n",
      "          key: \"locality\"\n",
      "          value {\n",
      "            s: \"Local\"\n",
      "          }\n",
      "        }\n",
      "        attr {\n",
      "          key: \"type\"\n",
      "          value {\n",
      "            s: \"double\"\n",
      "          }\n",
      "        }\n",
      "        attr {\n",
      "          key: \"zextra\"\n",
      "          value {\n",
      "            s: \"col_op {  function {    function_name: .divide.    inputs { extraction { path: ._1. } }    inputs { extraction { path: ._2. } }    expected_type { basic_type: DOUBLE }  }}\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  compilation_graph {\n",
      "    phase_name: \"AUTOCACHE_FULLFILL\"\n",
      "    graph {\n",
      "      nodes {\n",
      "        locality: DISTRIBUTED\n",
      "        path {\n",
      "          path: \"my_input\"\n",
      "        }\n",
      "        op_name: \"org.spark.DistributedLiteral\"\n",
      "        op_extra {\n",
      "          content: \"\\n\\030R\\026\\n\\t)\\000\\000\\000\\000\\000\\000\\360?\\n\\t)\\000\\000\\000\\000\\000\\000\\000@\\022\\004\\022\\002\\010\\002\"\n",
      "          content_debug: \"cell {\\n  array_value {\\n    values { double_value: 1.0 } values { double_value: 2.0 }\\n  }\\n}\\ncell_type { array_type { basic_type: DOUBLE } }\"\n",
      "          content_base64: \"ChhSFgoJKQAAAAAAAPA/CgkpAAAAAAAAAEASBBICCAI=\"\n",
      "        }\n",
      "        infered_type {\n",
      "          basic_type: DOUBLE\n",
      "        }\n",
      "      }\n",
      "      nodes {\n",
      "        path {\n",
      "          path: \"my_input_karps_merged_agg\"\n",
      "        }\n",
      "        op_name: \"org.spark.StructuredReduce\"\n",
      "        op_extra {\n",
      "          content: \"\\n*\\022(\\n\\023\\n\\r\\n\\005count\\022\\000\\032\\002\\010\\001\\032\\002_1\\n\\021\\n\\013\\n\\003sum\\022\\000\\032\\002\\010\\002\\032\\002_2\"\n",
      "          content_debug: \"agg_op {\\n  struct {\\n    fields {\\n      op {\\n        function_name: \\\"count\\\" inputs { } expected_type { basic_type: INT }\\n      }\\n      field_name: \\\"_1\\\"\\n    }\\n    fields {\\n      op {\\n        function_name: \\\"sum\\\"\\n        inputs { }\\n        expected_type { basic_type: DOUBLE }\\n      }\\n      field_name: \\\"_2\\\"\\n    }\\n  }\\n}\"\n",
      "          content_base64: \"CioSKAoTCg0KBWNvdW50EgAaAggBGgJfMQoRCgsKA3N1bRIAGgIIAhoCXzI=\"\n",
      "        }\n",
      "        parents {\n",
      "          path: \"my_input\"\n",
      "        }\n",
      "        infered_type {\n",
      "          struct_type {\n",
      "            fields {\n",
      "              field_name: \"_1\"\n",
      "              field_type {\n",
      "                basic_type: INT\n",
      "              }\n",
      "            }\n",
      "            fields {\n",
      "              field_name: \"_2\"\n",
      "              field_type {\n",
      "                basic_type: DOUBLE\n",
      "              }\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      nodes {\n",
      "        path {\n",
      "          path: \"count1\"\n",
      "        }\n",
      "        op_name: \"org.spark.LocalStructuredTransform\"\n",
      "        op_extra {\n",
      "          content: \"\\n\\006\\032\\004\\n\\002_1\"\n",
      "          content_debug: \"col_op { extraction { path: \\\"_1\\\" } }\"\n",
      "          content_base64: \"CgYaBAoCXzE=\"\n",
      "        }\n",
      "        parents {\n",
      "          path: \"my_input_karps_merged_agg\"\n",
      "        }\n",
      "        infered_type {\n",
      "          basic_type: INT\n",
      "        }\n",
      "      }\n",
      "      nodes {\n",
      "        path {\n",
      "          path: \"cast_double2\"\n",
      "        }\n",
      "        op_name: \"org.spark.LocalStructuredTransform\"\n",
      "        op_extra {\n",
      "          content: \"\\n\\027\\022\\025\\n\\013cast_double\\022\\002\\032\\000\\032\\002\\010\\002\"\n",
      "          content_debug: \"col_op {\\n  function {\\n    function_name: \\\"cast_double\\\"\\n    inputs { extraction { } }\\n    expected_type { basic_type: DOUBLE }\\n  }\\n}\"\n",
      "          content_base64: \"ChcSFQoLY2FzdF9kb3VibGUSAhoAGgIIAg==\"\n",
      "        }\n",
      "        parents {\n",
      "          path: \"count1\"\n",
      "        }\n",
      "        infered_type {\n",
      "          basic_type: DOUBLE\n",
      "        }\n",
      "      }\n",
      "      nodes {\n",
      "        path {\n",
      "          path: \"sum0\"\n",
      "        }\n",
      "        op_name: \"org.spark.LocalStructuredTransform\"\n",
      "        op_extra {\n",
      "          content: \"\\n\\006\\032\\004\\n\\002_2\"\n",
      "          content_debug: \"col_op { extraction { path: \\\"_2\\\" } }\"\n",
      "          content_base64: \"CgYaBAoCXzI=\"\n",
      "        }\n",
      "        parents {\n",
      "          path: \"my_input_karps_merged_agg\"\n",
      "        }\n",
      "        infered_type {\n",
      "          basic_type: DOUBLE\n",
      "        }\n",
      "      }\n",
      "      nodes {\n",
      "        path {\n",
      "          path: \"divide3_karps_localpack\"\n",
      "        }\n",
      "        op_name: \"org.spark.LocalPack\"\n",
      "        op_extra {\n",
      "        }\n",
      "        parents {\n",
      "          path: \"sum0\"\n",
      "        }\n",
      "        parents {\n",
      "          path: \"cast_double2\"\n",
      "        }\n",
      "        infered_type {\n",
      "          struct_type {\n",
      "            fields {\n",
      "              field_name: \"_1\"\n",
      "              field_type {\n",
      "                basic_type: DOUBLE\n",
      "              }\n",
      "            }\n",
      "            fields {\n",
      "              field_name: \"_2\"\n",
      "              field_type {\n",
      "                basic_type: DOUBLE\n",
      "              }\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      nodes {\n",
      "        path {\n",
      "          path: \"divide3\"\n",
      "        }\n",
      "        op_name: \"org.spark.LocalStructuredTransform\"\n",
      "        op_extra {\n",
      "          content: \"\\n\\036\\022\\034\\n\\006divide\\022\\006\\032\\004\\n\\002_1\\022\\006\\032\\004\\n\\002_2\\032\\002\\010\\002\"\n",
      "          content_debug: \"col_op {\\n  function {\\n    function_name: \\\"divide\\\"\\n    inputs { extraction { path: \\\"_1\\\" } }\\n    inputs { extraction { path: \\\"_2\\\" } }\\n    expected_type { basic_type: DOUBLE }\\n  }\\n}\"\n",
      "          content_base64: \"Ch4SHAoGZGl2aWRlEgYaBAoCXzESBhoECgJfMhoCCAI=\"\n",
      "        }\n",
      "        parents {\n",
      "          path: \"divide3_karps_localpack\"\n",
      "        }\n",
      "        infered_type {\n",
      "          basic_type: DOUBLE\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    graph_def {\n",
      "      node {\n",
      "        name: \"my_input\"\n",
      "        op: \"org.spark.DistributedLiteral\"\n",
      "        device: \"/spark:0\"\n",
      "        attr {\n",
      "          key: \"locality\"\n",
      "          value {\n",
      "            s: \"Distributed\"\n",
      "          }\n",
      "        }\n",
      "        attr {\n",
      "          key: \"type\"\n",
      "          value {\n",
      "            s: \"double\"\n",
      "          }\n",
      "        }\n",
      "        attr {\n",
      "          key: \"zextra\"\n",
      "          value {\n",
      "            s: \"cell {  array_value {    values { double_value: 1.0 } values { double_value: 2.0 }  }}cell_type { array_type { basic_type: DOUBLE } }\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      node {\n",
      "        name: \"my_input_karps_merged_agg\"\n",
      "        op: \"org.spark.StructuredReduce\"\n",
      "        input: \"my_input\"\n",
      "        device: \"/spark:0\"\n",
      "        attr {\n",
      "          key: \"locality\"\n",
      "          value {\n",
      "            s: \"Local\"\n",
      "          }\n",
      "        }\n",
      "        attr {\n",
      "          key: \"type\"\n",
      "          value {\n",
      "            s: \"{_1:int _2:double}\"\n",
      "          }\n",
      "        }\n",
      "        attr {\n",
      "          key: \"zextra\"\n",
      "          value {\n",
      "            s: \"agg_op {  struct {    fields {      op {        function_name: .count. inputs { } expected_type { basic_type: INT }      }      field_name: ._1.    }    fields {      op {        function_name: .sum.        inputs { }        expected_type { basic_type: DOUBLE }      }      field_name: ._2.    }  }}\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      node {\n",
      "        name: \"count1\"\n",
      "        op: \"org.spark.LocalStructuredTransform\"\n",
      "        input: \"my_input_karps_merged_agg\"\n",
      "        device: \"/spark:0\"\n",
      "        attr {\n",
      "          key: \"locality\"\n",
      "          value {\n",
      "            s: \"Local\"\n",
      "          }\n",
      "        }\n",
      "        attr {\n",
      "          key: \"type\"\n",
      "          value {\n",
      "            s: \"int\"\n",
      "          }\n",
      "        }\n",
      "        attr {\n",
      "          key: \"zextra\"\n",
      "          value {\n",
      "            s: \"col_op { extraction { path: ._1. } }\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      node {\n",
      "        name: \"cast_double2\"\n",
      "        op: \"org.spark.LocalStructuredTransform\"\n",
      "        input: \"count1\"\n",
      "        device: \"/spark:0\"\n",
      "        attr {\n",
      "          key: \"locality\"\n",
      "          value {\n",
      "            s: \"Local\"\n",
      "          }\n",
      "        }\n",
      "        attr {\n",
      "          key: \"type\"\n",
      "          value {\n",
      "            s: \"double\"\n",
      "          }\n",
      "        }\n",
      "        attr {\n",
      "          key: \"zextra\"\n",
      "          value {\n",
      "            s: \"col_op {  function {    function_name: .cast_double.    inputs { extraction { } }    expected_type { basic_type: DOUBLE }  }}\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      node {\n",
      "        name: \"sum0\"\n",
      "        op: \"org.spark.LocalStructuredTransform\"\n",
      "        input: \"my_input_karps_merged_agg\"\n",
      "        device: \"/spark:0\"\n",
      "        attr {\n",
      "          key: \"locality\"\n",
      "          value {\n",
      "            s: \"Local\"\n",
      "          }\n",
      "        }\n",
      "        attr {\n",
      "          key: \"type\"\n",
      "          value {\n",
      "            s: \"double\"\n",
      "          }\n",
      "        }\n",
      "        attr {\n",
      "          key: \"zextra\"\n",
      "          value {\n",
      "            s: \"col_op { extraction { path: ._2. } }\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      node {\n",
      "        name: \"divide3_karps_localpack\"\n",
      "        op: \"org.spark.LocalPack\"\n",
      "        input: \"sum0\"\n",
      "        input: \"cast_double2\"\n",
      "        device: \"/spark:0\"\n",
      "        attr {\n",
      "          key: \"locality\"\n",
      "          value {\n",
      "            s: \"Local\"\n",
      "          }\n",
      "        }\n",
      "        attr {\n",
      "          key: \"type\"\n",
      "          value {\n",
      "            s: \"{_1:double _2:double}\"\n",
      "          }\n",
      "        }\n",
      "        attr {\n",
      "          key: \"zextra\"\n",
      "          value {\n",
      "            s: \"\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      node {\n",
      "        name: \"divide3\"\n",
      "        op: \"org.spark.LocalStructuredTransform\"\n",
      "        input: \"divide3_karps_localpack\"\n",
      "        device: \"/spark:0\"\n",
      "        attr {\n",
      "          key: \"locality\"\n",
      "          value {\n",
      "            s: \"Local\"\n",
      "          }\n",
      "        }\n",
      "        attr {\n",
      "          key: \"type\"\n",
      "          value {\n",
      "            s: \"double\"\n",
      "          }\n",
      "        }\n",
      "        attr {\n",
      "          key: \"zextra\"\n",
      "          value {\n",
      "            s: \"col_op {  function {    function_name: .divide.    inputs { extraction { path: ._1. } }    inputs { extraction { path: ._2. } }    expected_type { basic_type: DOUBLE }  }}\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  compilation_graph {\n",
      "    phase_name: \"FINAL\"\n",
      "    graph {\n",
      "      nodes {\n",
      "        locality: DISTRIBUTED\n",
      "        path {\n",
      "          path: \"my_input\"\n",
      "        }\n",
      "        op_name: \"org.spark.DistributedLiteral\"\n",
      "        op_extra {\n",
      "          content: \"\\n\\030R\\026\\n\\t)\\000\\000\\000\\000\\000\\000\\360?\\n\\t)\\000\\000\\000\\000\\000\\000\\000@\\022\\004\\022\\002\\010\\002\"\n",
      "          content_debug: \"cell {\\n  array_value {\\n    values { double_value: 1.0 } values { double_value: 2.0 }\\n  }\\n}\\ncell_type { array_type { basic_type: DOUBLE } }\"\n",
      "          content_base64: \"ChhSFgoJKQAAAAAAAPA/CgkpAAAAAAAAAEASBBICCAI=\"\n",
      "        }\n",
      "        infered_type {\n",
      "          basic_type: DOUBLE\n",
      "        }\n",
      "      }\n",
      "      nodes {\n",
      "        path {\n",
      "          path: \"my_input_karps_merged_agg\"\n",
      "        }\n",
      "        op_name: \"org.spark.StructuredReduce\"\n",
      "        op_extra {\n",
      "          content: \"\\n*\\022(\\n\\023\\n\\r\\n\\005count\\022\\000\\032\\002\\010\\001\\032\\002_1\\n\\021\\n\\013\\n\\003sum\\022\\000\\032\\002\\010\\002\\032\\002_2\"\n",
      "          content_debug: \"agg_op {\\n  struct {\\n    fields {\\n      op {\\n        function_name: \\\"count\\\" inputs { } expected_type { basic_type: INT }\\n      }\\n      field_name: \\\"_1\\\"\\n    }\\n    fields {\\n      op {\\n        function_name: \\\"sum\\\"\\n        inputs { }\\n        expected_type { basic_type: DOUBLE }\\n      }\\n      field_name: \\\"_2\\\"\\n    }\\n  }\\n}\"\n",
      "          content_base64: \"CioSKAoTCg0KBWNvdW50EgAaAggBGgJfMQoRCgsKA3N1bRIAGgIIAhoCXzI=\"\n",
      "        }\n",
      "        parents {\n",
      "          path: \"my_input\"\n",
      "        }\n",
      "        infered_type {\n",
      "          struct_type {\n",
      "            fields {\n",
      "              field_name: \"_1\"\n",
      "              field_type {\n",
      "                basic_type: INT\n",
      "              }\n",
      "            }\n",
      "            fields {\n",
      "              field_name: \"_2\"\n",
      "              field_type {\n",
      "                basic_type: DOUBLE\n",
      "              }\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      nodes {\n",
      "        path {\n",
      "          path: \"count1\"\n",
      "        }\n",
      "        op_name: \"org.spark.LocalStructuredTransform\"\n",
      "        op_extra {\n",
      "          content: \"\\n\\006\\032\\004\\n\\002_1\"\n",
      "          content_debug: \"col_op { extraction { path: \\\"_1\\\" } }\"\n",
      "          content_base64: \"CgYaBAoCXzE=\"\n",
      "        }\n",
      "        parents {\n",
      "          path: \"my_input_karps_merged_agg\"\n",
      "        }\n",
      "        infered_type {\n",
      "          basic_type: INT\n",
      "        }\n",
      "      }\n",
      "      nodes {\n",
      "        path {\n",
      "          path: \"cast_double2\"\n",
      "        }\n",
      "        op_name: \"org.spark.LocalStructuredTransform\"\n",
      "        op_extra {\n",
      "          content: \"\\n\\027\\022\\025\\n\\013cast_double\\022\\002\\032\\000\\032\\002\\010\\002\"\n",
      "          content_debug: \"col_op {\\n  function {\\n    function_name: \\\"cast_double\\\"\\n    inputs { extraction { } }\\n    expected_type { basic_type: DOUBLE }\\n  }\\n}\"\n",
      "          content_base64: \"ChcSFQoLY2FzdF9kb3VibGUSAhoAGgIIAg==\"\n",
      "        }\n",
      "        parents {\n",
      "          path: \"count1\"\n",
      "        }\n",
      "        infered_type {\n",
      "          basic_type: DOUBLE\n",
      "        }\n",
      "      }\n",
      "      nodes {\n",
      "        path {\n",
      "          path: \"sum0\"\n",
      "        }\n",
      "        op_name: \"org.spark.LocalStructuredTransform\"\n",
      "        op_extra {\n",
      "          content: \"\\n\\006\\032\\004\\n\\002_2\"\n",
      "          content_debug: \"col_op { extraction { path: \\\"_2\\\" } }\"\n",
      "          content_base64: \"CgYaBAoCXzI=\"\n",
      "        }\n",
      "        parents {\n",
      "          path: \"my_input_karps_merged_agg\"\n",
      "        }\n",
      "        infered_type {\n",
      "          basic_type: DOUBLE\n",
      "        }\n",
      "      }\n",
      "      nodes {\n",
      "        path {\n",
      "          path: \"divide3_karps_localpack\"\n",
      "        }\n",
      "        op_name: \"org.spark.LocalPack\"\n",
      "        op_extra {\n",
      "        }\n",
      "        parents {\n",
      "          path: \"sum0\"\n",
      "        }\n",
      "        parents {\n",
      "          path: \"cast_double2\"\n",
      "        }\n",
      "        infered_type {\n",
      "          struct_type {\n",
      "            fields {\n",
      "              field_name: \"_1\"\n",
      "              field_type {\n",
      "                basic_type: DOUBLE\n",
      "              }\n",
      "            }\n",
      "            fields {\n",
      "              field_name: \"_2\"\n",
      "              field_type {\n",
      "                basic_type: DOUBLE\n",
      "              }\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      nodes {\n",
      "        path {\n",
      "          path: \"divide3\"\n",
      "        }\n",
      "        op_name: \"org.spark.LocalStructuredTransform\"\n",
      "        op_extra {\n",
      "          content: \"\\n\\036\\022\\034\\n\\006divide\\022\\006\\032\\004\\n\\002_1\\022\\006\\032\\004\\n\\002_2\\032\\002\\010\\002\"\n",
      "          content_debug: \"col_op {\\n  function {\\n    function_name: \\\"divide\\\"\\n    inputs { extraction { path: \\\"_1\\\" } }\\n    inputs { extraction { path: \\\"_2\\\" } }\\n    expected_type { basic_type: DOUBLE }\\n  }\\n}\"\n",
      "          content_base64: \"Ch4SHAoGZGl2aWRlEgYaBAoCXzESBhoECgJfMhoCCAI=\"\n",
      "        }\n",
      "        parents {\n",
      "          path: \"divide3_karps_localpack\"\n",
      "        }\n",
      "        infered_type {\n",
      "          basic_type: DOUBLE\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    graph_def {\n",
      "      node {\n",
      "        name: \"my_input\"\n",
      "        op: \"org.spark.DistributedLiteral\"\n",
      "        device: \"/spark:0\"\n",
      "        attr {\n",
      "          key: \"locality\"\n",
      "          value {\n",
      "            s: \"Distributed\"\n",
      "          }\n",
      "        }\n",
      "        attr {\n",
      "          key: \"type\"\n",
      "          value {\n",
      "            s: \"double\"\n",
      "          }\n",
      "        }\n",
      "        attr {\n",
      "          key: \"zextra\"\n",
      "          value {\n",
      "            s: \"cell {  array_value {    values { double_value: 1.0 } values { double_value: 2.0 }  }}cell_type { array_type { basic_type: DOUBLE } }\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      node {\n",
      "        name: \"my_input_karps_merged_agg\"\n",
      "        op: \"org.spark.StructuredReduce\"\n",
      "        input: \"my_input\"\n",
      "        device: \"/spark:0\"\n",
      "        attr {\n",
      "          key: \"locality\"\n",
      "          value {\n",
      "            s: \"Local\"\n",
      "          }\n",
      "        }\n",
      "        attr {\n",
      "          key: \"type\"\n",
      "          value {\n",
      "            s: \"{_1:int _2:double}\"\n",
      "          }\n",
      "        }\n",
      "        attr {\n",
      "          key: \"zextra\"\n",
      "          value {\n",
      "            s: \"agg_op {  struct {    fields {      op {        function_name: .count. inputs { } expected_type { basic_type: INT }      }      field_name: ._1.    }    fields {      op {        function_name: .sum.        inputs { }        expected_type { basic_type: DOUBLE }      }      field_name: ._2.    }  }}\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      node {\n",
      "        name: \"count1\"\n",
      "        op: \"org.spark.LocalStructuredTransform\"\n",
      "        input: \"my_input_karps_merged_agg\"\n",
      "        device: \"/spark:0\"\n",
      "        attr {\n",
      "          key: \"locality\"\n",
      "          value {\n",
      "            s: \"Local\"\n",
      "          }\n",
      "        }\n",
      "        attr {\n",
      "          key: \"type\"\n",
      "          value {\n",
      "            s: \"int\"\n",
      "          }\n",
      "        }\n",
      "        attr {\n",
      "          key: \"zextra\"\n",
      "          value {\n",
      "            s: \"col_op { extraction { path: ._1. } }\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      node {\n",
      "        name: \"cast_double2\"\n",
      "        op: \"org.spark.LocalStructuredTransform\"\n",
      "        input: \"count1\"\n",
      "        device: \"/spark:0\"\n",
      "        attr {\n",
      "          key: \"locality\"\n",
      "          value {\n",
      "            s: \"Local\"\n",
      "          }\n",
      "        }\n",
      "        attr {\n",
      "          key: \"type\"\n",
      "          value {\n",
      "            s: \"double\"\n",
      "          }\n",
      "        }\n",
      "        attr {\n",
      "          key: \"zextra\"\n",
      "          value {\n",
      "            s: \"col_op {  function {    function_name: .cast_double.    inputs { extraction { } }    expected_type { basic_type: DOUBLE }  }}\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      node {\n",
      "        name: \"sum0\"\n",
      "        op: \"org.spark.LocalStructuredTransform\"\n",
      "        input: \"my_input_karps_merged_agg\"\n",
      "        device: \"/spark:0\"\n",
      "        attr {\n",
      "          key: \"locality\"\n",
      "          value {\n",
      "            s: \"Local\"\n",
      "          }\n",
      "        }\n",
      "        attr {\n",
      "          key: \"type\"\n",
      "          value {\n",
      "            s: \"double\"\n",
      "          }\n",
      "        }\n",
      "        attr {\n",
      "          key: \"zextra\"\n",
      "          value {\n",
      "            s: \"col_op { extraction { path: ._2. } }\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      node {\n",
      "        name: \"divide3_karps_localpack\"\n",
      "        op: \"org.spark.LocalPack\"\n",
      "        input: \"sum0\"\n",
      "        input: \"cast_double2\"\n",
      "        device: \"/spark:0\"\n",
      "        attr {\n",
      "          key: \"locality\"\n",
      "          value {\n",
      "            s: \"Local\"\n",
      "          }\n",
      "        }\n",
      "        attr {\n",
      "          key: \"type\"\n",
      "          value {\n",
      "            s: \"{_1:double _2:double}\"\n",
      "          }\n",
      "        }\n",
      "        attr {\n",
      "          key: \"zextra\"\n",
      "          value {\n",
      "            s: \"\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      node {\n",
      "        name: \"divide3\"\n",
      "        op: \"org.spark.LocalStructuredTransform\"\n",
      "        input: \"divide3_karps_localpack\"\n",
      "        device: \"/spark:0\"\n",
      "        attr {\n",
      "          key: \"locality\"\n",
      "          value {\n",
      "            s: \"Local\"\n",
      "          }\n",
      "        }\n",
      "        attr {\n",
      "          key: \"type\"\n",
      "          value {\n",
      "            s: \"double\"\n",
      "          }\n",
      "        }\n",
      "        attr {\n",
      "          key: \"zextra\"\n",
      "          value {\n",
      "            s: \"col_op {  function {    function_name: .divide.    inputs { extraction { path: ._1. } }    inputs { extraction { path: ._2. } }    expected_type { basic_type: DOUBLE }  }}\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04:14:16 DEBUG:channel: received graph (discarding)\n",
      "04:14:16 DEBUG:channel: received pinned graph (discarding)\n",
      "04:14:16 DEBUG:channel: received compilation results\n",
      "04:14:16 DEBUG:channel: received compilation steps\n",
      "04:14:16 DEBUG:Calling _progress\n",
      "04:14:16 DEBUG:channel: got value <class 'karps.proto.interface_pb2.ComputationStreamResponse'>: session {\n",
      "  id: \"test3\"\n",
      "}\n",
      "computation {\n",
      "  id: \"1\"\n",
      "}\n",
      "results {\n",
      "  results {\n",
      "    local_path {\n",
      "      path: \"my_input_karps_merged_agg\"\n",
      "    }\n",
      "    status: SCHEDULED\n",
      "  }\n",
      "  results {\n",
      "    local_path {\n",
      "      path: \"cast_double2\"\n",
      "    }\n",
      "    status: SCHEDULED\n",
      "  }\n",
      "  results {\n",
      "    local_path {\n",
      "      path: \"divide3_karps_localpack\"\n",
      "    }\n",
      "    status: SCHEDULED\n",
      "  }\n",
      "  results {\n",
      "    local_path {\n",
      "      path: \"my_input\"\n",
      "    }\n",
      "    status: SCHEDULED\n",
      "  }\n",
      "  results {\n",
      "    local_path {\n",
      "      path: \"sum0\"\n",
      "    }\n",
      "    status: SCHEDULED\n",
      "  }\n",
      "  results {\n",
      "    local_path {\n",
      "      path: \"divide3\"\n",
      "    }\n",
      "    status: SCHEDULED\n",
      "  }\n",
      "  results {\n",
      "    local_path {\n",
      "      path: \"count1\"\n",
      "    }\n",
      "    status: SCHEDULED\n",
      "  }\n",
      "}\n",
      "\n",
      "04:14:16 DEBUG:channel: received result for /my_input_karps_merged_agg: local_path {\n",
      "  path: \"my_input_karps_merged_agg\"\n",
      "}\n",
      "status: SCHEDULED\n",
      "\n",
      "04:14:16 DEBUG:channel: received result for /cast_double2: local_path {\n",
      "  path: \"cast_double2\"\n",
      "}\n",
      "status: SCHEDULED\n",
      "\n",
      "04:14:16 DEBUG:channel: received result for /divide3_karps_localpack: local_path {\n",
      "  path: \"divide3_karps_localpack\"\n",
      "}\n",
      "status: SCHEDULED\n",
      "\n",
      "04:14:16 DEBUG:channel: received result for /my_input: local_path {\n",
      "  path: \"my_input\"\n",
      "}\n",
      "status: SCHEDULED\n",
      "\n",
      "04:14:16 DEBUG:channel: received result for /sum0: local_path {\n",
      "  path: \"sum0\"\n",
      "}\n",
      "status: SCHEDULED\n",
      "\n",
      "04:14:16 DEBUG:channel: received result for /divide3: local_path {\n",
      "  path: \"divide3\"\n",
      "}\n",
      "status: SCHEDULED\n",
      "\n",
      "04:14:16 DEBUG:channel: received result for /count1: local_path {\n",
      "  path: \"count1\"\n",
      "}\n",
      "status: SCHEDULED\n",
      "\n",
      "04:14:16 DEBUG:Calling _progress\n",
      "04:14:16 DEBUG:channel: got value <class 'karps.proto.interface_pb2.ComputationStreamResponse'>: session {\n",
      "  id: \"test3\"\n",
      "}\n",
      "computation {\n",
      "  id: \"1\"\n",
      "}\n",
      "results {\n",
      "  results {\n",
      "    local_path {\n",
      "      path: \"my_input\"\n",
      "    }\n",
      "    status: SCHEDULED\n",
      "    spark_stats {\n",
      "      rdd_info {\n",
      "        class_name: \"ParallelCollectionRDD\"\n",
      "        repr: \"ParallelCollectionRDD[0] at javaRDD at ExecutionItem.scala:56\"\n",
      "        proto {\n",
      "          name: \"my_input/ParallelCollectionRDD_0\"\n",
      "          op: \"ParallelCollectionRDD\"\n",
      "          attr {\n",
      "            key: \"name\"\n",
      "            value {\n",
      "              s: \"ParallelCollectionRDD\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      rdd_info {\n",
      "        rdd_id: 1\n",
      "        class_name: \"MapPartitionsRDD\"\n",
      "        repr: \"MapPartitionsRDD[1] at javaRDD at ExecutionItem.scala:56\"\n",
      "        parents: 0\n",
      "        proto {\n",
      "          name: \"my_input/MapPartitionsRDD_1\"\n",
      "          op: \"MapPartitionsRDD\"\n",
      "          input: \"my_input/ParallelCollectionRDD_0\"\n",
      "          attr {\n",
      "            key: \"name\"\n",
      "            value {\n",
      "              s: \"MapPartitionsRDD\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      rdd_info {\n",
      "        rdd_id: 2\n",
      "        class_name: \"MapPartitionsRDD\"\n",
      "        repr: \"MapPartitionsRDD[2] at javaRDD at ExecutionItem.scala:56\"\n",
      "        parents: 1\n",
      "        proto {\n",
      "          name: \"my_input/MapPartitionsRDD_2\"\n",
      "          op: \"MapPartitionsRDD\"\n",
      "          input: \"my_input/MapPartitionsRDD_1\"\n",
      "          attr {\n",
      "            key: \"name\"\n",
      "            value {\n",
      "              s: \"MapPartitionsRDD\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      rdd_info {\n",
      "        rdd_id: 3\n",
      "        class_name: \"MapPartitionsRDD\"\n",
      "        repr: \"MapPartitionsRDD[3] at javaRDD at ExecutionItem.scala:56\"\n",
      "        parents: 2\n",
      "        proto {\n",
      "          name: \"my_input/MapPartitionsRDD_3\"\n",
      "          op: \"MapPartitionsRDD\"\n",
      "          input: \"my_input/MapPartitionsRDD_2\"\n",
      "          attr {\n",
      "            key: \"name\"\n",
      "            value {\n",
      "              s: \"MapPartitionsRDD\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      rdd_info {\n",
      "        rdd_id: 4\n",
      "        class_name: \"MapPartitionsRDD\"\n",
      "        repr: \"MapPartitionsRDD[4] at createDataFrame at ExecutionItem.scala:56\"\n",
      "        parents: 3\n",
      "        proto {\n",
      "          name: \"my_input/MapPartitionsRDD_4\"\n",
      "          op: \"MapPartitionsRDD\"\n",
      "          input: \"my_input/MapPartitionsRDD_3\"\n",
      "          attr {\n",
      "            key: \"name\"\n",
      "            value {\n",
      "              s: \"MapPartitionsRDD\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      rdd_info {\n",
      "        rdd_id: 5\n",
      "        class_name: \"MapPartitionsRDD\"\n",
      "        repr: \"MapPartitionsRDD[5] at execute at ExecutionItem.scala:89\"\n",
      "        parents: 4\n",
      "        proto {\n",
      "          name: \"my_input/MapPartitionsRDD_5\"\n",
      "          op: \"MapPartitionsRDD\"\n",
      "          input: \"my_input/MapPartitionsRDD_4\"\n",
      "          attr {\n",
      "            key: \"name\"\n",
      "            value {\n",
      "              s: \"MapPartitionsRDD\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      parsed {\n",
      "        node_id: \"LogicalRDD_0\"\n",
      "        full_name: \"LogicalRDD [value#93]\"\n",
      "        proto {\n",
      "          name: \"my_input/LogicalRDD_0\"\n",
      "          op: \"LogicalRDD\"\n",
      "          attr {\n",
      "            key: \"schema\"\n",
      "            value {\n",
      "              s: \"root\\n |-- value: double (nullable = false)\\n\"\n",
      "            }\n",
      "          }\n",
      "          attr {\n",
      "            key: \"simple\"\n",
      "            value {\n",
      "              s: \"LogicalRDD [value#93]\"\n",
      "            }\n",
      "          }\n",
      "          attr {\n",
      "            key: \"verbose\"\n",
      "            value {\n",
      "              s: \"LogicalRDD [value#93]\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      physical {\n",
      "        node_id: \"Scan_ExistingRDD_0\"\n",
      "        full_name: \"Scan ExistingRDD[value#93]\"\n",
      "        proto {\n",
      "          name: \"my_input/Scan_ExistingRDD_0\"\n",
      "          op: \"Scan_ExistingRDD\"\n",
      "          attr {\n",
      "            key: \"schema\"\n",
      "            value {\n",
      "              s: \"root\\n |-- value: double (nullable = false)\\n\"\n",
      "            }\n",
      "          }\n",
      "          attr {\n",
      "            key: \"simple\"\n",
      "            value {\n",
      "              s: \"Scan ExistingRDD[value#93]\"\n",
      "            }\n",
      "          }\n",
      "          attr {\n",
      "            key: \"verbose\"\n",
      "            value {\n",
      "              s: \"Scan ExistingRDD[value#93]\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "04:14:16 DEBUG:channel: received result for /my_input: local_path {\n",
      "  path: \"my_input\"\n",
      "}\n",
      "status: SCHEDULED\n",
      "spark_stats {\n",
      "  rdd_info {\n",
      "    class_name: \"ParallelCollectionRDD\"\n",
      "    repr: \"ParallelCollectionRDD[0] at javaRDD at ExecutionItem.scala:56\"\n",
      "    proto {\n",
      "      name: \"my_input/ParallelCollectionRDD_0\"\n",
      "      op: \"ParallelCollectionRDD\"\n",
      "      attr {\n",
      "        key: \"name\"\n",
      "        value {\n",
      "          s: \"ParallelCollectionRDD\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  rdd_info {\n",
      "    rdd_id: 1\n",
      "    class_name: \"MapPartitionsRDD\"\n",
      "    repr: \"MapPartitionsRDD[1] at javaRDD at ExecutionItem.scala:56\"\n",
      "    parents: 0\n",
      "    proto {\n",
      "      name: \"my_input/MapPartitionsRDD_1\"\n",
      "      op: \"MapPartitionsRDD\"\n",
      "      input: \"my_input/ParallelCollectionRDD_0\"\n",
      "      attr {\n",
      "        key: \"name\"\n",
      "        value {\n",
      "          s: \"MapPartitionsRDD\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  rdd_info {\n",
      "    rdd_id: 2\n",
      "    class_name: \"MapPartitionsRDD\"\n",
      "    repr: \"MapPartitionsRDD[2] at javaRDD at ExecutionItem.scala:56\"\n",
      "    parents: 1\n",
      "    proto {\n",
      "      name: \"my_input/MapPartitionsRDD_2\"\n",
      "      op: \"MapPartitionsRDD\"\n",
      "      input: \"my_input/MapPartitionsRDD_1\"\n",
      "      attr {\n",
      "        key: \"name\"\n",
      "        value {\n",
      "          s: \"MapPartitionsRDD\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  rdd_info {\n",
      "    rdd_id: 3\n",
      "    class_name: \"MapPartitionsRDD\"\n",
      "    repr: \"MapPartitionsRDD[3] at javaRDD at ExecutionItem.scala:56\"\n",
      "    parents: 2\n",
      "    proto {\n",
      "      name: \"my_input/MapPartitionsRDD_3\"\n",
      "      op: \"MapPartitionsRDD\"\n",
      "      input: \"my_input/MapPartitionsRDD_2\"\n",
      "      attr {\n",
      "        key: \"name\"\n",
      "        value {\n",
      "          s: \"MapPartitionsRDD\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  rdd_info {\n",
      "    rdd_id: 4\n",
      "    class_name: \"MapPartitionsRDD\"\n",
      "    repr: \"MapPartitionsRDD[4] at createDataFrame at ExecutionItem.scala:56\"\n",
      "    parents: 3\n",
      "    proto {\n",
      "      name: \"my_input/MapPartitionsRDD_4\"\n",
      "      op: \"MapPartitionsRDD\"\n",
      "      input: \"my_input/MapPartitionsRDD_3\"\n",
      "      attr {\n",
      "        key: \"name\"\n",
      "        value {\n",
      "          s: \"MapPartitionsRDD\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  rdd_info {\n",
      "    rdd_id: 5\n",
      "    class_name: \"MapPartitionsRDD\"\n",
      "    repr: \"MapPartitionsRDD[5] at execute at ExecutionItem.scala:89\"\n",
      "    parents: 4\n",
      "    proto {\n",
      "      name: \"my_input/MapPartitionsRDD_5\"\n",
      "      op: \"MapPartitionsRDD\"\n",
      "      input: \"my_input/MapPartitionsRDD_4\"\n",
      "      attr {\n",
      "        key: \"name\"\n",
      "        value {\n",
      "          s: \"MapPartitionsRDD\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parsed {\n",
      "    node_id: \"LogicalRDD_0\"\n",
      "    full_name: \"LogicalRDD [value#93]\"\n",
      "    proto {\n",
      "      name: \"my_input/LogicalRDD_0\"\n",
      "      op: \"LogicalRDD\"\n",
      "      attr {\n",
      "        key: \"schema\"\n",
      "        value {\n",
      "          s: \"root\\n |-- value: double (nullable = false)\\n\"\n",
      "        }\n",
      "      }\n",
      "      attr {\n",
      "        key: \"simple\"\n",
      "        value {\n",
      "          s: \"LogicalRDD [value#93]\"\n",
      "        }\n",
      "      }\n",
      "      attr {\n",
      "        key: \"verbose\"\n",
      "        value {\n",
      "          s: \"LogicalRDD [value#93]\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  physical {\n",
      "    node_id: \"Scan_ExistingRDD_0\"\n",
      "    full_name: \"Scan ExistingRDD[value#93]\"\n",
      "    proto {\n",
      "      name: \"my_input/Scan_ExistingRDD_0\"\n",
      "      op: \"Scan_ExistingRDD\"\n",
      "      attr {\n",
      "        key: \"schema\"\n",
      "        value {\n",
      "          s: \"root\\n |-- value: double (nullable = false)\\n\"\n",
      "        }\n",
      "      }\n",
      "      attr {\n",
      "        key: \"simple\"\n",
      "        value {\n",
      "          s: \"Scan ExistingRDD[value#93]\"\n",
      "        }\n",
      "      }\n",
      "      attr {\n",
      "        key: \"verbose\"\n",
      "        value {\n",
      "          s: \"Scan ExistingRDD[value#93]\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04:14:16 DEBUG:Calling _progress\n",
      "04:14:17 DEBUG:channel: got value <class 'karps.proto.interface_pb2.ComputationStreamResponse'>: session {\n",
      "  id: \"test3\"\n",
      "}\n",
      "computation {\n",
      "  id: \"1\"\n",
      "}\n",
      "results {\n",
      "  results {\n",
      "    local_path {\n",
      "      path: \"my_input\"\n",
      "    }\n",
      "    status: SCHEDULED\n",
      "    spark_stats {\n",
      "      rdd_info {\n",
      "        class_name: \"ParallelCollectionRDD\"\n",
      "        repr: \"ParallelCollectionRDD[0] at javaRDD at ExecutionItem.scala:56\"\n",
      "        proto {\n",
      "          name: \"my_input/ParallelCollectionRDD_0\"\n",
      "          op: \"ParallelCollectionRDD\"\n",
      "          attr {\n",
      "            key: \"name\"\n",
      "            value {\n",
      "              s: \"ParallelCollectionRDD\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      rdd_info {\n",
      "        rdd_id: 1\n",
      "        class_name: \"MapPartitionsRDD\"\n",
      "        repr: \"MapPartitionsRDD[1] at javaRDD at ExecutionItem.scala:56\"\n",
      "        parents: 0\n",
      "        proto {\n",
      "          name: \"my_input/MapPartitionsRDD_1\"\n",
      "          op: \"MapPartitionsRDD\"\n",
      "          input: \"my_input/ParallelCollectionRDD_0\"\n",
      "          attr {\n",
      "            key: \"name\"\n",
      "            value {\n",
      "              s: \"MapPartitionsRDD\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      rdd_info {\n",
      "        rdd_id: 2\n",
      "        class_name: \"MapPartitionsRDD\"\n",
      "        repr: \"MapPartitionsRDD[2] at javaRDD at ExecutionItem.scala:56\"\n",
      "        parents: 1\n",
      "        proto {\n",
      "          name: \"my_input/MapPartitionsRDD_2\"\n",
      "          op: \"MapPartitionsRDD\"\n",
      "          input: \"my_input/MapPartitionsRDD_1\"\n",
      "          attr {\n",
      "            key: \"name\"\n",
      "            value {\n",
      "              s: \"MapPartitionsRDD\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      rdd_info {\n",
      "        rdd_id: 3\n",
      "        class_name: \"MapPartitionsRDD\"\n",
      "        repr: \"MapPartitionsRDD[3] at javaRDD at ExecutionItem.scala:56\"\n",
      "        parents: 2\n",
      "        proto {\n",
      "          name: \"my_input/MapPartitionsRDD_3\"\n",
      "          op: \"MapPartitionsRDD\"\n",
      "          input: \"my_input/MapPartitionsRDD_2\"\n",
      "          attr {\n",
      "            key: \"name\"\n",
      "            value {\n",
      "              s: \"MapPartitionsRDD\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      rdd_info {\n",
      "        rdd_id: 4\n",
      "        class_name: \"MapPartitionsRDD\"\n",
      "        repr: \"MapPartitionsRDD[4] at createDataFrame at ExecutionItem.scala:56\"\n",
      "        parents: 3\n",
      "        proto {\n",
      "          name: \"my_input/MapPartitionsRDD_4\"\n",
      "          op: \"MapPartitionsRDD\"\n",
      "          input: \"my_input/MapPartitionsRDD_3\"\n",
      "          attr {\n",
      "            key: \"name\"\n",
      "            value {\n",
      "              s: \"MapPartitionsRDD\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      rdd_info {\n",
      "        rdd_id: 5\n",
      "        class_name: \"MapPartitionsRDD\"\n",
      "        repr: \"MapPartitionsRDD[5] at execute at ExecutionItem.scala:89\"\n",
      "        parents: 4\n",
      "        proto {\n",
      "          name: \"my_input/MapPartitionsRDD_5\"\n",
      "          op: \"MapPartitionsRDD\"\n",
      "          input: \"my_input/MapPartitionsRDD_4\"\n",
      "          attr {\n",
      "            key: \"name\"\n",
      "            value {\n",
      "              s: \"MapPartitionsRDD\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      parsed {\n",
      "        node_id: \"LogicalRDD_0\"\n",
      "        full_name: \"LogicalRDD [value#93]\"\n",
      "        proto {\n",
      "          name: \"my_input/LogicalRDD_0\"\n",
      "          op: \"LogicalRDD\"\n",
      "          attr {\n",
      "            key: \"schema\"\n",
      "            value {\n",
      "              s: \"root\\n |-- value: double (nullable = false)\\n\"\n",
      "            }\n",
      "          }\n",
      "          attr {\n",
      "            key: \"simple\"\n",
      "            value {\n",
      "              s: \"LogicalRDD [value#93]\"\n",
      "            }\n",
      "          }\n",
      "          attr {\n",
      "            key: \"verbose\"\n",
      "            value {\n",
      "              s: \"LogicalRDD [value#93]\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      physical {\n",
      "        node_id: \"Scan_ExistingRDD_0\"\n",
      "        full_name: \"Scan ExistingRDD[value#93]\"\n",
      "        proto {\n",
      "          name: \"my_input/Scan_ExistingRDD_0\"\n",
      "          op: \"Scan_ExistingRDD\"\n",
      "          attr {\n",
      "            key: \"schema\"\n",
      "            value {\n",
      "              s: \"root\\n |-- value: double (nullable = false)\\n\"\n",
      "            }\n",
      "          }\n",
      "          attr {\n",
      "            key: \"simple\"\n",
      "            value {\n",
      "              s: \"Scan ExistingRDD[value#93]\"\n",
      "            }\n",
      "          }\n",
      "          attr {\n",
      "            key: \"verbose\"\n",
      "            value {\n",
      "              s: \"Scan ExistingRDD[value#93]\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "04:14:17 DEBUG:channel: received result for /my_input: local_path {\n",
      "  path: \"my_input\"\n",
      "}\n",
      "status: SCHEDULED\n",
      "spark_stats {\n",
      "  rdd_info {\n",
      "    class_name: \"ParallelCollectionRDD\"\n",
      "    repr: \"ParallelCollectionRDD[0] at javaRDD at ExecutionItem.scala:56\"\n",
      "    proto {\n",
      "      name: \"my_input/ParallelCollectionRDD_0\"\n",
      "      op: \"ParallelCollectionRDD\"\n",
      "      attr {\n",
      "        key: \"name\"\n",
      "        value {\n",
      "          s: \"ParallelCollectionRDD\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  rdd_info {\n",
      "    rdd_id: 1\n",
      "    class_name: \"MapPartitionsRDD\"\n",
      "    repr: \"MapPartitionsRDD[1] at javaRDD at ExecutionItem.scala:56\"\n",
      "    parents: 0\n",
      "    proto {\n",
      "      name: \"my_input/MapPartitionsRDD_1\"\n",
      "      op: \"MapPartitionsRDD\"\n",
      "      input: \"my_input/ParallelCollectionRDD_0\"\n",
      "      attr {\n",
      "        key: \"name\"\n",
      "        value {\n",
      "          s: \"MapPartitionsRDD\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  rdd_info {\n",
      "    rdd_id: 2\n",
      "    class_name: \"MapPartitionsRDD\"\n",
      "    repr: \"MapPartitionsRDD[2] at javaRDD at ExecutionItem.scala:56\"\n",
      "    parents: 1\n",
      "    proto {\n",
      "      name: \"my_input/MapPartitionsRDD_2\"\n",
      "      op: \"MapPartitionsRDD\"\n",
      "      input: \"my_input/MapPartitionsRDD_1\"\n",
      "      attr {\n",
      "        key: \"name\"\n",
      "        value {\n",
      "          s: \"MapPartitionsRDD\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  rdd_info {\n",
      "    rdd_id: 3\n",
      "    class_name: \"MapPartitionsRDD\"\n",
      "    repr: \"MapPartitionsRDD[3] at javaRDD at ExecutionItem.scala:56\"\n",
      "    parents: 2\n",
      "    proto {\n",
      "      name: \"my_input/MapPartitionsRDD_3\"\n",
      "      op: \"MapPartitionsRDD\"\n",
      "      input: \"my_input/MapPartitionsRDD_2\"\n",
      "      attr {\n",
      "        key: \"name\"\n",
      "        value {\n",
      "          s: \"MapPartitionsRDD\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  rdd_info {\n",
      "    rdd_id: 4\n",
      "    class_name: \"MapPartitionsRDD\"\n",
      "    repr: \"MapPartitionsRDD[4] at createDataFrame at ExecutionItem.scala:56\"\n",
      "    parents: 3\n",
      "    proto {\n",
      "      name: \"my_input/MapPartitionsRDD_4\"\n",
      "      op: \"MapPartitionsRDD\"\n",
      "      input: \"my_input/MapPartitionsRDD_3\"\n",
      "      attr {\n",
      "        key: \"name\"\n",
      "        value {\n",
      "          s: \"MapPartitionsRDD\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  rdd_info {\n",
      "    rdd_id: 5\n",
      "    class_name: \"MapPartitionsRDD\"\n",
      "    repr: \"MapPartitionsRDD[5] at execute at ExecutionItem.scala:89\"\n",
      "    parents: 4\n",
      "    proto {\n",
      "      name: \"my_input/MapPartitionsRDD_5\"\n",
      "      op: \"MapPartitionsRDD\"\n",
      "      input: \"my_input/MapPartitionsRDD_4\"\n",
      "      attr {\n",
      "        key: \"name\"\n",
      "        value {\n",
      "          s: \"MapPartitionsRDD\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parsed {\n",
      "    node_id: \"LogicalRDD_0\"\n",
      "    full_name: \"LogicalRDD [value#93]\"\n",
      "    proto {\n",
      "      name: \"my_input/LogicalRDD_0\"\n",
      "      op: \"LogicalRDD\"\n",
      "      attr {\n",
      "        key: \"schema\"\n",
      "        value {\n",
      "          s: \"root\\n |-- value: double (nullable = false)\\n\"\n",
      "        }\n",
      "      }\n",
      "      attr {\n",
      "        key: \"simple\"\n",
      "        value {\n",
      "          s: \"LogicalRDD [value#93]\"\n",
      "        }\n",
      "      }\n",
      "      attr {\n",
      "        key: \"verbose\"\n",
      "        value {\n",
      "          s: \"LogicalRDD [value#93]\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  physical {\n",
      "    node_id: \"Scan_ExistingRDD_0\"\n",
      "    full_name: \"Scan ExistingRDD[value#93]\"\n",
      "    proto {\n",
      "      name: \"my_input/Scan_ExistingRDD_0\"\n",
      "      op: \"Scan_ExistingRDD\"\n",
      "      attr {\n",
      "        key: \"schema\"\n",
      "        value {\n",
      "          s: \"root\\n |-- value: double (nullable = false)\\n\"\n",
      "        }\n",
      "      }\n",
      "      attr {\n",
      "        key: \"simple\"\n",
      "        value {\n",
      "          s: \"Scan ExistingRDD[value#93]\"\n",
      "        }\n",
      "      }\n",
      "      attr {\n",
      "        key: \"verbose\"\n",
      "        value {\n",
      "          s: \"Scan ExistingRDD[value#93]\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "04:14:17 DEBUG:Calling _progress\n",
      "04:14:17 DEBUG:channel: got value <class 'karps.proto.interface_pb2.ComputationStreamResponse'>: session {\n",
      "  id: \"test3\"\n",
      "}\n",
      "computation {\n",
      "  id: \"1\"\n",
      "}\n",
      "results {\n",
      "  results {\n",
      "    local_path {\n",
      "      path: \"my_input_karps_merged_agg\"\n",
      "    }\n",
      "    status: SCHEDULED\n",
      "    spark_stats {\n",
      "      rdd_info {\n",
      "        rdd_id: 6\n",
      "        class_name: \"MapPartitionsRDD\"\n",
      "        repr: \"MapPartitionsRDD[6] at javaRDD at ExecutionItem.scala:56\"\n",
      "        parents: 4\n",
      "        proto {\n",
      "          name: \"my_input_karps_merged_agg/MapPartitionsRDD_6\"\n",
      "          op: \"MapPartitionsRDD\"\n",
      "          input: \"my_input/MapPartitionsRDD_4\"\n",
      "          input: \"^my_input/MapPartitionsRDD_5\"\n",
      "          attr {\n",
      "            key: \"name\"\n",
      "            value {\n",
      "              s: \"MapPartitionsRDD\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      rdd_info {\n",
      "        rdd_id: 7\n",
      "        class_name: \"MapPartitionsRDD\"\n",
      "        repr: \"MapPartitionsRDD[7] at javaRDD at ExecutionItem.scala:56\"\n",
      "        parents: 6\n",
      "        proto {\n",
      "          name: \"my_input_karps_merged_agg/MapPartitionsRDD_7\"\n",
      "          op: \"MapPartitionsRDD\"\n",
      "          input: \"my_input_karps_merged_agg/MapPartitionsRDD_6\"\n",
      "          attr {\n",
      "            key: \"name\"\n",
      "            value {\n",
      "              s: \"MapPartitionsRDD\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      rdd_info {\n",
      "        rdd_id: 8\n",
      "        class_name: \"ShuffledRowRDD\"\n",
      "        repr: \"ShuffledRowRDD[8] at javaRDD at ExecutionItem.scala:56\"\n",
      "        parents: 7\n",
      "        proto {\n",
      "          name: \"my_input_karps_merged_agg/ShuffledRowRDD_8\"\n",
      "          op: \"ShuffledRowRDD\"\n",
      "          input: \"my_input_karps_merged_agg/MapPartitionsRDD_7\"\n",
      "          attr {\n",
      "            key: \"name\"\n",
      "            value {\n",
      "              s: \"ShuffledRowRDD\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      rdd_info {\n",
      "        rdd_id: 9\n",
      "        class_name: \"MapPartitionsRDD\"\n",
      "        repr: \"MapPartitionsRDD[9] at javaRDD at ExecutionItem.scala:56\"\n",
      "        parents: 8\n",
      "        proto {\n",
      "          name: \"my_input_karps_merged_agg/MapPartitionsRDD_9\"\n",
      "          op: \"MapPartitionsRDD\"\n",
      "          input: \"my_input_karps_merged_agg/ShuffledRowRDD_8\"\n",
      "          attr {\n",
      "            key: \"name\"\n",
      "            value {\n",
      "              s: \"MapPartitionsRDD\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      rdd_info {\n",
      "        rdd_id: 10\n",
      "        class_name: \"MapPartitionsRDD\"\n",
      "        repr: \"MapPartitionsRDD[10] at javaRDD at ExecutionItem.scala:56\"\n",
      "        parents: 9\n",
      "        proto {\n",
      "          name: \"my_input_karps_merged_agg/MapPartitionsRDD_10\"\n",
      "          op: \"MapPartitionsRDD\"\n",
      "          input: \"my_input_karps_merged_agg/MapPartitionsRDD_9\"\n",
      "          attr {\n",
      "            key: \"name\"\n",
      "            value {\n",
      "              s: \"MapPartitionsRDD\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      rdd_info {\n",
      "        rdd_id: 11\n",
      "        class_name: \"MapPartitionsRDD\"\n",
      "        repr: \"MapPartitionsRDD[11] at javaRDD at ExecutionItem.scala:56\"\n",
      "        parents: 10\n",
      "        proto {\n",
      "          name: \"my_input_karps_merged_agg/MapPartitionsRDD_11\"\n",
      "          op: \"MapPartitionsRDD\"\n",
      "          input: \"my_input_karps_merged_agg/MapPartitionsRDD_10\"\n",
      "          attr {\n",
      "            key: \"name\"\n",
      "            value {\n",
      "              s: \"MapPartitionsRDD\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      rdd_info {\n",
      "        rdd_id: 12\n",
      "        class_name: \"MapPartitionsRDD\"\n",
      "        repr: \"MapPartitionsRDD[12] at createDataFrame at ExecutionItem.scala:56\"\n",
      "        parents: 11\n",
      "        proto {\n",
      "          name: \"my_input_karps_merged_agg/MapPartitionsRDD_12\"\n",
      "          op: \"MapPartitionsRDD\"\n",
      "          input: \"my_input_karps_merged_agg/MapPartitionsRDD_11\"\n",
      "          attr {\n",
      "            key: \"name\"\n",
      "            value {\n",
      "              s: \"MapPartitionsRDD\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      rdd_info {\n",
      "        rdd_id: 13\n",
      "        class_name: \"MapPartitionsRDD\"\n",
      "        repr: \"MapPartitionsRDD[13] at execute at ExecutionItem.scala:89\"\n",
      "        parents: 12\n",
      "        proto {\n",
      "          name: \"my_input_karps_merged_agg/MapPartitionsRDD_13\"\n",
      "          op: \"MapPartitionsRDD\"\n",
      "          input: \"my_input_karps_merged_agg/MapPartitionsRDD_12\"\n",
      "          attr {\n",
      "            key: \"name\"\n",
      "            value {\n",
      "              s: \"MapPartitionsRDD\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      parsed {\n",
      "        node_id: \"LogicalRDD_0\"\n",
      "        full_name: \"LogicalRDD [_1#128L, _2#129]\"\n",
      "        proto {\n",
      "          name: \"my_input_karps_merged_agg/LogicalRDD_0\"\n",
      "          op: \"LogicalRDD\"\n",
      "          input: \"^my_input/LogicalRDD_0\"\n",
      "          attr {\n",
      "            key: \"schema\"\n",
      "            value {\n",
      "              s: \"root\\n |-- _1: long (nullable = false)\\n |-- _2: double (nullable = true)\\n\"\n",
      "            }\n",
      "          }\n",
      "          attr {\n",
      "            key: \"simple\"\n",
      "            value {\n",
      "              s: \"LogicalRDD [_1#128L, _2#129]\"\n",
      "            }\n",
      "          }\n",
      "          attr {\n",
      "            key: \"verbose\"\n",
      "            value {\n",
      "              s: \"LogicalRDD [_1#128L, _2#129]\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      physical {\n",
      "        node_id: \"Scan_ExistingRDD_0\"\n",
      "        full_name: \"Scan ExistingRDD[_1#128L,_2#129]\"\n",
      "        proto {\n",
      "          name: \"my_input_karps_merged_agg/Scan_ExistingRDD_0\"\n",
      "          op: \"Scan_ExistingRDD\"\n",
      "          input: \"^my_input/Scan_ExistingRDD_0\"\n",
      "          attr {\n",
      "            key: \"schema\"\n",
      "            value {\n",
      "              s: \"root\\n |-- _1: long (nullable = false)\\n |-- _2: double (nullable = true)\\n\"\n",
      "            }\n",
      "          }\n",
      "          attr {\n",
      "            key: \"simple\"\n",
      "            value {\n",
      "              s: \"Scan ExistingRDD[_1#128L,_2#129]\"\n",
      "            }\n",
      "          }\n",
      "          attr {\n",
      "            key: \"verbose\"\n",
      "            value {\n",
      "              s: \"Scan ExistingRDD[_1#128L,_2#129]\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04:14:17 DEBUG:channel: received result for /my_input_karps_merged_agg: local_path {\n",
      "  path: \"my_input_karps_merged_agg\"\n",
      "}\n",
      "status: SCHEDULED\n",
      "spark_stats {\n",
      "  rdd_info {\n",
      "    rdd_id: 6\n",
      "    class_name: \"MapPartitionsRDD\"\n",
      "    repr: \"MapPartitionsRDD[6] at javaRDD at ExecutionItem.scala:56\"\n",
      "    parents: 4\n",
      "    proto {\n",
      "      name: \"my_input_karps_merged_agg/MapPartitionsRDD_6\"\n",
      "      op: \"MapPartitionsRDD\"\n",
      "      input: \"my_input/MapPartitionsRDD_4\"\n",
      "      input: \"^my_input/MapPartitionsRDD_5\"\n",
      "      attr {\n",
      "        key: \"name\"\n",
      "        value {\n",
      "          s: \"MapPartitionsRDD\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  rdd_info {\n",
      "    rdd_id: 7\n",
      "    class_name: \"MapPartitionsRDD\"\n",
      "    repr: \"MapPartitionsRDD[7] at javaRDD at ExecutionItem.scala:56\"\n",
      "    parents: 6\n",
      "    proto {\n",
      "      name: \"my_input_karps_merged_agg/MapPartitionsRDD_7\"\n",
      "      op: \"MapPartitionsRDD\"\n",
      "      input: \"my_input_karps_merged_agg/MapPartitionsRDD_6\"\n",
      "      attr {\n",
      "        key: \"name\"\n",
      "        value {\n",
      "          s: \"MapPartitionsRDD\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  rdd_info {\n",
      "    rdd_id: 8\n",
      "    class_name: \"ShuffledRowRDD\"\n",
      "    repr: \"ShuffledRowRDD[8] at javaRDD at ExecutionItem.scala:56\"\n",
      "    parents: 7\n",
      "    proto {\n",
      "      name: \"my_input_karps_merged_agg/ShuffledRowRDD_8\"\n",
      "      op: \"ShuffledRowRDD\"\n",
      "      input: \"my_input_karps_merged_agg/MapPartitionsRDD_7\"\n",
      "      attr {\n",
      "        key: \"name\"\n",
      "        value {\n",
      "          s: \"ShuffledRowRDD\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  rdd_info {\n",
      "    rdd_id: 9\n",
      "    class_name: \"MapPartitionsRDD\"\n",
      "    repr: \"MapPartitionsRDD[9] at javaRDD at ExecutionItem.scala:56\"\n",
      "    parents: 8\n",
      "    proto {\n",
      "      name: \"my_input_karps_merged_agg/MapPartitionsRDD_9\"\n",
      "      op: \"MapPartitionsRDD\"\n",
      "      input: \"my_input_karps_merged_agg/ShuffledRowRDD_8\"\n",
      "      attr {\n",
      "        key: \"name\"\n",
      "        value {\n",
      "          s: \"MapPartitionsRDD\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  rdd_info {\n",
      "    rdd_id: 10\n",
      "    class_name: \"MapPartitionsRDD\"\n",
      "    repr: \"MapPartitionsRDD[10] at javaRDD at ExecutionItem.scala:56\"\n",
      "    parents: 9\n",
      "    proto {\n",
      "      name: \"my_input_karps_merged_agg/MapPartitionsRDD_10\"\n",
      "      op: \"MapPartitionsRDD\"\n",
      "      input: \"my_input_karps_merged_agg/MapPartitionsRDD_9\"\n",
      "      attr {\n",
      "        key: \"name\"\n",
      "        value {\n",
      "          s: \"MapPartitionsRDD\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  rdd_info {\n",
      "    rdd_id: 11\n",
      "    class_name: \"MapPartitionsRDD\"\n",
      "    repr: \"MapPartitionsRDD[11] at javaRDD at ExecutionItem.scala:56\"\n",
      "    parents: 10\n",
      "    proto {\n",
      "      name: \"my_input_karps_merged_agg/MapPartitionsRDD_11\"\n",
      "      op: \"MapPartitionsRDD\"\n",
      "      input: \"my_input_karps_merged_agg/MapPartitionsRDD_10\"\n",
      "      attr {\n",
      "        key: \"name\"\n",
      "        value {\n",
      "          s: \"MapPartitionsRDD\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  rdd_info {\n",
      "    rdd_id: 12\n",
      "    class_name: \"MapPartitionsRDD\"\n",
      "    repr: \"MapPartitionsRDD[12] at createDataFrame at ExecutionItem.scala:56\"\n",
      "    parents: 11\n",
      "    proto {\n",
      "      name: \"my_input_karps_merged_agg/MapPartitionsRDD_12\"\n",
      "      op: \"MapPartitionsRDD\"\n",
      "      input: \"my_input_karps_merged_agg/MapPartitionsRDD_11\"\n",
      "      attr {\n",
      "        key: \"name\"\n",
      "        value {\n",
      "          s: \"MapPartitionsRDD\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  rdd_info {\n",
      "    rdd_id: 13\n",
      "    class_name: \"MapPartitionsRDD\"\n",
      "    repr: \"MapPartitionsRDD[13] at execute at ExecutionItem.scala:89\"\n",
      "    parents: 12\n",
      "    proto {\n",
      "      name: \"my_input_karps_merged_agg/MapPartitionsRDD_13\"\n",
      "      op: \"MapPartitionsRDD\"\n",
      "      input: \"my_input_karps_merged_agg/MapPartitionsRDD_12\"\n",
      "      attr {\n",
      "        key: \"name\"\n",
      "        value {\n",
      "          s: \"MapPartitionsRDD\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parsed {\n",
      "    node_id: \"LogicalRDD_0\"\n",
      "    full_name: \"LogicalRDD [_1#128L, _2#129]\"\n",
      "    proto {\n",
      "      name: \"my_input_karps_merged_agg/LogicalRDD_0\"\n",
      "      op: \"LogicalRDD\"\n",
      "      input: \"^my_input/LogicalRDD_0\"\n",
      "      attr {\n",
      "        key: \"schema\"\n",
      "        value {\n",
      "          s: \"root\\n |-- _1: long (nullable = false)\\n |-- _2: double (nullable = true)\\n\"\n",
      "        }\n",
      "      }\n",
      "      attr {\n",
      "        key: \"simple\"\n",
      "        value {\n",
      "          s: \"LogicalRDD [_1#128L, _2#129]\"\n",
      "        }\n",
      "      }\n",
      "      attr {\n",
      "        key: \"verbose\"\n",
      "        value {\n",
      "          s: \"LogicalRDD [_1#128L, _2#129]\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  physical {\n",
      "    node_id: \"Scan_ExistingRDD_0\"\n",
      "    full_name: \"Scan ExistingRDD[_1#128L,_2#129]\"\n",
      "    proto {\n",
      "      name: \"my_input_karps_merged_agg/Scan_ExistingRDD_0\"\n",
      "      op: \"Scan_ExistingRDD\"\n",
      "      input: \"^my_input/Scan_ExistingRDD_0\"\n",
      "      attr {\n",
      "        key: \"schema\"\n",
      "        value {\n",
      "          s: \"root\\n |-- _1: long (nullable = false)\\n |-- _2: double (nullable = true)\\n\"\n",
      "        }\n",
      "      }\n",
      "      attr {\n",
      "        key: \"simple\"\n",
      "        value {\n",
      "          s: \"Scan ExistingRDD[_1#128L,_2#129]\"\n",
      "        }\n",
      "      }\n",
      "      attr {\n",
      "        key: \"verbose\"\n",
      "        value {\n",
      "          s: \"Scan ExistingRDD[_1#128L,_2#129]\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "04:14:17 DEBUG:Calling _progress\n",
      "04:14:25 DEBUG:channel: got value <class 'karps.proto.interface_pb2.ComputationStreamResponse'>: session {\n",
      "  id: \"test3\"\n",
      "}\n",
      "computation {\n",
      "  id: \"1\"\n",
      "}\n",
      "results {\n",
      "  results {\n",
      "    local_path {\n",
      "      path: \"my_input_karps_merged_agg\"\n",
      "    }\n",
      "    status: FINISHED_SUCCESS\n",
      "    final_result {\n",
      "      cell {\n",
      "        struct_value {\n",
      "          values {\n",
      "            int_value: 2\n",
      "          }\n",
      "          values {\n",
      "            double_value: 3.0\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      cell_type {\n",
      "        struct_type {\n",
      "          fields {\n",
      "            field_name: \"_1\"\n",
      "            field_type {\n",
      "              basic_type: INT\n",
      "            }\n",
      "          }\n",
      "          fields {\n",
      "            field_name: \"_2\"\n",
      "            field_type {\n",
      "              basic_type: DOUBLE\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    spark_stats {\n",
      "      rdd_info {\n",
      "        rdd_id: 6\n",
      "        class_name: \"MapPartitionsRDD\"\n",
      "        repr: \"MapPartitionsRDD[6] at javaRDD at ExecutionItem.scala:56\"\n",
      "        parents: 4\n",
      "        proto {\n",
      "          name: \"my_input_karps_merged_agg/MapPartitionsRDD_6\"\n",
      "          op: \"MapPartitionsRDD\"\n",
      "          input: \"my_input/MapPartitionsRDD_4\"\n",
      "          input: \"^my_input/MapPartitionsRDD_5\"\n",
      "          attr {\n",
      "            key: \"name\"\n",
      "            value {\n",
      "              s: \"MapPartitionsRDD\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      rdd_info {\n",
      "        rdd_id: 7\n",
      "        class_name: \"MapPartitionsRDD\"\n",
      "        repr: \"MapPartitionsRDD[7] at javaRDD at ExecutionItem.scala:56\"\n",
      "        parents: 6\n",
      "        proto {\n",
      "          name: \"my_input_karps_merged_agg/MapPartitionsRDD_7\"\n",
      "          op: \"MapPartitionsRDD\"\n",
      "          input: \"my_input_karps_merged_agg/MapPartitionsRDD_6\"\n",
      "          attr {\n",
      "            key: \"name\"\n",
      "            value {\n",
      "              s: \"MapPartitionsRDD\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      rdd_info {\n",
      "        rdd_id: 8\n",
      "        class_name: \"ShuffledRowRDD\"\n",
      "        repr: \"ShuffledRowRDD[8] at javaRDD at ExecutionItem.scala:56\"\n",
      "        parents: 7\n",
      "        proto {\n",
      "          name: \"my_input_karps_merged_agg/ShuffledRowRDD_8\"\n",
      "          op: \"ShuffledRowRDD\"\n",
      "          input: \"my_input_karps_merged_agg/MapPartitionsRDD_7\"\n",
      "          attr {\n",
      "            key: \"name\"\n",
      "            value {\n",
      "              s: \"ShuffledRowRDD\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      rdd_info {\n",
      "        rdd_id: 9\n",
      "        class_name: \"MapPartitionsRDD\"\n",
      "        repr: \"MapPartitionsRDD[9] at javaRDD at ExecutionItem.scala:56\"\n",
      "        parents: 8\n",
      "        proto {\n",
      "          name: \"my_input_karps_merged_agg/MapPartitionsRDD_9\"\n",
      "          op: \"MapPartitionsRDD\"\n",
      "          input: \"my_input_karps_merged_agg/ShuffledRowRDD_8\"\n",
      "          attr {\n",
      "            key: \"name\"\n",
      "            value {\n",
      "              s: \"MapPartitionsRDD\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      rdd_info {\n",
      "        rdd_id: 10\n",
      "        class_name: \"MapPartitionsRDD\"\n",
      "        repr: \"MapPartitionsRDD[10] at javaRDD at ExecutionItem.scala:56\"\n",
      "        parents: 9\n",
      "        proto {\n",
      "          name: \"my_input_karps_merged_agg/MapPartitionsRDD_10\"\n",
      "          op: \"MapPartitionsRDD\"\n",
      "          input: \"my_input_karps_merged_agg/MapPartitionsRDD_9\"\n",
      "          attr {\n",
      "            key: \"name\"\n",
      "            value {\n",
      "              s: \"MapPartitionsRDD\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      rdd_info {\n",
      "        rdd_id: 11\n",
      "        class_name: \"MapPartitionsRDD\"\n",
      "        repr: \"MapPartitionsRDD[11] at javaRDD at ExecutionItem.scala:56\"\n",
      "        parents: 10\n",
      "        proto {\n",
      "          name: \"my_input_karps_merged_agg/MapPartitionsRDD_11\"\n",
      "          op: \"MapPartitionsRDD\"\n",
      "          input: \"my_input_karps_merged_agg/MapPartitionsRDD_10\"\n",
      "          attr {\n",
      "            key: \"name\"\n",
      "            value {\n",
      "              s: \"MapPartitionsRDD\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      rdd_info {\n",
      "        rdd_id: 12\n",
      "        class_name: \"MapPartitionsRDD\"\n",
      "        repr: \"MapPartitionsRDD[12] at createDataFrame at ExecutionItem.scala:56\"\n",
      "        parents: 11\n",
      "        proto {\n",
      "          name: \"my_input_karps_merged_agg/MapPartitionsRDD_12\"\n",
      "          op: \"MapPartitionsRDD\"\n",
      "          input: \"my_input_karps_merged_agg/MapPartitionsRDD_11\"\n",
      "          attr {\n",
      "            key: \"name\"\n",
      "            value {\n",
      "              s: \"MapPartitionsRDD\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      rdd_info {\n",
      "        rdd_id: 13\n",
      "        class_name: \"MapPartitionsRDD\"\n",
      "        repr: \"MapPartitionsRDD[13] at execute at ExecutionItem.scala:89\"\n",
      "        parents: 12\n",
      "        proto {\n",
      "          name: \"my_input_karps_merged_agg/MapPartitionsRDD_13\"\n",
      "          op: \"MapPartitionsRDD\"\n",
      "          input: \"my_input_karps_merged_agg/MapPartitionsRDD_12\"\n",
      "          attr {\n",
      "            key: \"name\"\n",
      "            value {\n",
      "              s: \"MapPartitionsRDD\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      parsed {\n",
      "        node_id: \"LogicalRDD_0\"\n",
      "        full_name: \"LogicalRDD [_1#128L, _2#129]\"\n",
      "        proto {\n",
      "          name: \"my_input_karps_merged_agg/LogicalRDD_0\"\n",
      "          op: \"LogicalRDD\"\n",
      "          input: \"^my_input/LogicalRDD_0\"\n",
      "          attr {\n",
      "            key: \"schema\"\n",
      "            value {\n",
      "              s: \"root\\n |-- _1: long (nullable = false)\\n |-- _2: double (nullable = true)\\n\"\n",
      "            }\n",
      "          }\n",
      "          attr {\n",
      "            key: \"simple\"\n",
      "            value {\n",
      "              s: \"LogicalRDD [_1#128L, _2#129]\"\n",
      "            }\n",
      "          }\n",
      "          attr {\n",
      "            key: \"verbose\"\n",
      "            value {\n",
      "              s: \"LogicalRDD [_1#128L, _2#129]\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      physical {\n",
      "        node_id: \"Scan_ExistingRDD_0\"\n",
      "        full_name: \"Scan ExistingRDD[_1#128L,_2#129]\"\n",
      "        proto {\n",
      "          name: \"my_input_karps_merged_agg/Scan_ExistingRDD_0\"\n",
      "          op: \"Scan_ExistingRDD\"\n",
      "          input: \"^my_input/Scan_ExistingRDD_0\"\n",
      "          attr {\n",
      "            key: \"schema\"\n",
      "            value {\n",
      "              s: \"root\\n |-- _1: long (nullable = false)\\n |-- _2: double (nullable = true)\\n\"\n",
      "            }\n",
      "          }\n",
      "          attr {\n",
      "            key: \"simple\"\n",
      "            value {\n",
      "              s: \"Scan ExistingRDD[_1#128L,_2#129]\"\n",
      "            }\n",
      "          }\n",
      "          attr {\n",
      "            key: \"verbose\"\n",
      "            value {\n",
      "              s: \"Scan ExistingRDD[_1#128L,_2#129]\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04:14:25 DEBUG:channel: received result for /my_input_karps_merged_agg: local_path {\n",
      "  path: \"my_input_karps_merged_agg\"\n",
      "}\n",
      "status: FINISHED_SUCCESS\n",
      "final_result {\n",
      "  cell {\n",
      "    struct_value {\n",
      "      values {\n",
      "        int_value: 2\n",
      "      }\n",
      "      values {\n",
      "        double_value: 3.0\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  cell_type {\n",
      "    struct_type {\n",
      "      fields {\n",
      "        field_name: \"_1\"\n",
      "        field_type {\n",
      "          basic_type: INT\n",
      "        }\n",
      "      }\n",
      "      fields {\n",
      "        field_name: \"_2\"\n",
      "        field_type {\n",
      "          basic_type: DOUBLE\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "spark_stats {\n",
      "  rdd_info {\n",
      "    rdd_id: 6\n",
      "    class_name: \"MapPartitionsRDD\"\n",
      "    repr: \"MapPartitionsRDD[6] at javaRDD at ExecutionItem.scala:56\"\n",
      "    parents: 4\n",
      "    proto {\n",
      "      name: \"my_input_karps_merged_agg/MapPartitionsRDD_6\"\n",
      "      op: \"MapPartitionsRDD\"\n",
      "      input: \"my_input/MapPartitionsRDD_4\"\n",
      "      input: \"^my_input/MapPartitionsRDD_5\"\n",
      "      attr {\n",
      "        key: \"name\"\n",
      "        value {\n",
      "          s: \"MapPartitionsRDD\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  rdd_info {\n",
      "    rdd_id: 7\n",
      "    class_name: \"MapPartitionsRDD\"\n",
      "    repr: \"MapPartitionsRDD[7] at javaRDD at ExecutionItem.scala:56\"\n",
      "    parents: 6\n",
      "    proto {\n",
      "      name: \"my_input_karps_merged_agg/MapPartitionsRDD_7\"\n",
      "      op: \"MapPartitionsRDD\"\n",
      "      input: \"my_input_karps_merged_agg/MapPartitionsRDD_6\"\n",
      "      attr {\n",
      "        key: \"name\"\n",
      "        value {\n",
      "          s: \"MapPartitionsRDD\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  rdd_info {\n",
      "    rdd_id: 8\n",
      "    class_name: \"ShuffledRowRDD\"\n",
      "    repr: \"ShuffledRowRDD[8] at javaRDD at ExecutionItem.scala:56\"\n",
      "    parents: 7\n",
      "    proto {\n",
      "      name: \"my_input_karps_merged_agg/ShuffledRowRDD_8\"\n",
      "      op: \"ShuffledRowRDD\"\n",
      "      input: \"my_input_karps_merged_agg/MapPartitionsRDD_7\"\n",
      "      attr {\n",
      "        key: \"name\"\n",
      "        value {\n",
      "          s: \"ShuffledRowRDD\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  rdd_info {\n",
      "    rdd_id: 9\n",
      "    class_name: \"MapPartitionsRDD\"\n",
      "    repr: \"MapPartitionsRDD[9] at javaRDD at ExecutionItem.scala:56\"\n",
      "    parents: 8\n",
      "    proto {\n",
      "      name: \"my_input_karps_merged_agg/MapPartitionsRDD_9\"\n",
      "      op: \"MapPartitionsRDD\"\n",
      "      input: \"my_input_karps_merged_agg/ShuffledRowRDD_8\"\n",
      "      attr {\n",
      "        key: \"name\"\n",
      "        value {\n",
      "          s: \"MapPartitionsRDD\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  rdd_info {\n",
      "    rdd_id: 10\n",
      "    class_name: \"MapPartitionsRDD\"\n",
      "    repr: \"MapPartitionsRDD[10] at javaRDD at ExecutionItem.scala:56\"\n",
      "    parents: 9\n",
      "    proto {\n",
      "      name: \"my_input_karps_merged_agg/MapPartitionsRDD_10\"\n",
      "      op: \"MapPartitionsRDD\"\n",
      "      input: \"my_input_karps_merged_agg/MapPartitionsRDD_9\"\n",
      "      attr {\n",
      "        key: \"name\"\n",
      "        value {\n",
      "          s: \"MapPartitionsRDD\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  rdd_info {\n",
      "    rdd_id: 11\n",
      "    class_name: \"MapPartitionsRDD\"\n",
      "    repr: \"MapPartitionsRDD[11] at javaRDD at ExecutionItem.scala:56\"\n",
      "    parents: 10\n",
      "    proto {\n",
      "      name: \"my_input_karps_merged_agg/MapPartitionsRDD_11\"\n",
      "      op: \"MapPartitionsRDD\"\n",
      "      input: \"my_input_karps_merged_agg/MapPartitionsRDD_10\"\n",
      "      attr {\n",
      "        key: \"name\"\n",
      "        value {\n",
      "          s: \"MapPartitionsRDD\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  rdd_info {\n",
      "    rdd_id: 12\n",
      "    class_name: \"MapPartitionsRDD\"\n",
      "    repr: \"MapPartitionsRDD[12] at createDataFrame at ExecutionItem.scala:56\"\n",
      "    parents: 11\n",
      "    proto {\n",
      "      name: \"my_input_karps_merged_agg/MapPartitionsRDD_12\"\n",
      "      op: \"MapPartitionsRDD\"\n",
      "      input: \"my_input_karps_merged_agg/MapPartitionsRDD_11\"\n",
      "      attr {\n",
      "        key: \"name\"\n",
      "        value {\n",
      "          s: \"MapPartitionsRDD\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  rdd_info {\n",
      "    rdd_id: 13\n",
      "    class_name: \"MapPartitionsRDD\"\n",
      "    repr: \"MapPartitionsRDD[13] at execute at ExecutionItem.scala:89\"\n",
      "    parents: 12\n",
      "    proto {\n",
      "      name: \"my_input_karps_merged_agg/MapPartitionsRDD_13\"\n",
      "      op: \"MapPartitionsRDD\"\n",
      "      input: \"my_input_karps_merged_agg/MapPartitionsRDD_12\"\n",
      "      attr {\n",
      "        key: \"name\"\n",
      "        value {\n",
      "          s: \"MapPartitionsRDD\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parsed {\n",
      "    node_id: \"LogicalRDD_0\"\n",
      "    full_name: \"LogicalRDD [_1#128L, _2#129]\"\n",
      "    proto {\n",
      "      name: \"my_input_karps_merged_agg/LogicalRDD_0\"\n",
      "      op: \"LogicalRDD\"\n",
      "      input: \"^my_input/LogicalRDD_0\"\n",
      "      attr {\n",
      "        key: \"schema\"\n",
      "        value {\n",
      "          s: \"root\\n |-- _1: long (nullable = false)\\n |-- _2: double (nullable = true)\\n\"\n",
      "        }\n",
      "      }\n",
      "      attr {\n",
      "        key: \"simple\"\n",
      "        value {\n",
      "          s: \"LogicalRDD [_1#128L, _2#129]\"\n",
      "        }\n",
      "      }\n",
      "      attr {\n",
      "        key: \"verbose\"\n",
      "        value {\n",
      "          s: \"LogicalRDD [_1#128L, _2#129]\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  physical {\n",
      "    node_id: \"Scan_ExistingRDD_0\"\n",
      "    full_name: \"Scan ExistingRDD[_1#128L,_2#129]\"\n",
      "    proto {\n",
      "      name: \"my_input_karps_merged_agg/Scan_ExistingRDD_0\"\n",
      "      op: \"Scan_ExistingRDD\"\n",
      "      input: \"^my_input/Scan_ExistingRDD_0\"\n",
      "      attr {\n",
      "        key: \"schema\"\n",
      "        value {\n",
      "          s: \"root\\n |-- _1: long (nullable = false)\\n |-- _2: double (nullable = true)\\n\"\n",
      "        }\n",
      "      }\n",
      "      attr {\n",
      "        key: \"simple\"\n",
      "        value {\n",
      "          s: \"Scan ExistingRDD[_1#128L,_2#129]\"\n",
      "        }\n",
      "      }\n",
      "      attr {\n",
      "        key: \"verbose\"\n",
      "        value {\n",
      "          s: \"Scan ExistingRDD[_1#128L,_2#129]\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "04:14:25 DEBUG:Calling _progress\n",
      "04:14:25 DEBUG:channel: got value <class 'karps.proto.interface_pb2.ComputationStreamResponse'>: session {\n",
      "  id: \"test3\"\n",
      "}\n",
      "computation {\n",
      "  id: \"1\"\n",
      "}\n",
      "results {\n",
      "  results {\n",
      "    local_path {\n",
      "      path: \"count1\"\n",
      "    }\n",
      "    status: SCHEDULED\n",
      "    spark_stats {\n",
      "      rdd_info {\n",
      "        rdd_id: 14\n",
      "        class_name: \"ParallelCollectionRDD\"\n",
      "        repr: \"ParallelCollectionRDD[14] at javaRDD at ExecutionItem.scala:56\"\n",
      "        proto {\n",
      "          name: \"count1/ParallelCollectionRDD_14\"\n",
      "          op: \"ParallelCollectionRDD\"\n",
      "          input: \"^my_input_karps_merged_agg/MapPartitionsRDD_13\"\n",
      "          attr {\n",
      "            key: \"name\"\n",
      "            value {\n",
      "              s: \"ParallelCollectionRDD\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      rdd_info {\n",
      "        rdd_id: 15\n",
      "        class_name: \"MapPartitionsRDD\"\n",
      "        repr: \"MapPartitionsRDD[15] at javaRDD at ExecutionItem.scala:56\"\n",
      "        parents: 14\n",
      "        proto {\n",
      "          name: \"count1/MapPartitionsRDD_15\"\n",
      "          op: \"MapPartitionsRDD\"\n",
      "          input: \"count1/ParallelCollectionRDD_14\"\n",
      "          attr {\n",
      "            key: \"name\"\n",
      "            value {\n",
      "              s: \"MapPartitionsRDD\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      rdd_info {\n",
      "        rdd_id: 16\n",
      "        class_name: \"MapPartitionsRDD\"\n",
      "        repr: \"MapPartitionsRDD[16] at javaRDD at ExecutionItem.scala:56\"\n",
      "        parents: 15\n",
      "        proto {\n",
      "          name: \"count1/MapPartitionsRDD_16\"\n",
      "          op: \"MapPartitionsRDD\"\n",
      "          input: \"count1/MapPartitionsRDD_15\"\n",
      "          attr {\n",
      "            key: \"name\"\n",
      "            value {\n",
      "              s: \"MapPartitionsRDD\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      rdd_info {\n",
      "        rdd_id: 17\n",
      "        class_name: \"MapPartitionsRDD\"\n",
      "        repr: \"MapPartitionsRDD[17] at javaRDD at ExecutionItem.scala:56\"\n",
      "        parents: 16\n",
      "        proto {\n",
      "          name: \"count1/MapPartitionsRDD_17\"\n",
      "          op: \"MapPartitionsRDD\"\n",
      "          input: \"count1/MapPartitionsRDD_16\"\n",
      "          attr {\n",
      "            key: \"name\"\n",
      "            value {\n",
      "              s: \"MapPartitionsRDD\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      rdd_info {\n",
      "        rdd_id: 18\n",
      "        class_name: \"MapPartitionsRDD\"\n",
      "        repr: \"MapPartitionsRDD[18] at createDataFrame at ExecutionItem.scala:56\"\n",
      "        parents: 17\n",
      "        proto {\n",
      "          name: \"count1/MapPartitionsRDD_18\"\n",
      "          op: \"MapPartitionsRDD\"\n",
      "          input: \"count1/MapPartitionsRDD_17\"\n",
      "          attr {\n",
      "            key: \"name\"\n",
      "            value {\n",
      "              s: \"MapPartitionsRDD\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      rdd_info {\n",
      "        rdd_id: 19\n",
      "        class_name: \"MapPartitionsRDD\"\n",
      "        repr: \"MapPartitionsRDD[19] at execute at ExecutionItem.scala:89\"\n",
      "        parents: 18\n",
      "        proto {\n",
      "          name: \"count1/MapPartitionsRDD_19\"\n",
      "          op: \"MapPartitionsRDD\"\n",
      "          input: \"count1/MapPartitionsRDD_18\"\n",
      "          attr {\n",
      "            key: \"name\"\n",
      "            value {\n",
      "              s: \"MapPartitionsRDD\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      parsed {\n",
      "        node_id: \"LogicalRDD_0\"\n",
      "        full_name: \"LogicalRDD [value#148]\"\n",
      "        proto {\n",
      "          name: \"count1/LogicalRDD_0\"\n",
      "          op: \"LogicalRDD\"\n",
      "          input: \"^my_input_karps_merged_agg/LogicalRDD_0\"\n",
      "          attr {\n",
      "            key: \"schema\"\n",
      "            value {\n",
      "              s: \"root\\n |-- value: integer (nullable = false)\\n\"\n",
      "            }\n",
      "          }\n",
      "          attr {\n",
      "            key: \"simple\"\n",
      "            value {\n",
      "              s: \"LogicalRDD [value#148]\"\n",
      "            }\n",
      "          }\n",
      "          attr {\n",
      "            key: \"verbose\"\n",
      "            value {\n",
      "              s: \"LogicalRDD [value#148]\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      physical {\n",
      "        node_id: \"Scan_ExistingRDD_0\"\n",
      "        full_name: \"Scan ExistingRDD[value#148]\"\n",
      "        proto {\n",
      "          name: \"count1/Scan_ExistingRDD_0\"\n",
      "          op: \"Scan_ExistingRDD\"\n",
      "          input: \"^my_input_karps_merged_agg/Scan_ExistingRDD_0\"\n",
      "          attr {\n",
      "            key: \"schema\"\n",
      "            value {\n",
      "              s: \"root\\n |-- value: integer (nullable = false)\\n\"\n",
      "            }\n",
      "          }\n",
      "          attr {\n",
      "            key: \"simple\"\n",
      "            value {\n",
      "              s: \"Scan ExistingRDD[value#148]\"\n",
      "            }\n",
      "          }\n",
      "          attr {\n",
      "            key: \"verbose\"\n",
      "            value {\n",
      "              s: \"Scan ExistingRDD[value#148]\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04:14:25 DEBUG:channel: received result for /count1: local_path {\n",
      "  path: \"count1\"\n",
      "}\n",
      "status: SCHEDULED\n",
      "spark_stats {\n",
      "  rdd_info {\n",
      "    rdd_id: 14\n",
      "    class_name: \"ParallelCollectionRDD\"\n",
      "    repr: \"ParallelCollectionRDD[14] at javaRDD at ExecutionItem.scala:56\"\n",
      "    proto {\n",
      "      name: \"count1/ParallelCollectionRDD_14\"\n",
      "      op: \"ParallelCollectionRDD\"\n",
      "      input: \"^my_input_karps_merged_agg/MapPartitionsRDD_13\"\n",
      "      attr {\n",
      "        key: \"name\"\n",
      "        value {\n",
      "          s: \"ParallelCollectionRDD\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  rdd_info {\n",
      "    rdd_id: 15\n",
      "    class_name: \"MapPartitionsRDD\"\n",
      "    repr: \"MapPartitionsRDD[15] at javaRDD at ExecutionItem.scala:56\"\n",
      "    parents: 14\n",
      "    proto {\n",
      "      name: \"count1/MapPartitionsRDD_15\"\n",
      "      op: \"MapPartitionsRDD\"\n",
      "      input: \"count1/ParallelCollectionRDD_14\"\n",
      "      attr {\n",
      "        key: \"name\"\n",
      "        value {\n",
      "          s: \"MapPartitionsRDD\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  rdd_info {\n",
      "    rdd_id: 16\n",
      "    class_name: \"MapPartitionsRDD\"\n",
      "    repr: \"MapPartitionsRDD[16] at javaRDD at ExecutionItem.scala:56\"\n",
      "    parents: 15\n",
      "    proto {\n",
      "      name: \"count1/MapPartitionsRDD_16\"\n",
      "      op: \"MapPartitionsRDD\"\n",
      "      input: \"count1/MapPartitionsRDD_15\"\n",
      "      attr {\n",
      "        key: \"name\"\n",
      "        value {\n",
      "          s: \"MapPartitionsRDD\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  rdd_info {\n",
      "    rdd_id: 17\n",
      "    class_name: \"MapPartitionsRDD\"\n",
      "    repr: \"MapPartitionsRDD[17] at javaRDD at ExecutionItem.scala:56\"\n",
      "    parents: 16\n",
      "    proto {\n",
      "      name: \"count1/MapPartitionsRDD_17\"\n",
      "      op: \"MapPartitionsRDD\"\n",
      "      input: \"count1/MapPartitionsRDD_16\"\n",
      "      attr {\n",
      "        key: \"name\"\n",
      "        value {\n",
      "          s: \"MapPartitionsRDD\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  rdd_info {\n",
      "    rdd_id: 18\n",
      "    class_name: \"MapPartitionsRDD\"\n",
      "    repr: \"MapPartitionsRDD[18] at createDataFrame at ExecutionItem.scala:56\"\n",
      "    parents: 17\n",
      "    proto {\n",
      "      name: \"count1/MapPartitionsRDD_18\"\n",
      "      op: \"MapPartitionsRDD\"\n",
      "      input: \"count1/MapPartitionsRDD_17\"\n",
      "      attr {\n",
      "        key: \"name\"\n",
      "        value {\n",
      "          s: \"MapPartitionsRDD\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  rdd_info {\n",
      "    rdd_id: 19\n",
      "    class_name: \"MapPartitionsRDD\"\n",
      "    repr: \"MapPartitionsRDD[19] at execute at ExecutionItem.scala:89\"\n",
      "    parents: 18\n",
      "    proto {\n",
      "      name: \"count1/MapPartitionsRDD_19\"\n",
      "      op: \"MapPartitionsRDD\"\n",
      "      input: \"count1/MapPartitionsRDD_18\"\n",
      "      attr {\n",
      "        key: \"name\"\n",
      "        value {\n",
      "          s: \"MapPartitionsRDD\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parsed {\n",
      "    node_id: \"LogicalRDD_0\"\n",
      "    full_name: \"LogicalRDD [value#148]\"\n",
      "    proto {\n",
      "      name: \"count1/LogicalRDD_0\"\n",
      "      op: \"LogicalRDD\"\n",
      "      input: \"^my_input_karps_merged_agg/LogicalRDD_0\"\n",
      "      attr {\n",
      "        key: \"schema\"\n",
      "        value {\n",
      "          s: \"root\\n |-- value: integer (nullable = false)\\n\"\n",
      "        }\n",
      "      }\n",
      "      attr {\n",
      "        key: \"simple\"\n",
      "        value {\n",
      "          s: \"LogicalRDD [value#148]\"\n",
      "        }\n",
      "      }\n",
      "      attr {\n",
      "        key: \"verbose\"\n",
      "        value {\n",
      "          s: \"LogicalRDD [value#148]\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  physical {\n",
      "    node_id: \"Scan_ExistingRDD_0\"\n",
      "    full_name: \"Scan ExistingRDD[value#148]\"\n",
      "    proto {\n",
      "      name: \"count1/Scan_ExistingRDD_0\"\n",
      "      op: \"Scan_ExistingRDD\"\n",
      "      input: \"^my_input_karps_merged_agg/Scan_ExistingRDD_0\"\n",
      "      attr {\n",
      "        key: \"schema\"\n",
      "        value {\n",
      "          s: \"root\\n |-- value: integer (nullable = false)\\n\"\n",
      "        }\n",
      "      }\n",
      "      attr {\n",
      "        key: \"simple\"\n",
      "        value {\n",
      "          s: \"Scan ExistingRDD[value#148]\"\n",
      "        }\n",
      "      }\n",
      "      attr {\n",
      "        key: \"verbose\"\n",
      "        value {\n",
      "          s: \"Scan ExistingRDD[value#148]\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "04:14:25 DEBUG:Calling _progress\n",
      "04:14:28 DEBUG:channel: got value <class 'karps.proto.interface_pb2.ComputationStreamResponse'>: session {\n",
      "  id: \"test3\"\n",
      "}\n",
      "computation {\n",
      "  id: \"1\"\n",
      "}\n",
      "results {\n",
      "  results {\n",
      "    local_path {\n",
      "      path: \"count1\"\n",
      "    }\n",
      "    status: FINISHED_SUCCESS\n",
      "    final_result {\n",
      "      cell {\n",
      "        int_value: 2\n",
      "      }\n",
      "      cell_type {\n",
      "        basic_type: INT\n",
      "      }\n",
      "    }\n",
      "    spark_stats {\n",
      "      rdd_info {\n",
      "        rdd_id: 14\n",
      "        class_name: \"ParallelCollectionRDD\"\n",
      "        repr: \"ParallelCollectionRDD[14] at javaRDD at ExecutionItem.scala:56\"\n",
      "        proto {\n",
      "          name: \"count1/ParallelCollectionRDD_14\"\n",
      "          op: \"ParallelCollectionRDD\"\n",
      "          input: \"^my_input_karps_merged_agg/MapPartitionsRDD_13\"\n",
      "          attr {\n",
      "            key: \"name\"\n",
      "            value {\n",
      "              s: \"ParallelCollectionRDD\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      rdd_info {\n",
      "        rdd_id: 15\n",
      "        class_name: \"MapPartitionsRDD\"\n",
      "        repr: \"MapPartitionsRDD[15] at javaRDD at ExecutionItem.scala:56\"\n",
      "        parents: 14\n",
      "        proto {\n",
      "          name: \"count1/MapPartitionsRDD_15\"\n",
      "          op: \"MapPartitionsRDD\"\n",
      "          input: \"count1/ParallelCollectionRDD_14\"\n",
      "          attr {\n",
      "            key: \"name\"\n",
      "            value {\n",
      "              s: \"MapPartitionsRDD\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      rdd_info {\n",
      "        rdd_id: 16\n",
      "        class_name: \"MapPartitionsRDD\"\n",
      "        repr: \"MapPartitionsRDD[16] at javaRDD at ExecutionItem.scala:56\"\n",
      "        parents: 15\n",
      "        proto {\n",
      "          name: \"count1/MapPartitionsRDD_16\"\n",
      "          op: \"MapPartitionsRDD\"\n",
      "          input: \"count1/MapPartitionsRDD_15\"\n",
      "          attr {\n",
      "            key: \"name\"\n",
      "            value {\n",
      "              s: \"MapPartitionsRDD\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      rdd_info {\n",
      "        rdd_id: 17\n",
      "        class_name: \"MapPartitionsRDD\"\n",
      "        repr: \"MapPartitionsRDD[17] at javaRDD at ExecutionItem.scala:56\"\n",
      "        parents: 16\n",
      "        proto {\n",
      "          name: \"count1/MapPartitionsRDD_17\"\n",
      "          op: \"MapPartitionsRDD\"\n",
      "          input: \"count1/MapPartitionsRDD_16\"\n",
      "          attr {\n",
      "            key: \"name\"\n",
      "            value {\n",
      "              s: \"MapPartitionsRDD\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      rdd_info {\n",
      "        rdd_id: 18\n",
      "        class_name: \"MapPartitionsRDD\"\n",
      "        repr: \"MapPartitionsRDD[18] at createDataFrame at ExecutionItem.scala:56\"\n",
      "        parents: 17\n",
      "        proto {\n",
      "          name: \"count1/MapPartitionsRDD_18\"\n",
      "          op: \"MapPartitionsRDD\"\n",
      "          input: \"count1/MapPartitionsRDD_17\"\n",
      "          attr {\n",
      "            key: \"name\"\n",
      "            value {\n",
      "              s: \"MapPartitionsRDD\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      rdd_info {\n",
      "        rdd_id: 19\n",
      "        class_name: \"MapPartitionsRDD\"\n",
      "        repr: \"MapPartitionsRDD[19] at execute at ExecutionItem.scala:89\"\n",
      "        parents: 18\n",
      "        proto {\n",
      "          name: \"count1/MapPartitionsRDD_19\"\n",
      "          op: \"MapPartitionsRDD\"\n",
      "          input: \"count1/MapPartitionsRDD_18\"\n",
      "          attr {\n",
      "            key: \"name\"\n",
      "            value {\n",
      "              s: \"MapPartitionsRDD\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      parsed {\n",
      "        node_id: \"LogicalRDD_0\"\n",
      "        full_name: \"LogicalRDD [value#148]\"\n",
      "        proto {\n",
      "          name: \"count1/LogicalRDD_0\"\n",
      "          op: \"LogicalRDD\"\n",
      "          input: \"^my_input_karps_merged_agg/LogicalRDD_0\"\n",
      "          attr {\n",
      "            key: \"schema\"\n",
      "            value {\n",
      "              s: \"root\\n |-- value: integer (nullable = false)\\n\"\n",
      "            }\n",
      "          }\n",
      "          attr {\n",
      "            key: \"simple\"\n",
      "            value {\n",
      "              s: \"LogicalRDD [value#148]\"\n",
      "            }\n",
      "          }\n",
      "          attr {\n",
      "            key: \"verbose\"\n",
      "            value {\n",
      "              s: \"LogicalRDD [value#148]\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      physical {\n",
      "        node_id: \"Scan_ExistingRDD_0\"\n",
      "        full_name: \"Scan ExistingRDD[value#148]\"\n",
      "        proto {\n",
      "          name: \"count1/Scan_ExistingRDD_0\"\n",
      "          op: \"Scan_ExistingRDD\"\n",
      "          input: \"^my_input_karps_merged_agg/Scan_ExistingRDD_0\"\n",
      "          attr {\n",
      "            key: \"schema\"\n",
      "            value {\n",
      "              s: \"root\\n |-- value: integer (nullable = false)\\n\"\n",
      "            }\n",
      "          }\n",
      "          attr {\n",
      "            key: \"simple\"\n",
      "            value {\n",
      "              s: \"Scan ExistingRDD[value#148]\"\n",
      "            }\n",
      "          }\n",
      "          attr {\n",
      "            key: \"verbose\"\n",
      "            value {\n",
      "              s: \"Scan ExistingRDD[value#148]\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "04:14:28 DEBUG:channel: received result for /count1: local_path {\n",
      "  path: \"count1\"\n",
      "}\n",
      "status: FINISHED_SUCCESS\n",
      "final_result {\n",
      "  cell {\n",
      "    int_value: 2\n",
      "  }\n",
      "  cell_type {\n",
      "    basic_type: INT\n",
      "  }\n",
      "}\n",
      "spark_stats {\n",
      "  rdd_info {\n",
      "    rdd_id: 14\n",
      "    class_name: \"ParallelCollectionRDD\"\n",
      "    repr: \"ParallelCollectionRDD[14] at javaRDD at ExecutionItem.scala:56\"\n",
      "    proto {\n",
      "      name: \"count1/ParallelCollectionRDD_14\"\n",
      "      op: \"ParallelCollectionRDD\"\n",
      "      input: \"^my_input_karps_merged_agg/MapPartitionsRDD_13\"\n",
      "      attr {\n",
      "        key: \"name\"\n",
      "        value {\n",
      "          s: \"ParallelCollectionRDD\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  rdd_info {\n",
      "    rdd_id: 15\n",
      "    class_name: \"MapPartitionsRDD\"\n",
      "    repr: \"MapPartitionsRDD[15] at javaRDD at ExecutionItem.scala:56\"\n",
      "    parents: 14\n",
      "    proto {\n",
      "      name: \"count1/MapPartitionsRDD_15\"\n",
      "      op: \"MapPartitionsRDD\"\n",
      "      input: \"count1/ParallelCollectionRDD_14\"\n",
      "      attr {\n",
      "        key: \"name\"\n",
      "        value {\n",
      "          s: \"MapPartitionsRDD\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  rdd_info {\n",
      "    rdd_id: 16\n",
      "    class_name: \"MapPartitionsRDD\"\n",
      "    repr: \"MapPartitionsRDD[16] at javaRDD at ExecutionItem.scala:56\"\n",
      "    parents: 15\n",
      "    proto {\n",
      "      name: \"count1/MapPartitionsRDD_16\"\n",
      "      op: \"MapPartitionsRDD\"\n",
      "      input: \"count1/MapPartitionsRDD_15\"\n",
      "      attr {\n",
      "        key: \"name\"\n",
      "        value {\n",
      "          s: \"MapPartitionsRDD\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  rdd_info {\n",
      "    rdd_id: 17\n",
      "    class_name: \"MapPartitionsRDD\"\n",
      "    repr: \"MapPartitionsRDD[17] at javaRDD at ExecutionItem.scala:56\"\n",
      "    parents: 16\n",
      "    proto {\n",
      "      name: \"count1/MapPartitionsRDD_17\"\n",
      "      op: \"MapPartitionsRDD\"\n",
      "      input: \"count1/MapPartitionsRDD_16\"\n",
      "      attr {\n",
      "        key: \"name\"\n",
      "        value {\n",
      "          s: \"MapPartitionsRDD\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  rdd_info {\n",
      "    rdd_id: 18\n",
      "    class_name: \"MapPartitionsRDD\"\n",
      "    repr: \"MapPartitionsRDD[18] at createDataFrame at ExecutionItem.scala:56\"\n",
      "    parents: 17\n",
      "    proto {\n",
      "      name: \"count1/MapPartitionsRDD_18\"\n",
      "      op: \"MapPartitionsRDD\"\n",
      "      input: \"count1/MapPartitionsRDD_17\"\n",
      "      attr {\n",
      "        key: \"name\"\n",
      "        value {\n",
      "          s: \"MapPartitionsRDD\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  rdd_info {\n",
      "    rdd_id: 19\n",
      "    class_name: \"MapPartitionsRDD\"\n",
      "    repr: \"MapPartitionsRDD[19] at execute at ExecutionItem.scala:89\"\n",
      "    parents: 18\n",
      "    proto {\n",
      "      name: \"count1/MapPartitionsRDD_19\"\n",
      "      op: \"MapPartitionsRDD\"\n",
      "      input: \"count1/MapPartitionsRDD_18\"\n",
      "      attr {\n",
      "        key: \"name\"\n",
      "        value {\n",
      "          s: \"MapPartitionsRDD\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parsed {\n",
      "    node_id: \"LogicalRDD_0\"\n",
      "    full_name: \"LogicalRDD [value#148]\"\n",
      "    proto {\n",
      "      name: \"count1/LogicalRDD_0\"\n",
      "      op: \"LogicalRDD\"\n",
      "      input: \"^my_input_karps_merged_agg/LogicalRDD_0\"\n",
      "      attr {\n",
      "        key: \"schema\"\n",
      "        value {\n",
      "          s: \"root\\n |-- value: integer (nullable = false)\\n\"\n",
      "        }\n",
      "      }\n",
      "      attr {\n",
      "        key: \"simple\"\n",
      "        value {\n",
      "          s: \"LogicalRDD [value#148]\"\n",
      "        }\n",
      "      }\n",
      "      attr {\n",
      "        key: \"verbose\"\n",
      "        value {\n",
      "          s: \"LogicalRDD [value#148]\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  physical {\n",
      "    node_id: \"Scan_ExistingRDD_0\"\n",
      "    full_name: \"Scan ExistingRDD[value#148]\"\n",
      "    proto {\n",
      "      name: \"count1/Scan_ExistingRDD_0\"\n",
      "      op: \"Scan_ExistingRDD\"\n",
      "      input: \"^my_input_karps_merged_agg/Scan_ExistingRDD_0\"\n",
      "      attr {\n",
      "        key: \"schema\"\n",
      "        value {\n",
      "          s: \"root\\n |-- value: integer (nullable = false)\\n\"\n",
      "        }\n",
      "      }\n",
      "      attr {\n",
      "        key: \"simple\"\n",
      "        value {\n",
      "          s: \"Scan ExistingRDD[value#148]\"\n",
      "        }\n",
      "      }\n",
      "      attr {\n",
      "        key: \"verbose\"\n",
      "        value {\n",
      "          s: \"Scan ExistingRDD[value#148]\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04:14:28 DEBUG:Calling _progress\n",
      "04:14:28 DEBUG:channel: got value <class 'karps.proto.interface_pb2.ComputationStreamResponse'>: session {\n",
      "  id: \"test3\"\n",
      "}\n",
      "computation {\n",
      "  id: \"1\"\n",
      "}\n",
      "results {\n",
      "  results {\n",
      "    local_path {\n",
      "      path: \"sum0\"\n",
      "    }\n",
      "    status: SCHEDULED\n",
      "    spark_stats {\n",
      "      rdd_info {\n",
      "        rdd_id: 20\n",
      "        class_name: \"ParallelCollectionRDD\"\n",
      "        repr: \"ParallelCollectionRDD[20] at javaRDD at ExecutionItem.scala:56\"\n",
      "        proto {\n",
      "          name: \"sum0/ParallelCollectionRDD_20\"\n",
      "          op: \"ParallelCollectionRDD\"\n",
      "          input: \"^my_input_karps_merged_agg/MapPartitionsRDD_13\"\n",
      "          attr {\n",
      "            key: \"name\"\n",
      "            value {\n",
      "              s: \"ParallelCollectionRDD\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      rdd_info {\n",
      "        rdd_id: 21\n",
      "        class_name: \"MapPartitionsRDD\"\n",
      "        repr: \"MapPartitionsRDD[21] at javaRDD at ExecutionItem.scala:56\"\n",
      "        parents: 20\n",
      "        proto {\n",
      "          name: \"sum0/MapPartitionsRDD_21\"\n",
      "          op: \"MapPartitionsRDD\"\n",
      "          input: \"sum0/ParallelCollectionRDD_20\"\n",
      "          attr {\n",
      "            key: \"name\"\n",
      "            value {\n",
      "              s: \"MapPartitionsRDD\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      rdd_info {\n",
      "        rdd_id: 22\n",
      "        class_name: \"MapPartitionsRDD\"\n",
      "        repr: \"MapPartitionsRDD[22] at javaRDD at ExecutionItem.scala:56\"\n",
      "        parents: 21\n",
      "        proto {\n",
      "          name: \"sum0/MapPartitionsRDD_22\"\n",
      "          op: \"MapPartitionsRDD\"\n",
      "          input: \"sum0/MapPartitionsRDD_21\"\n",
      "          attr {\n",
      "            key: \"name\"\n",
      "            value {\n",
      "              s: \"MapPartitionsRDD\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      rdd_info {\n",
      "        rdd_id: 23\n",
      "        class_name: \"MapPartitionsRDD\"\n",
      "        repr: \"MapPartitionsRDD[23] at javaRDD at ExecutionItem.scala:56\"\n",
      "        parents: 22\n",
      "        proto {\n",
      "          name: \"sum0/MapPartitionsRDD_23\"\n",
      "          op: \"MapPartitionsRDD\"\n",
      "          input: \"sum0/MapPartitionsRDD_22\"\n",
      "          attr {\n",
      "            key: \"name\"\n",
      "            value {\n",
      "              s: \"MapPartitionsRDD\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      rdd_info {\n",
      "        rdd_id: 24\n",
      "        class_name: \"MapPartitionsRDD\"\n",
      "        repr: \"MapPartitionsRDD[24] at createDataFrame at ExecutionItem.scala:56\"\n",
      "        parents: 23\n",
      "        proto {\n",
      "          name: \"sum0/MapPartitionsRDD_24\"\n",
      "          op: \"MapPartitionsRDD\"\n",
      "          input: \"sum0/MapPartitionsRDD_23\"\n",
      "          attr {\n",
      "            key: \"name\"\n",
      "            value {\n",
      "              s: \"MapPartitionsRDD\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      rdd_info {\n",
      "        rdd_id: 25\n",
      "        class_name: \"MapPartitionsRDD\"\n",
      "        repr: \"MapPartitionsRDD[25] at execute at ExecutionItem.scala:89\"\n",
      "        parents: 24\n",
      "        proto {\n",
      "          name: \"sum0/MapPartitionsRDD_25\"\n",
      "          op: \"MapPartitionsRDD\"\n",
      "          input: \"sum0/MapPartitionsRDD_24\"\n",
      "          attr {\n",
      "            key: \"name\"\n",
      "            value {\n",
      "              s: \"MapPartitionsRDD\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      parsed {\n",
      "        node_id: \"LogicalRDD_0\"\n",
      "        full_name: \"LogicalRDD [value#166]\"\n",
      "        proto {\n",
      "          name: \"sum0/LogicalRDD_0\"\n",
      "          op: \"LogicalRDD\"\n",
      "          input: \"^my_input_karps_merged_agg/LogicalRDD_0\"\n",
      "          attr {\n",
      "            key: \"schema\"\n",
      "            value {\n",
      "              s: \"root\\n |-- value: double (nullable = false)\\n\"\n",
      "            }\n",
      "          }\n",
      "          attr {\n",
      "            key: \"simple\"\n",
      "            value {\n",
      "              s: \"LogicalRDD [value#166]\"\n",
      "            }\n",
      "          }\n",
      "          attr {\n",
      "            key: \"verbose\"\n",
      "            value {\n",
      "              s: \"LogicalRDD [value#166]\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      physical {\n",
      "        node_id: \"Scan_ExistingRDD_0\"\n",
      "        full_name: \"Scan ExistingRDD[value#166]\"\n",
      "        proto {\n",
      "          name: \"sum0/Scan_ExistingRDD_0\"\n",
      "          op: \"Scan_ExistingRDD\"\n",
      "          input: \"^my_input_karps_merged_agg/Scan_ExistingRDD_0\"\n",
      "          attr {\n",
      "            key: \"schema\"\n",
      "            value {\n",
      "              s: \"root\\n |-- value: double (nullable = false)\\n\"\n",
      "            }\n",
      "          }\n",
      "          attr {\n",
      "            key: \"simple\"\n",
      "            value {\n",
      "              s: \"Scan ExistingRDD[value#166]\"\n",
      "            }\n",
      "          }\n",
      "          attr {\n",
      "            key: \"verbose\"\n",
      "            value {\n",
      "              s: \"Scan ExistingRDD[value#166]\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "04:14:28 DEBUG:channel: received result for /sum0: local_path {\n",
      "  path: \"sum0\"\n",
      "}\n",
      "status: SCHEDULED\n",
      "spark_stats {\n",
      "  rdd_info {\n",
      "    rdd_id: 20\n",
      "    class_name: \"ParallelCollectionRDD\"\n",
      "    repr: \"ParallelCollectionRDD[20] at javaRDD at ExecutionItem.scala:56\"\n",
      "    proto {\n",
      "      name: \"sum0/ParallelCollectionRDD_20\"\n",
      "      op: \"ParallelCollectionRDD\"\n",
      "      input: \"^my_input_karps_merged_agg/MapPartitionsRDD_13\"\n",
      "      attr {\n",
      "        key: \"name\"\n",
      "        value {\n",
      "          s: \"ParallelCollectionRDD\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  rdd_info {\n",
      "    rdd_id: 21\n",
      "    class_name: \"MapPartitionsRDD\"\n",
      "    repr: \"MapPartitionsRDD[21] at javaRDD at ExecutionItem.scala:56\"\n",
      "    parents: 20\n",
      "    proto {\n",
      "      name: \"sum0/MapPartitionsRDD_21\"\n",
      "      op: \"MapPartitionsRDD\"\n",
      "      input: \"sum0/ParallelCollectionRDD_20\"\n",
      "      attr {\n",
      "        key: \"name\"\n",
      "        value {\n",
      "          s: \"MapPartitionsRDD\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  rdd_info {\n",
      "    rdd_id: 22\n",
      "    class_name: \"MapPartitionsRDD\"\n",
      "    repr: \"MapPartitionsRDD[22] at javaRDD at ExecutionItem.scala:56\"\n",
      "    parents: 21\n",
      "    proto {\n",
      "      name: \"sum0/MapPartitionsRDD_22\"\n",
      "      op: \"MapPartitionsRDD\"\n",
      "      input: \"sum0/MapPartitionsRDD_21\"\n",
      "      attr {\n",
      "        key: \"name\"\n",
      "        value {\n",
      "          s: \"MapPartitionsRDD\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  rdd_info {\n",
      "    rdd_id: 23\n",
      "    class_name: \"MapPartitionsRDD\"\n",
      "    repr: \"MapPartitionsRDD[23] at javaRDD at ExecutionItem.scala:56\"\n",
      "    parents: 22\n",
      "    proto {\n",
      "      name: \"sum0/MapPartitionsRDD_23\"\n",
      "      op: \"MapPartitionsRDD\"\n",
      "      input: \"sum0/MapPartitionsRDD_22\"\n",
      "      attr {\n",
      "        key: \"name\"\n",
      "        value {\n",
      "          s: \"MapPartitionsRDD\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  rdd_info {\n",
      "    rdd_id: 24\n",
      "    class_name: \"MapPartitionsRDD\"\n",
      "    repr: \"MapPartitionsRDD[24] at createDataFrame at ExecutionItem.scala:56\"\n",
      "    parents: 23\n",
      "    proto {\n",
      "      name: \"sum0/MapPartitionsRDD_24\"\n",
      "      op: \"MapPartitionsRDD\"\n",
      "      input: \"sum0/MapPartitionsRDD_23\"\n",
      "      attr {\n",
      "        key: \"name\"\n",
      "        value {\n",
      "          s: \"MapPartitionsRDD\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  rdd_info {\n",
      "    rdd_id: 25\n",
      "    class_name: \"MapPartitionsRDD\"\n",
      "    repr: \"MapPartitionsRDD[25] at execute at ExecutionItem.scala:89\"\n",
      "    parents: 24\n",
      "    proto {\n",
      "      name: \"sum0/MapPartitionsRDD_25\"\n",
      "      op: \"MapPartitionsRDD\"\n",
      "      input: \"sum0/MapPartitionsRDD_24\"\n",
      "      attr {\n",
      "        key: \"name\"\n",
      "        value {\n",
      "          s: \"MapPartitionsRDD\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parsed {\n",
      "    node_id: \"LogicalRDD_0\"\n",
      "    full_name: \"LogicalRDD [value#166]\"\n",
      "    proto {\n",
      "      name: \"sum0/LogicalRDD_0\"\n",
      "      op: \"LogicalRDD\"\n",
      "      input: \"^my_input_karps_merged_agg/LogicalRDD_0\"\n",
      "      attr {\n",
      "        key: \"schema\"\n",
      "        value {\n",
      "          s: \"root\\n |-- value: double (nullable = false)\\n\"\n",
      "        }\n",
      "      }\n",
      "      attr {\n",
      "        key: \"simple\"\n",
      "        value {\n",
      "          s: \"LogicalRDD [value#166]\"\n",
      "        }\n",
      "      }\n",
      "      attr {\n",
      "        key: \"verbose\"\n",
      "        value {\n",
      "          s: \"LogicalRDD [value#166]\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  physical {\n",
      "    node_id: \"Scan_ExistingRDD_0\"\n",
      "    full_name: \"Scan ExistingRDD[value#166]\"\n",
      "    proto {\n",
      "      name: \"sum0/Scan_ExistingRDD_0\"\n",
      "      op: \"Scan_ExistingRDD\"\n",
      "      input: \"^my_input_karps_merged_agg/Scan_ExistingRDD_0\"\n",
      "      attr {\n",
      "        key: \"schema\"\n",
      "        value {\n",
      "          s: \"root\\n |-- value: double (nullable = false)\\n\"\n",
      "        }\n",
      "      }\n",
      "      attr {\n",
      "        key: \"simple\"\n",
      "        value {\n",
      "          s: \"Scan ExistingRDD[value#166]\"\n",
      "        }\n",
      "      }\n",
      "      attr {\n",
      "        key: \"verbose\"\n",
      "        value {\n",
      "          s: \"Scan ExistingRDD[value#166]\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "04:14:28 DEBUG:Calling _progress\n",
      "04:14:28 DEBUG:channel: got value <class 'karps.proto.interface_pb2.ComputationStreamResponse'>: session {\n",
      "  id: \"test3\"\n",
      "}\n",
      "computation {\n",
      "  id: \"1\"\n",
      "}\n",
      "results {\n",
      "  results {\n",
      "    local_path {\n",
      "      path: \"sum0\"\n",
      "    }\n",
      "    status: FINISHED_SUCCESS\n",
      "    final_result {\n",
      "      cell {\n",
      "        double_value: 3.0\n",
      "      }\n",
      "      cell_type {\n",
      "        basic_type: DOUBLE\n",
      "      }\n",
      "    }\n",
      "    spark_stats {\n",
      "      rdd_info {\n",
      "        rdd_id: 20\n",
      "        class_name: \"ParallelCollectionRDD\"\n",
      "        repr: \"ParallelCollectionRDD[20] at javaRDD at ExecutionItem.scala:56\"\n",
      "        proto {\n",
      "          name: \"sum0/ParallelCollectionRDD_20\"\n",
      "          op: \"ParallelCollectionRDD\"\n",
      "          input: \"^my_input_karps_merged_agg/MapPartitionsRDD_13\"\n",
      "          attr {\n",
      "            key: \"name\"\n",
      "            value {\n",
      "              s: \"ParallelCollectionRDD\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      rdd_info {\n",
      "        rdd_id: 21\n",
      "        class_name: \"MapPartitionsRDD\"\n",
      "        repr: \"MapPartitionsRDD[21] at javaRDD at ExecutionItem.scala:56\"\n",
      "        parents: 20\n",
      "        proto {\n",
      "          name: \"sum0/MapPartitionsRDD_21\"\n",
      "          op: \"MapPartitionsRDD\"\n",
      "          input: \"sum0/ParallelCollectionRDD_20\"\n",
      "          attr {\n",
      "            key: \"name\"\n",
      "            value {\n",
      "              s: \"MapPartitionsRDD\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      rdd_info {\n",
      "        rdd_id: 22\n",
      "        class_name: \"MapPartitionsRDD\"\n",
      "        repr: \"MapPartitionsRDD[22] at javaRDD at ExecutionItem.scala:56\"\n",
      "        parents: 21\n",
      "        proto {\n",
      "          name: \"sum0/MapPartitionsRDD_22\"\n",
      "          op: \"MapPartitionsRDD\"\n",
      "          input: \"sum0/MapPartitionsRDD_21\"\n",
      "          attr {\n",
      "            key: \"name\"\n",
      "            value {\n",
      "              s: \"MapPartitionsRDD\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      rdd_info {\n",
      "        rdd_id: 23\n",
      "        class_name: \"MapPartitionsRDD\"\n",
      "        repr: \"MapPartitionsRDD[23] at javaRDD at ExecutionItem.scala:56\"\n",
      "        parents: 22\n",
      "        proto {\n",
      "          name: \"sum0/MapPartitionsRDD_23\"\n",
      "          op: \"MapPartitionsRDD\"\n",
      "          input: \"sum0/MapPartitionsRDD_22\"\n",
      "          attr {\n",
      "            key: \"name\"\n",
      "            value {\n",
      "              s: \"MapPartitionsRDD\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      rdd_info {\n",
      "        rdd_id: 24\n",
      "        class_name: \"MapPartitionsRDD\"\n",
      "        repr: \"MapPartitionsRDD[24] at createDataFrame at ExecutionItem.scala:56\"\n",
      "        parents: 23\n",
      "        proto {\n",
      "          name: \"sum0/MapPartitionsRDD_24\"\n",
      "          op: \"MapPartitionsRDD\"\n",
      "          input: \"sum0/MapPartitionsRDD_23\"\n",
      "          attr {\n",
      "            key: \"name\"\n",
      "            value {\n",
      "              s: \"MapPartitionsRDD\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      rdd_info {\n",
      "        rdd_id: 25\n",
      "        class_name: \"MapPartitionsRDD\"\n",
      "        repr: \"MapPartitionsRDD[25] at execute at ExecutionItem.scala:89\"\n",
      "        parents: 24\n",
      "        proto {\n",
      "          name: \"sum0/MapPartitionsRDD_25\"\n",
      "          op: \"MapPartitionsRDD\"\n",
      "          input: \"sum0/MapPartitionsRDD_24\"\n",
      "          attr {\n",
      "            key: \"name\"\n",
      "            value {\n",
      "              s: \"MapPartitionsRDD\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      parsed {\n",
      "        node_id: \"LogicalRDD_0\"\n",
      "        full_name: \"LogicalRDD [value#166]\"\n",
      "        proto {\n",
      "          name: \"sum0/LogicalRDD_0\"\n",
      "          op: \"LogicalRDD\"\n",
      "          input: \"^my_input_karps_merged_agg/LogicalRDD_0\"\n",
      "          attr {\n",
      "            key: \"schema\"\n",
      "            value {\n",
      "              s: \"root\\n |-- value: double (nullable = false)\\n\"\n",
      "            }\n",
      "          }\n",
      "          attr {\n",
      "            key: \"simple\"\n",
      "            value {\n",
      "              s: \"LogicalRDD [value#166]\"\n",
      "            }\n",
      "          }\n",
      "          attr {\n",
      "            key: \"verbose\"\n",
      "            value {\n",
      "              s: \"LogicalRDD [value#166]\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      physical {\n",
      "        node_id: \"Scan_ExistingRDD_0\"\n",
      "        full_name: \"Scan ExistingRDD[value#166]\"\n",
      "        proto {\n",
      "          name: \"sum0/Scan_ExistingRDD_0\"\n",
      "          op: \"Scan_ExistingRDD\"\n",
      "          input: \"^my_input_karps_merged_agg/Scan_ExistingRDD_0\"\n",
      "          attr {\n",
      "            key: \"schema\"\n",
      "            value {\n",
      "              s: \"root\\n |-- value: double (nullable = false)\\n\"\n",
      "            }\n",
      "          }\n",
      "          attr {\n",
      "            key: \"simple\"\n",
      "            value {\n",
      "              s: \"Scan ExistingRDD[value#166]\"\n",
      "            }\n",
      "          }\n",
      "          attr {\n",
      "            key: \"verbose\"\n",
      "            value {\n",
      "              s: \"Scan ExistingRDD[value#166]\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04:14:28 DEBUG:channel: received result for /sum0: local_path {\n",
      "  path: \"sum0\"\n",
      "}\n",
      "status: FINISHED_SUCCESS\n",
      "final_result {\n",
      "  cell {\n",
      "    double_value: 3.0\n",
      "  }\n",
      "  cell_type {\n",
      "    basic_type: DOUBLE\n",
      "  }\n",
      "}\n",
      "spark_stats {\n",
      "  rdd_info {\n",
      "    rdd_id: 20\n",
      "    class_name: \"ParallelCollectionRDD\"\n",
      "    repr: \"ParallelCollectionRDD[20] at javaRDD at ExecutionItem.scala:56\"\n",
      "    proto {\n",
      "      name: \"sum0/ParallelCollectionRDD_20\"\n",
      "      op: \"ParallelCollectionRDD\"\n",
      "      input: \"^my_input_karps_merged_agg/MapPartitionsRDD_13\"\n",
      "      attr {\n",
      "        key: \"name\"\n",
      "        value {\n",
      "          s: \"ParallelCollectionRDD\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  rdd_info {\n",
      "    rdd_id: 21\n",
      "    class_name: \"MapPartitionsRDD\"\n",
      "    repr: \"MapPartitionsRDD[21] at javaRDD at ExecutionItem.scala:56\"\n",
      "    parents: 20\n",
      "    proto {\n",
      "      name: \"sum0/MapPartitionsRDD_21\"\n",
      "      op: \"MapPartitionsRDD\"\n",
      "      input: \"sum0/ParallelCollectionRDD_20\"\n",
      "      attr {\n",
      "        key: \"name\"\n",
      "        value {\n",
      "          s: \"MapPartitionsRDD\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  rdd_info {\n",
      "    rdd_id: 22\n",
      "    class_name: \"MapPartitionsRDD\"\n",
      "    repr: \"MapPartitionsRDD[22] at javaRDD at ExecutionItem.scala:56\"\n",
      "    parents: 21\n",
      "    proto {\n",
      "      name: \"sum0/MapPartitionsRDD_22\"\n",
      "      op: \"MapPartitionsRDD\"\n",
      "      input: \"sum0/MapPartitionsRDD_21\"\n",
      "      attr {\n",
      "        key: \"name\"\n",
      "        value {\n",
      "          s: \"MapPartitionsRDD\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  rdd_info {\n",
      "    rdd_id: 23\n",
      "    class_name: \"MapPartitionsRDD\"\n",
      "    repr: \"MapPartitionsRDD[23] at javaRDD at ExecutionItem.scala:56\"\n",
      "    parents: 22\n",
      "    proto {\n",
      "      name: \"sum0/MapPartitionsRDD_23\"\n",
      "      op: \"MapPartitionsRDD\"\n",
      "      input: \"sum0/MapPartitionsRDD_22\"\n",
      "      attr {\n",
      "        key: \"name\"\n",
      "        value {\n",
      "          s: \"MapPartitionsRDD\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  rdd_info {\n",
      "    rdd_id: 24\n",
      "    class_name: \"MapPartitionsRDD\"\n",
      "    repr: \"MapPartitionsRDD[24] at createDataFrame at ExecutionItem.scala:56\"\n",
      "    parents: 23\n",
      "    proto {\n",
      "      name: \"sum0/MapPartitionsRDD_24\"\n",
      "      op: \"MapPartitionsRDD\"\n",
      "      input: \"sum0/MapPartitionsRDD_23\"\n",
      "      attr {\n",
      "        key: \"name\"\n",
      "        value {\n",
      "          s: \"MapPartitionsRDD\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  rdd_info {\n",
      "    rdd_id: 25\n",
      "    class_name: \"MapPartitionsRDD\"\n",
      "    repr: \"MapPartitionsRDD[25] at execute at ExecutionItem.scala:89\"\n",
      "    parents: 24\n",
      "    proto {\n",
      "      name: \"sum0/MapPartitionsRDD_25\"\n",
      "      op: \"MapPartitionsRDD\"\n",
      "      input: \"sum0/MapPartitionsRDD_24\"\n",
      "      attr {\n",
      "        key: \"name\"\n",
      "        value {\n",
      "          s: \"MapPartitionsRDD\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parsed {\n",
      "    node_id: \"LogicalRDD_0\"\n",
      "    full_name: \"LogicalRDD [value#166]\"\n",
      "    proto {\n",
      "      name: \"sum0/LogicalRDD_0\"\n",
      "      op: \"LogicalRDD\"\n",
      "      input: \"^my_input_karps_merged_agg/LogicalRDD_0\"\n",
      "      attr {\n",
      "        key: \"schema\"\n",
      "        value {\n",
      "          s: \"root\\n |-- value: double (nullable = false)\\n\"\n",
      "        }\n",
      "      }\n",
      "      attr {\n",
      "        key: \"simple\"\n",
      "        value {\n",
      "          s: \"LogicalRDD [value#166]\"\n",
      "        }\n",
      "      }\n",
      "      attr {\n",
      "        key: \"verbose\"\n",
      "        value {\n",
      "          s: \"LogicalRDD [value#166]\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  physical {\n",
      "    node_id: \"Scan_ExistingRDD_0\"\n",
      "    full_name: \"Scan ExistingRDD[value#166]\"\n",
      "    proto {\n",
      "      name: \"sum0/Scan_ExistingRDD_0\"\n",
      "      op: \"Scan_ExistingRDD\"\n",
      "      input: \"^my_input_karps_merged_agg/Scan_ExistingRDD_0\"\n",
      "      attr {\n",
      "        key: \"schema\"\n",
      "        value {\n",
      "          s: \"root\\n |-- value: double (nullable = false)\\n\"\n",
      "        }\n",
      "      }\n",
      "      attr {\n",
      "        key: \"simple\"\n",
      "        value {\n",
      "          s: \"Scan ExistingRDD[value#166]\"\n",
      "        }\n",
      "      }\n",
      "      attr {\n",
      "        key: \"verbose\"\n",
      "        value {\n",
      "          s: \"Scan ExistingRDD[value#166]\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "04:14:28 DEBUG:Calling _progress\n",
      "04:14:28 DEBUG:channel: got value <class 'karps.proto.interface_pb2.ComputationStreamResponse'>: session {\n",
      "  id: \"test3\"\n",
      "}\n",
      "computation {\n",
      "  id: \"1\"\n",
      "}\n",
      "results {\n",
      "  results {\n",
      "    local_path {\n",
      "      path: \"cast_double2\"\n",
      "    }\n",
      "    status: SCHEDULED\n",
      "    spark_stats {\n",
      "      rdd_info {\n",
      "        rdd_id: 26\n",
      "        class_name: \"ParallelCollectionRDD\"\n",
      "        repr: \"ParallelCollectionRDD[26] at javaRDD at ExecutionItem.scala:56\"\n",
      "        proto {\n",
      "          name: \"cast_double2/ParallelCollectionRDD_26\"\n",
      "          op: \"ParallelCollectionRDD\"\n",
      "          input: \"^count1/MapPartitionsRDD_19\"\n",
      "          attr {\n",
      "            key: \"name\"\n",
      "            value {\n",
      "              s: \"ParallelCollectionRDD\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      rdd_info {\n",
      "        rdd_id: 27\n",
      "        class_name: \"MapPartitionsRDD\"\n",
      "        repr: \"MapPartitionsRDD[27] at javaRDD at ExecutionItem.scala:56\"\n",
      "        parents: 26\n",
      "        proto {\n",
      "          name: \"cast_double2/MapPartitionsRDD_27\"\n",
      "          op: \"MapPartitionsRDD\"\n",
      "          input: \"cast_double2/ParallelCollectionRDD_26\"\n",
      "          attr {\n",
      "            key: \"name\"\n",
      "            value {\n",
      "              s: \"MapPartitionsRDD\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      rdd_info {\n",
      "        rdd_id: 28\n",
      "        class_name: \"MapPartitionsRDD\"\n",
      "        repr: \"MapPartitionsRDD[28] at javaRDD at ExecutionItem.scala:56\"\n",
      "        parents: 27\n",
      "        proto {\n",
      "          name: \"cast_double2/MapPartitionsRDD_28\"\n",
      "          op: \"MapPartitionsRDD\"\n",
      "          input: \"cast_double2/MapPartitionsRDD_27\"\n",
      "          attr {\n",
      "            key: \"name\"\n",
      "            value {\n",
      "              s: \"MapPartitionsRDD\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      rdd_info {\n",
      "        rdd_id: 29\n",
      "        class_name: \"MapPartitionsRDD\"\n",
      "        repr: \"MapPartitionsRDD[29] at javaRDD at ExecutionItem.scala:56\"\n",
      "        parents: 28\n",
      "        proto {\n",
      "          name: \"cast_double2/MapPartitionsRDD_29\"\n",
      "          op: \"MapPartitionsRDD\"\n",
      "          input: \"cast_double2/MapPartitionsRDD_28\"\n",
      "          attr {\n",
      "            key: \"name\"\n",
      "            value {\n",
      "              s: \"MapPartitionsRDD\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      rdd_info {\n",
      "        rdd_id: 30\n",
      "        class_name: \"MapPartitionsRDD\"\n",
      "        repr: \"MapPartitionsRDD[30] at createDataFrame at ExecutionItem.scala:56\"\n",
      "        parents: 29\n",
      "        proto {\n",
      "          name: \"cast_double2/MapPartitionsRDD_30\"\n",
      "          op: \"MapPartitionsRDD\"\n",
      "          input: \"cast_double2/MapPartitionsRDD_29\"\n",
      "          attr {\n",
      "            key: \"name\"\n",
      "            value {\n",
      "              s: \"MapPartitionsRDD\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      rdd_info {\n",
      "        rdd_id: 31\n",
      "        class_name: \"MapPartitionsRDD\"\n",
      "        repr: \"MapPartitionsRDD[31] at execute at ExecutionItem.scala:89\"\n",
      "        parents: 30\n",
      "        proto {\n",
      "          name: \"cast_double2/MapPartitionsRDD_31\"\n",
      "          op: \"MapPartitionsRDD\"\n",
      "          input: \"cast_double2/MapPartitionsRDD_30\"\n",
      "          attr {\n",
      "            key: \"name\"\n",
      "            value {\n",
      "              s: \"MapPartitionsRDD\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      parsed {\n",
      "        node_id: \"LogicalRDD_0\"\n",
      "        full_name: \"LogicalRDD [value#185]\"\n",
      "        proto {\n",
      "          name: \"cast_double2/LogicalRDD_0\"\n",
      "          op: \"LogicalRDD\"\n",
      "          input: \"^count1/LogicalRDD_0\"\n",
      "          attr {\n",
      "            key: \"schema\"\n",
      "            value {\n",
      "              s: \"root\\n |-- value: double (nullable = false)\\n\"\n",
      "            }\n",
      "          }\n",
      "          attr {\n",
      "            key: \"simple\"\n",
      "            value {\n",
      "              s: \"LogicalRDD [value#185]\"\n",
      "            }\n",
      "          }\n",
      "          attr {\n",
      "            key: \"verbose\"\n",
      "            value {\n",
      "              s: \"LogicalRDD [value#185]\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      physical {\n",
      "        node_id: \"Scan_ExistingRDD_0\"\n",
      "        full_name: \"Scan ExistingRDD[value#185]\"\n",
      "        proto {\n",
      "          name: \"cast_double2/Scan_ExistingRDD_0\"\n",
      "          op: \"Scan_ExistingRDD\"\n",
      "          input: \"^count1/Scan_ExistingRDD_0\"\n",
      "          attr {\n",
      "            key: \"schema\"\n",
      "            value {\n",
      "              s: \"root\\n |-- value: double (nullable = false)\\n\"\n",
      "            }\n",
      "          }\n",
      "          attr {\n",
      "            key: \"simple\"\n",
      "            value {\n",
      "              s: \"Scan ExistingRDD[value#185]\"\n",
      "            }\n",
      "          }\n",
      "          attr {\n",
      "            key: \"verbose\"\n",
      "            value {\n",
      "              s: \"Scan ExistingRDD[value#185]\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "04:14:28 DEBUG:channel: received result for /cast_double2: local_path {\n",
      "  path: \"cast_double2\"\n",
      "}\n",
      "status: SCHEDULED\n",
      "spark_stats {\n",
      "  rdd_info {\n",
      "    rdd_id: 26\n",
      "    class_name: \"ParallelCollectionRDD\"\n",
      "    repr: \"ParallelCollectionRDD[26] at javaRDD at ExecutionItem.scala:56\"\n",
      "    proto {\n",
      "      name: \"cast_double2/ParallelCollectionRDD_26\"\n",
      "      op: \"ParallelCollectionRDD\"\n",
      "      input: \"^count1/MapPartitionsRDD_19\"\n",
      "      attr {\n",
      "        key: \"name\"\n",
      "        value {\n",
      "          s: \"ParallelCollectionRDD\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  rdd_info {\n",
      "    rdd_id: 27\n",
      "    class_name: \"MapPartitionsRDD\"\n",
      "    repr: \"MapPartitionsRDD[27] at javaRDD at ExecutionItem.scala:56\"\n",
      "    parents: 26\n",
      "    proto {\n",
      "      name: \"cast_double2/MapPartitionsRDD_27\"\n",
      "      op: \"MapPartitionsRDD\"\n",
      "      input: \"cast_double2/ParallelCollectionRDD_26\"\n",
      "      attr {\n",
      "        key: \"name\"\n",
      "        value {\n",
      "          s: \"MapPartitionsRDD\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  rdd_info {\n",
      "    rdd_id: 28\n",
      "    class_name: \"MapPartitionsRDD\"\n",
      "    repr: \"MapPartitionsRDD[28] at javaRDD at ExecutionItem.scala:56\"\n",
      "    parents: 27\n",
      "    proto {\n",
      "      name: \"cast_double2/MapPartitionsRDD_28\"\n",
      "      op: \"MapPartitionsRDD\"\n",
      "      input: \"cast_double2/MapPartitionsRDD_27\"\n",
      "      attr {\n",
      "        key: \"name\"\n",
      "        value {\n",
      "          s: \"MapPartitionsRDD\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  rdd_info {\n",
      "    rdd_id: 29\n",
      "    class_name: \"MapPartitionsRDD\"\n",
      "    repr: \"MapPartitionsRDD[29] at javaRDD at ExecutionItem.scala:56\"\n",
      "    parents: 28\n",
      "    proto {\n",
      "      name: \"cast_double2/MapPartitionsRDD_29\"\n",
      "      op: \"MapPartitionsRDD\"\n",
      "      input: \"cast_double2/MapPartitionsRDD_28\"\n",
      "      attr {\n",
      "        key: \"name\"\n",
      "        value {\n",
      "          s: \"MapPartitionsRDD\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  rdd_info {\n",
      "    rdd_id: 30\n",
      "    class_name: \"MapPartitionsRDD\"\n",
      "    repr: \"MapPartitionsRDD[30] at createDataFrame at ExecutionItem.scala:56\"\n",
      "    parents: 29\n",
      "    proto {\n",
      "      name: \"cast_double2/MapPartitionsRDD_30\"\n",
      "      op: \"MapPartitionsRDD\"\n",
      "      input: \"cast_double2/MapPartitionsRDD_29\"\n",
      "      attr {\n",
      "        key: \"name\"\n",
      "        value {\n",
      "          s: \"MapPartitionsRDD\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  rdd_info {\n",
      "    rdd_id: 31\n",
      "    class_name: \"MapPartitionsRDD\"\n",
      "    repr: \"MapPartitionsRDD[31] at execute at ExecutionItem.scala:89\"\n",
      "    parents: 30\n",
      "    proto {\n",
      "      name: \"cast_double2/MapPartitionsRDD_31\"\n",
      "      op: \"MapPartitionsRDD\"\n",
      "      input: \"cast_double2/MapPartitionsRDD_30\"\n",
      "      attr {\n",
      "        key: \"name\"\n",
      "        value {\n",
      "          s: \"MapPartitionsRDD\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parsed {\n",
      "    node_id: \"LogicalRDD_0\"\n",
      "    full_name: \"LogicalRDD [value#185]\"\n",
      "    proto {\n",
      "      name: \"cast_double2/LogicalRDD_0\"\n",
      "      op: \"LogicalRDD\"\n",
      "      input: \"^count1/LogicalRDD_0\"\n",
      "      attr {\n",
      "        key: \"schema\"\n",
      "        value {\n",
      "          s: \"root\\n |-- value: double (nullable = false)\\n\"\n",
      "        }\n",
      "      }\n",
      "      attr {\n",
      "        key: \"simple\"\n",
      "        value {\n",
      "          s: \"LogicalRDD [value#185]\"\n",
      "        }\n",
      "      }\n",
      "      attr {\n",
      "        key: \"verbose\"\n",
      "        value {\n",
      "          s: \"LogicalRDD [value#185]\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  physical {\n",
      "    node_id: \"Scan_ExistingRDD_0\"\n",
      "    full_name: \"Scan ExistingRDD[value#185]\"\n",
      "    proto {\n",
      "      name: \"cast_double2/Scan_ExistingRDD_0\"\n",
      "      op: \"Scan_ExistingRDD\"\n",
      "      input: \"^count1/Scan_ExistingRDD_0\"\n",
      "      attr {\n",
      "        key: \"schema\"\n",
      "        value {\n",
      "          s: \"root\\n |-- value: double (nullable = false)\\n\"\n",
      "        }\n",
      "      }\n",
      "      attr {\n",
      "        key: \"simple\"\n",
      "        value {\n",
      "          s: \"Scan ExistingRDD[value#185]\"\n",
      "        }\n",
      "      }\n",
      "      attr {\n",
      "        key: \"verbose\"\n",
      "        value {\n",
      "          s: \"Scan ExistingRDD[value#185]\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04:14:28 DEBUG:Calling _progress\n",
      "04:14:31 DEBUG:channel: got value <class 'karps.proto.interface_pb2.ComputationStreamResponse'>: session {\n",
      "  id: \"test3\"\n",
      "}\n",
      "computation {\n",
      "  id: \"1\"\n",
      "}\n",
      "results {\n",
      "  results {\n",
      "    local_path {\n",
      "      path: \"cast_double2\"\n",
      "    }\n",
      "    status: FINISHED_SUCCESS\n",
      "    final_result {\n",
      "      cell {\n",
      "        double_value: 2.0\n",
      "      }\n",
      "      cell_type {\n",
      "        basic_type: DOUBLE\n",
      "      }\n",
      "    }\n",
      "    spark_stats {\n",
      "      rdd_info {\n",
      "        rdd_id: 26\n",
      "        class_name: \"ParallelCollectionRDD\"\n",
      "        repr: \"ParallelCollectionRDD[26] at javaRDD at ExecutionItem.scala:56\"\n",
      "        proto {\n",
      "          name: \"cast_double2/ParallelCollectionRDD_26\"\n",
      "          op: \"ParallelCollectionRDD\"\n",
      "          input: \"^count1/MapPartitionsRDD_19\"\n",
      "          attr {\n",
      "            key: \"name\"\n",
      "            value {\n",
      "              s: \"ParallelCollectionRDD\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      rdd_info {\n",
      "        rdd_id: 27\n",
      "        class_name: \"MapPartitionsRDD\"\n",
      "        repr: \"MapPartitionsRDD[27] at javaRDD at ExecutionItem.scala:56\"\n",
      "        parents: 26\n",
      "        proto {\n",
      "          name: \"cast_double2/MapPartitionsRDD_27\"\n",
      "          op: \"MapPartitionsRDD\"\n",
      "          input: \"cast_double2/ParallelCollectionRDD_26\"\n",
      "          attr {\n",
      "            key: \"name\"\n",
      "            value {\n",
      "              s: \"MapPartitionsRDD\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      rdd_info {\n",
      "        rdd_id: 28\n",
      "        class_name: \"MapPartitionsRDD\"\n",
      "        repr: \"MapPartitionsRDD[28] at javaRDD at ExecutionItem.scala:56\"\n",
      "        parents: 27\n",
      "        proto {\n",
      "          name: \"cast_double2/MapPartitionsRDD_28\"\n",
      "          op: \"MapPartitionsRDD\"\n",
      "          input: \"cast_double2/MapPartitionsRDD_27\"\n",
      "          attr {\n",
      "            key: \"name\"\n",
      "            value {\n",
      "              s: \"MapPartitionsRDD\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      rdd_info {\n",
      "        rdd_id: 29\n",
      "        class_name: \"MapPartitionsRDD\"\n",
      "        repr: \"MapPartitionsRDD[29] at javaRDD at ExecutionItem.scala:56\"\n",
      "        parents: 28\n",
      "        proto {\n",
      "          name: \"cast_double2/MapPartitionsRDD_29\"\n",
      "          op: \"MapPartitionsRDD\"\n",
      "          input: \"cast_double2/MapPartitionsRDD_28\"\n",
      "          attr {\n",
      "            key: \"name\"\n",
      "            value {\n",
      "              s: \"MapPartitionsRDD\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      rdd_info {\n",
      "        rdd_id: 30\n",
      "        class_name: \"MapPartitionsRDD\"\n",
      "        repr: \"MapPartitionsRDD[30] at createDataFrame at ExecutionItem.scala:56\"\n",
      "        parents: 29\n",
      "        proto {\n",
      "          name: \"cast_double2/MapPartitionsRDD_30\"\n",
      "          op: \"MapPartitionsRDD\"\n",
      "          input: \"cast_double2/MapPartitionsRDD_29\"\n",
      "          attr {\n",
      "            key: \"name\"\n",
      "            value {\n",
      "              s: \"MapPartitionsRDD\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      rdd_info {\n",
      "        rdd_id: 31\n",
      "        class_name: \"MapPartitionsRDD\"\n",
      "        repr: \"MapPartitionsRDD[31] at execute at ExecutionItem.scala:89\"\n",
      "        parents: 30\n",
      "        proto {\n",
      "          name: \"cast_double2/MapPartitionsRDD_31\"\n",
      "          op: \"MapPartitionsRDD\"\n",
      "          input: \"cast_double2/MapPartitionsRDD_30\"\n",
      "          attr {\n",
      "            key: \"name\"\n",
      "            value {\n",
      "              s: \"MapPartitionsRDD\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      parsed {\n",
      "        node_id: \"LogicalRDD_0\"\n",
      "        full_name: \"LogicalRDD [value#185]\"\n",
      "        proto {\n",
      "          name: \"cast_double2/LogicalRDD_0\"\n",
      "          op: \"LogicalRDD\"\n",
      "          input: \"^count1/LogicalRDD_0\"\n",
      "          attr {\n",
      "            key: \"schema\"\n",
      "            value {\n",
      "              s: \"root\\n |-- value: double (nullable = false)\\n\"\n",
      "            }\n",
      "          }\n",
      "          attr {\n",
      "            key: \"simple\"\n",
      "            value {\n",
      "              s: \"LogicalRDD [value#185]\"\n",
      "            }\n",
      "          }\n",
      "          attr {\n",
      "            key: \"verbose\"\n",
      "            value {\n",
      "              s: \"LogicalRDD [value#185]\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      physical {\n",
      "        node_id: \"Scan_ExistingRDD_0\"\n",
      "        full_name: \"Scan ExistingRDD[value#185]\"\n",
      "        proto {\n",
      "          name: \"cast_double2/Scan_ExistingRDD_0\"\n",
      "          op: \"Scan_ExistingRDD\"\n",
      "          input: \"^count1/Scan_ExistingRDD_0\"\n",
      "          attr {\n",
      "            key: \"schema\"\n",
      "            value {\n",
      "              s: \"root\\n |-- value: double (nullable = false)\\n\"\n",
      "            }\n",
      "          }\n",
      "          attr {\n",
      "            key: \"simple\"\n",
      "            value {\n",
      "              s: \"Scan ExistingRDD[value#185]\"\n",
      "            }\n",
      "          }\n",
      "          attr {\n",
      "            key: \"verbose\"\n",
      "            value {\n",
      "              s: \"Scan ExistingRDD[value#185]\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "04:14:31 DEBUG:channel: received result for /cast_double2: local_path {\n",
      "  path: \"cast_double2\"\n",
      "}\n",
      "status: FINISHED_SUCCESS\n",
      "final_result {\n",
      "  cell {\n",
      "    double_value: 2.0\n",
      "  }\n",
      "  cell_type {\n",
      "    basic_type: DOUBLE\n",
      "  }\n",
      "}\n",
      "spark_stats {\n",
      "  rdd_info {\n",
      "    rdd_id: 26\n",
      "    class_name: \"ParallelCollectionRDD\"\n",
      "    repr: \"ParallelCollectionRDD[26] at javaRDD at ExecutionItem.scala:56\"\n",
      "    proto {\n",
      "      name: \"cast_double2/ParallelCollectionRDD_26\"\n",
      "      op: \"ParallelCollectionRDD\"\n",
      "      input: \"^count1/MapPartitionsRDD_19\"\n",
      "      attr {\n",
      "        key: \"name\"\n",
      "        value {\n",
      "          s: \"ParallelCollectionRDD\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  rdd_info {\n",
      "    rdd_id: 27\n",
      "    class_name: \"MapPartitionsRDD\"\n",
      "    repr: \"MapPartitionsRDD[27] at javaRDD at ExecutionItem.scala:56\"\n",
      "    parents: 26\n",
      "    proto {\n",
      "      name: \"cast_double2/MapPartitionsRDD_27\"\n",
      "      op: \"MapPartitionsRDD\"\n",
      "      input: \"cast_double2/ParallelCollectionRDD_26\"\n",
      "      attr {\n",
      "        key: \"name\"\n",
      "        value {\n",
      "          s: \"MapPartitionsRDD\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  rdd_info {\n",
      "    rdd_id: 28\n",
      "    class_name: \"MapPartitionsRDD\"\n",
      "    repr: \"MapPartitionsRDD[28] at javaRDD at ExecutionItem.scala:56\"\n",
      "    parents: 27\n",
      "    proto {\n",
      "      name: \"cast_double2/MapPartitionsRDD_28\"\n",
      "      op: \"MapPartitionsRDD\"\n",
      "      input: \"cast_double2/MapPartitionsRDD_27\"\n",
      "      attr {\n",
      "        key: \"name\"\n",
      "        value {\n",
      "          s: \"MapPartitionsRDD\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  rdd_info {\n",
      "    rdd_id: 29\n",
      "    class_name: \"MapPartitionsRDD\"\n",
      "    repr: \"MapPartitionsRDD[29] at javaRDD at ExecutionItem.scala:56\"\n",
      "    parents: 28\n",
      "    proto {\n",
      "      name: \"cast_double2/MapPartitionsRDD_29\"\n",
      "      op: \"MapPartitionsRDD\"\n",
      "      input: \"cast_double2/MapPartitionsRDD_28\"\n",
      "      attr {\n",
      "        key: \"name\"\n",
      "        value {\n",
      "          s: \"MapPartitionsRDD\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  rdd_info {\n",
      "    rdd_id: 30\n",
      "    class_name: \"MapPartitionsRDD\"\n",
      "    repr: \"MapPartitionsRDD[30] at createDataFrame at ExecutionItem.scala:56\"\n",
      "    parents: 29\n",
      "    proto {\n",
      "      name: \"cast_double2/MapPartitionsRDD_30\"\n",
      "      op: \"MapPartitionsRDD\"\n",
      "      input: \"cast_double2/MapPartitionsRDD_29\"\n",
      "      attr {\n",
      "        key: \"name\"\n",
      "        value {\n",
      "          s: \"MapPartitionsRDD\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  rdd_info {\n",
      "    rdd_id: 31\n",
      "    class_name: \"MapPartitionsRDD\"\n",
      "    repr: \"MapPartitionsRDD[31] at execute at ExecutionItem.scala:89\"\n",
      "    parents: 30\n",
      "    proto {\n",
      "      name: \"cast_double2/MapPartitionsRDD_31\"\n",
      "      op: \"MapPartitionsRDD\"\n",
      "      input: \"cast_double2/MapPartitionsRDD_30\"\n",
      "      attr {\n",
      "        key: \"name\"\n",
      "        value {\n",
      "          s: \"MapPartitionsRDD\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parsed {\n",
      "    node_id: \"LogicalRDD_0\"\n",
      "    full_name: \"LogicalRDD [value#185]\"\n",
      "    proto {\n",
      "      name: \"cast_double2/LogicalRDD_0\"\n",
      "      op: \"LogicalRDD\"\n",
      "      input: \"^count1/LogicalRDD_0\"\n",
      "      attr {\n",
      "        key: \"schema\"\n",
      "        value {\n",
      "          s: \"root\\n |-- value: double (nullable = false)\\n\"\n",
      "        }\n",
      "      }\n",
      "      attr {\n",
      "        key: \"simple\"\n",
      "        value {\n",
      "          s: \"LogicalRDD [value#185]\"\n",
      "        }\n",
      "      }\n",
      "      attr {\n",
      "        key: \"verbose\"\n",
      "        value {\n",
      "          s: \"LogicalRDD [value#185]\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  physical {\n",
      "    node_id: \"Scan_ExistingRDD_0\"\n",
      "    full_name: \"Scan ExistingRDD[value#185]\"\n",
      "    proto {\n",
      "      name: \"cast_double2/Scan_ExistingRDD_0\"\n",
      "      op: \"Scan_ExistingRDD\"\n",
      "      input: \"^count1/Scan_ExistingRDD_0\"\n",
      "      attr {\n",
      "        key: \"schema\"\n",
      "        value {\n",
      "          s: \"root\\n |-- value: double (nullable = false)\\n\"\n",
      "        }\n",
      "      }\n",
      "      attr {\n",
      "        key: \"simple\"\n",
      "        value {\n",
      "          s: \"Scan ExistingRDD[value#185]\"\n",
      "        }\n",
      "      }\n",
      "      attr {\n",
      "        key: \"verbose\"\n",
      "        value {\n",
      "          s: \"Scan ExistingRDD[value#185]\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04:14:31 DEBUG:Calling _progress\n",
      "04:14:31 DEBUG:channel: got value <class 'karps.proto.interface_pb2.ComputationStreamResponse'>: session {\n",
      "  id: \"test3\"\n",
      "}\n",
      "computation {\n",
      "  id: \"1\"\n",
      "}\n",
      "results {\n",
      "  results {\n",
      "    local_path {\n",
      "      path: \"divide3_karps_localpack\"\n",
      "    }\n",
      "    status: SCHEDULED\n",
      "    spark_stats {\n",
      "      rdd_info {\n",
      "        rdd_id: 32\n",
      "        class_name: \"ParallelCollectionRDD\"\n",
      "        repr: \"ParallelCollectionRDD[32] at javaRDD at ExecutionItem.scala:56\"\n",
      "        proto {\n",
      "          name: \"divide3_karps_localpack/ParallelCollectionRDD_32\"\n",
      "          op: \"ParallelCollectionRDD\"\n",
      "          input: \"^sum0/MapPartitionsRDD_25\"\n",
      "          input: \"^cast_double2/MapPartitionsRDD_31\"\n",
      "          attr {\n",
      "            key: \"name\"\n",
      "            value {\n",
      "              s: \"ParallelCollectionRDD\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      rdd_info {\n",
      "        rdd_id: 33\n",
      "        class_name: \"MapPartitionsRDD\"\n",
      "        repr: \"MapPartitionsRDD[33] at javaRDD at ExecutionItem.scala:56\"\n",
      "        parents: 32\n",
      "        proto {\n",
      "          name: \"divide3_karps_localpack/MapPartitionsRDD_33\"\n",
      "          op: \"MapPartitionsRDD\"\n",
      "          input: \"divide3_karps_localpack/ParallelCollectionRDD_32\"\n",
      "          attr {\n",
      "            key: \"name\"\n",
      "            value {\n",
      "              s: \"MapPartitionsRDD\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      rdd_info {\n",
      "        rdd_id: 34\n",
      "        class_name: \"MapPartitionsRDD\"\n",
      "        repr: \"MapPartitionsRDD[34] at javaRDD at ExecutionItem.scala:56\"\n",
      "        parents: 33\n",
      "        proto {\n",
      "          name: \"divide3_karps_localpack/MapPartitionsRDD_34\"\n",
      "          op: \"MapPartitionsRDD\"\n",
      "          input: \"divide3_karps_localpack/MapPartitionsRDD_33\"\n",
      "          attr {\n",
      "            key: \"name\"\n",
      "            value {\n",
      "              s: \"MapPartitionsRDD\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      rdd_info {\n",
      "        rdd_id: 35\n",
      "        class_name: \"MapPartitionsRDD\"\n",
      "        repr: \"MapPartitionsRDD[35] at javaRDD at ExecutionItem.scala:56\"\n",
      "        parents: 34\n",
      "        proto {\n",
      "          name: \"divide3_karps_localpack/MapPartitionsRDD_35\"\n",
      "          op: \"MapPartitionsRDD\"\n",
      "          input: \"divide3_karps_localpack/MapPartitionsRDD_34\"\n",
      "          attr {\n",
      "            key: \"name\"\n",
      "            value {\n",
      "              s: \"MapPartitionsRDD\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      rdd_info {\n",
      "        rdd_id: 36\n",
      "        class_name: \"MapPartitionsRDD\"\n",
      "        repr: \"MapPartitionsRDD[36] at createDataFrame at ExecutionItem.scala:56\"\n",
      "        parents: 35\n",
      "        proto {\n",
      "          name: \"divide3_karps_localpack/MapPartitionsRDD_36\"\n",
      "          op: \"MapPartitionsRDD\"\n",
      "          input: \"divide3_karps_localpack/MapPartitionsRDD_35\"\n",
      "          attr {\n",
      "            key: \"name\"\n",
      "            value {\n",
      "              s: \"MapPartitionsRDD\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      rdd_info {\n",
      "        rdd_id: 37\n",
      "        class_name: \"MapPartitionsRDD\"\n",
      "        repr: \"MapPartitionsRDD[37] at execute at ExecutionItem.scala:89\"\n",
      "        parents: 36\n",
      "        proto {\n",
      "          name: \"divide3_karps_localpack/MapPartitionsRDD_37\"\n",
      "          op: \"MapPartitionsRDD\"\n",
      "          input: \"divide3_karps_localpack/MapPartitionsRDD_36\"\n",
      "          attr {\n",
      "            key: \"name\"\n",
      "            value {\n",
      "              s: \"MapPartitionsRDD\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      parsed {\n",
      "        node_id: \"LogicalRDD_0\"\n",
      "        full_name: \"LogicalRDD [_1#198, _2#199]\"\n",
      "        proto {\n",
      "          name: \"divide3_karps_localpack/LogicalRDD_0\"\n",
      "          op: \"LogicalRDD\"\n",
      "          input: \"^sum0/LogicalRDD_0\"\n",
      "          input: \"^cast_double2/LogicalRDD_0\"\n",
      "          attr {\n",
      "            key: \"schema\"\n",
      "            value {\n",
      "              s: \"root\\n |-- _1: double (nullable = false)\\n |-- _2: double (nullable = false)\\n\"\n",
      "            }\n",
      "          }\n",
      "          attr {\n",
      "            key: \"simple\"\n",
      "            value {\n",
      "              s: \"LogicalRDD [_1#198, _2#199]\"\n",
      "            }\n",
      "          }\n",
      "          attr {\n",
      "            key: \"verbose\"\n",
      "            value {\n",
      "              s: \"LogicalRDD [_1#198, _2#199]\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      physical {\n",
      "        node_id: \"Scan_ExistingRDD_0\"\n",
      "        full_name: \"Scan ExistingRDD[_1#198,_2#199]\"\n",
      "        proto {\n",
      "          name: \"divide3_karps_localpack/Scan_ExistingRDD_0\"\n",
      "          op: \"Scan_ExistingRDD\"\n",
      "          input: \"^sum0/Scan_ExistingRDD_0\"\n",
      "          input: \"^cast_double2/Scan_ExistingRDD_0\"\n",
      "          attr {\n",
      "            key: \"schema\"\n",
      "            value {\n",
      "              s: \"root\\n |-- _1: double (nullable = false)\\n |-- _2: double (nullable = false)\\n\"\n",
      "            }\n",
      "          }\n",
      "          attr {\n",
      "            key: \"simple\"\n",
      "            value {\n",
      "              s: \"Scan ExistingRDD[_1#198,_2#199]\"\n",
      "            }\n",
      "          }\n",
      "          attr {\n",
      "            key: \"verbose\"\n",
      "            value {\n",
      "              s: \"Scan ExistingRDD[_1#198,_2#199]\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "04:14:31 DEBUG:channel: received result for /divide3_karps_localpack: local_path {\n",
      "  path: \"divide3_karps_localpack\"\n",
      "}\n",
      "status: SCHEDULED\n",
      "spark_stats {\n",
      "  rdd_info {\n",
      "    rdd_id: 32\n",
      "    class_name: \"ParallelCollectionRDD\"\n",
      "    repr: \"ParallelCollectionRDD[32] at javaRDD at ExecutionItem.scala:56\"\n",
      "    proto {\n",
      "      name: \"divide3_karps_localpack/ParallelCollectionRDD_32\"\n",
      "      op: \"ParallelCollectionRDD\"\n",
      "      input: \"^sum0/MapPartitionsRDD_25\"\n",
      "      input: \"^cast_double2/MapPartitionsRDD_31\"\n",
      "      attr {\n",
      "        key: \"name\"\n",
      "        value {\n",
      "          s: \"ParallelCollectionRDD\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  rdd_info {\n",
      "    rdd_id: 33\n",
      "    class_name: \"MapPartitionsRDD\"\n",
      "    repr: \"MapPartitionsRDD[33] at javaRDD at ExecutionItem.scala:56\"\n",
      "    parents: 32\n",
      "    proto {\n",
      "      name: \"divide3_karps_localpack/MapPartitionsRDD_33\"\n",
      "      op: \"MapPartitionsRDD\"\n",
      "      input: \"divide3_karps_localpack/ParallelCollectionRDD_32\"\n",
      "      attr {\n",
      "        key: \"name\"\n",
      "        value {\n",
      "          s: \"MapPartitionsRDD\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  rdd_info {\n",
      "    rdd_id: 34\n",
      "    class_name: \"MapPartitionsRDD\"\n",
      "    repr: \"MapPartitionsRDD[34] at javaRDD at ExecutionItem.scala:56\"\n",
      "    parents: 33\n",
      "    proto {\n",
      "      name: \"divide3_karps_localpack/MapPartitionsRDD_34\"\n",
      "      op: \"MapPartitionsRDD\"\n",
      "      input: \"divide3_karps_localpack/MapPartitionsRDD_33\"\n",
      "      attr {\n",
      "        key: \"name\"\n",
      "        value {\n",
      "          s: \"MapPartitionsRDD\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  rdd_info {\n",
      "    rdd_id: 35\n",
      "    class_name: \"MapPartitionsRDD\"\n",
      "    repr: \"MapPartitionsRDD[35] at javaRDD at ExecutionItem.scala:56\"\n",
      "    parents: 34\n",
      "    proto {\n",
      "      name: \"divide3_karps_localpack/MapPartitionsRDD_35\"\n",
      "      op: \"MapPartitionsRDD\"\n",
      "      input: \"divide3_karps_localpack/MapPartitionsRDD_34\"\n",
      "      attr {\n",
      "        key: \"name\"\n",
      "        value {\n",
      "          s: \"MapPartitionsRDD\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  rdd_info {\n",
      "    rdd_id: 36\n",
      "    class_name: \"MapPartitionsRDD\"\n",
      "    repr: \"MapPartitionsRDD[36] at createDataFrame at ExecutionItem.scala:56\"\n",
      "    parents: 35\n",
      "    proto {\n",
      "      name: \"divide3_karps_localpack/MapPartitionsRDD_36\"\n",
      "      op: \"MapPartitionsRDD\"\n",
      "      input: \"divide3_karps_localpack/MapPartitionsRDD_35\"\n",
      "      attr {\n",
      "        key: \"name\"\n",
      "        value {\n",
      "          s: \"MapPartitionsRDD\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  rdd_info {\n",
      "    rdd_id: 37\n",
      "    class_name: \"MapPartitionsRDD\"\n",
      "    repr: \"MapPartitionsRDD[37] at execute at ExecutionItem.scala:89\"\n",
      "    parents: 36\n",
      "    proto {\n",
      "      name: \"divide3_karps_localpack/MapPartitionsRDD_37\"\n",
      "      op: \"MapPartitionsRDD\"\n",
      "      input: \"divide3_karps_localpack/MapPartitionsRDD_36\"\n",
      "      attr {\n",
      "        key: \"name\"\n",
      "        value {\n",
      "          s: \"MapPartitionsRDD\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parsed {\n",
      "    node_id: \"LogicalRDD_0\"\n",
      "    full_name: \"LogicalRDD [_1#198, _2#199]\"\n",
      "    proto {\n",
      "      name: \"divide3_karps_localpack/LogicalRDD_0\"\n",
      "      op: \"LogicalRDD\"\n",
      "      input: \"^sum0/LogicalRDD_0\"\n",
      "      input: \"^cast_double2/LogicalRDD_0\"\n",
      "      attr {\n",
      "        key: \"schema\"\n",
      "        value {\n",
      "          s: \"root\\n |-- _1: double (nullable = false)\\n |-- _2: double (nullable = false)\\n\"\n",
      "        }\n",
      "      }\n",
      "      attr {\n",
      "        key: \"simple\"\n",
      "        value {\n",
      "          s: \"LogicalRDD [_1#198, _2#199]\"\n",
      "        }\n",
      "      }\n",
      "      attr {\n",
      "        key: \"verbose\"\n",
      "        value {\n",
      "          s: \"LogicalRDD [_1#198, _2#199]\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  physical {\n",
      "    node_id: \"Scan_ExistingRDD_0\"\n",
      "    full_name: \"Scan ExistingRDD[_1#198,_2#199]\"\n",
      "    proto {\n",
      "      name: \"divide3_karps_localpack/Scan_ExistingRDD_0\"\n",
      "      op: \"Scan_ExistingRDD\"\n",
      "      input: \"^sum0/Scan_ExistingRDD_0\"\n",
      "      input: \"^cast_double2/Scan_ExistingRDD_0\"\n",
      "      attr {\n",
      "        key: \"schema\"\n",
      "        value {\n",
      "          s: \"root\\n |-- _1: double (nullable = false)\\n |-- _2: double (nullable = false)\\n\"\n",
      "        }\n",
      "      }\n",
      "      attr {\n",
      "        key: \"simple\"\n",
      "        value {\n",
      "          s: \"Scan ExistingRDD[_1#198,_2#199]\"\n",
      "        }\n",
      "      }\n",
      "      attr {\n",
      "        key: \"verbose\"\n",
      "        value {\n",
      "          s: \"Scan ExistingRDD[_1#198,_2#199]\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04:14:31 DEBUG:Calling _progress\n",
      "04:14:31 DEBUG:channel: got value <class 'karps.proto.interface_pb2.ComputationStreamResponse'>: session {\n",
      "  id: \"test3\"\n",
      "}\n",
      "computation {\n",
      "  id: \"1\"\n",
      "}\n",
      "results {\n",
      "  results {\n",
      "    local_path {\n",
      "      path: \"divide3_karps_localpack\"\n",
      "    }\n",
      "    status: FINISHED_SUCCESS\n",
      "    final_result {\n",
      "      cell {\n",
      "        struct_value {\n",
      "          values {\n",
      "            double_value: 3.0\n",
      "          }\n",
      "          values {\n",
      "            double_value: 2.0\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      cell_type {\n",
      "        struct_type {\n",
      "          fields {\n",
      "            field_name: \"_1\"\n",
      "            field_type {\n",
      "              basic_type: DOUBLE\n",
      "            }\n",
      "          }\n",
      "          fields {\n",
      "            field_name: \"_2\"\n",
      "            field_type {\n",
      "              basic_type: DOUBLE\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    spark_stats {\n",
      "      rdd_info {\n",
      "        rdd_id: 32\n",
      "        class_name: \"ParallelCollectionRDD\"\n",
      "        repr: \"ParallelCollectionRDD[32] at javaRDD at ExecutionItem.scala:56\"\n",
      "        proto {\n",
      "          name: \"divide3_karps_localpack/ParallelCollectionRDD_32\"\n",
      "          op: \"ParallelCollectionRDD\"\n",
      "          input: \"^sum0/MapPartitionsRDD_25\"\n",
      "          input: \"^cast_double2/MapPartitionsRDD_31\"\n",
      "          attr {\n",
      "            key: \"name\"\n",
      "            value {\n",
      "              s: \"ParallelCollectionRDD\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      rdd_info {\n",
      "        rdd_id: 33\n",
      "        class_name: \"MapPartitionsRDD\"\n",
      "        repr: \"MapPartitionsRDD[33] at javaRDD at ExecutionItem.scala:56\"\n",
      "        parents: 32\n",
      "        proto {\n",
      "          name: \"divide3_karps_localpack/MapPartitionsRDD_33\"\n",
      "          op: \"MapPartitionsRDD\"\n",
      "          input: \"divide3_karps_localpack/ParallelCollectionRDD_32\"\n",
      "          attr {\n",
      "            key: \"name\"\n",
      "            value {\n",
      "              s: \"MapPartitionsRDD\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      rdd_info {\n",
      "        rdd_id: 34\n",
      "        class_name: \"MapPartitionsRDD\"\n",
      "        repr: \"MapPartitionsRDD[34] at javaRDD at ExecutionItem.scala:56\"\n",
      "        parents: 33\n",
      "        proto {\n",
      "          name: \"divide3_karps_localpack/MapPartitionsRDD_34\"\n",
      "          op: \"MapPartitionsRDD\"\n",
      "          input: \"divide3_karps_localpack/MapPartitionsRDD_33\"\n",
      "          attr {\n",
      "            key: \"name\"\n",
      "            value {\n",
      "              s: \"MapPartitionsRDD\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      rdd_info {\n",
      "        rdd_id: 35\n",
      "        class_name: \"MapPartitionsRDD\"\n",
      "        repr: \"MapPartitionsRDD[35] at javaRDD at ExecutionItem.scala:56\"\n",
      "        parents: 34\n",
      "        proto {\n",
      "          name: \"divide3_karps_localpack/MapPartitionsRDD_35\"\n",
      "          op: \"MapPartitionsRDD\"\n",
      "          input: \"divide3_karps_localpack/MapPartitionsRDD_34\"\n",
      "          attr {\n",
      "            key: \"name\"\n",
      "            value {\n",
      "              s: \"MapPartitionsRDD\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      rdd_info {\n",
      "        rdd_id: 36\n",
      "        class_name: \"MapPartitionsRDD\"\n",
      "        repr: \"MapPartitionsRDD[36] at createDataFrame at ExecutionItem.scala:56\"\n",
      "        parents: 35\n",
      "        proto {\n",
      "          name: \"divide3_karps_localpack/MapPartitionsRDD_36\"\n",
      "          op: \"MapPartitionsRDD\"\n",
      "          input: \"divide3_karps_localpack/MapPartitionsRDD_35\"\n",
      "          attr {\n",
      "            key: \"name\"\n",
      "            value {\n",
      "              s: \"MapPartitionsRDD\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      rdd_info {\n",
      "        rdd_id: 37\n",
      "        class_name: \"MapPartitionsRDD\"\n",
      "        repr: \"MapPartitionsRDD[37] at execute at ExecutionItem.scala:89\"\n",
      "        parents: 36\n",
      "        proto {\n",
      "          name: \"divide3_karps_localpack/MapPartitionsRDD_37\"\n",
      "          op: \"MapPartitionsRDD\"\n",
      "          input: \"divide3_karps_localpack/MapPartitionsRDD_36\"\n",
      "          attr {\n",
      "            key: \"name\"\n",
      "            value {\n",
      "              s: \"MapPartitionsRDD\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      parsed {\n",
      "        node_id: \"LogicalRDD_0\"\n",
      "        full_name: \"LogicalRDD [_1#198, _2#199]\"\n",
      "        proto {\n",
      "          name: \"divide3_karps_localpack/LogicalRDD_0\"\n",
      "          op: \"LogicalRDD\"\n",
      "          input: \"^sum0/LogicalRDD_0\"\n",
      "          input: \"^cast_double2/LogicalRDD_0\"\n",
      "          attr {\n",
      "            key: \"schema\"\n",
      "            value {\n",
      "              s: \"root\\n |-- _1: double (nullable = false)\\n |-- _2: double (nullable = false)\\n\"\n",
      "            }\n",
      "          }\n",
      "          attr {\n",
      "            key: \"simple\"\n",
      "            value {\n",
      "              s: \"LogicalRDD [_1#198, _2#199]\"\n",
      "            }\n",
      "          }\n",
      "          attr {\n",
      "            key: \"verbose\"\n",
      "            value {\n",
      "              s: \"LogicalRDD [_1#198, _2#199]\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      physical {\n",
      "        node_id: \"Scan_ExistingRDD_0\"\n",
      "        full_name: \"Scan ExistingRDD[_1#198,_2#199]\"\n",
      "        proto {\n",
      "          name: \"divide3_karps_localpack/Scan_ExistingRDD_0\"\n",
      "          op: \"Scan_ExistingRDD\"\n",
      "          input: \"^sum0/Scan_ExistingRDD_0\"\n",
      "          input: \"^cast_double2/Scan_ExistingRDD_0\"\n",
      "          attr {\n",
      "            key: \"schema\"\n",
      "            value {\n",
      "              s: \"root\\n |-- _1: double (nullable = false)\\n |-- _2: double (nullable = false)\\n\"\n",
      "            }\n",
      "          }\n",
      "          attr {\n",
      "            key: \"simple\"\n",
      "            value {\n",
      "              s: \"Scan ExistingRDD[_1#198,_2#199]\"\n",
      "            }\n",
      "          }\n",
      "          attr {\n",
      "            key: \"verbose\"\n",
      "            value {\n",
      "              s: \"Scan ExistingRDD[_1#198,_2#199]\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "04:14:31 DEBUG:channel: received result for /divide3_karps_localpack: local_path {\n",
      "  path: \"divide3_karps_localpack\"\n",
      "}\n",
      "status: FINISHED_SUCCESS\n",
      "final_result {\n",
      "  cell {\n",
      "    struct_value {\n",
      "      values {\n",
      "        double_value: 3.0\n",
      "      }\n",
      "      values {\n",
      "        double_value: 2.0\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  cell_type {\n",
      "    struct_type {\n",
      "      fields {\n",
      "        field_name: \"_1\"\n",
      "        field_type {\n",
      "          basic_type: DOUBLE\n",
      "        }\n",
      "      }\n",
      "      fields {\n",
      "        field_name: \"_2\"\n",
      "        field_type {\n",
      "          basic_type: DOUBLE\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "spark_stats {\n",
      "  rdd_info {\n",
      "    rdd_id: 32\n",
      "    class_name: \"ParallelCollectionRDD\"\n",
      "    repr: \"ParallelCollectionRDD[32] at javaRDD at ExecutionItem.scala:56\"\n",
      "    proto {\n",
      "      name: \"divide3_karps_localpack/ParallelCollectionRDD_32\"\n",
      "      op: \"ParallelCollectionRDD\"\n",
      "      input: \"^sum0/MapPartitionsRDD_25\"\n",
      "      input: \"^cast_double2/MapPartitionsRDD_31\"\n",
      "      attr {\n",
      "        key: \"name\"\n",
      "        value {\n",
      "          s: \"ParallelCollectionRDD\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  rdd_info {\n",
      "    rdd_id: 33\n",
      "    class_name: \"MapPartitionsRDD\"\n",
      "    repr: \"MapPartitionsRDD[33] at javaRDD at ExecutionItem.scala:56\"\n",
      "    parents: 32\n",
      "    proto {\n",
      "      name: \"divide3_karps_localpack/MapPartitionsRDD_33\"\n",
      "      op: \"MapPartitionsRDD\"\n",
      "      input: \"divide3_karps_localpack/ParallelCollectionRDD_32\"\n",
      "      attr {\n",
      "        key: \"name\"\n",
      "        value {\n",
      "          s: \"MapPartitionsRDD\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  rdd_info {\n",
      "    rdd_id: 34\n",
      "    class_name: \"MapPartitionsRDD\"\n",
      "    repr: \"MapPartitionsRDD[34] at javaRDD at ExecutionItem.scala:56\"\n",
      "    parents: 33\n",
      "    proto {\n",
      "      name: \"divide3_karps_localpack/MapPartitionsRDD_34\"\n",
      "      op: \"MapPartitionsRDD\"\n",
      "      input: \"divide3_karps_localpack/MapPartitionsRDD_33\"\n",
      "      attr {\n",
      "        key: \"name\"\n",
      "        value {\n",
      "          s: \"MapPartitionsRDD\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  rdd_info {\n",
      "    rdd_id: 35\n",
      "    class_name: \"MapPartitionsRDD\"\n",
      "    repr: \"MapPartitionsRDD[35] at javaRDD at ExecutionItem.scala:56\"\n",
      "    parents: 34\n",
      "    proto {\n",
      "      name: \"divide3_karps_localpack/MapPartitionsRDD_35\"\n",
      "      op: \"MapPartitionsRDD\"\n",
      "      input: \"divide3_karps_localpack/MapPartitionsRDD_34\"\n",
      "      attr {\n",
      "        key: \"name\"\n",
      "        value {\n",
      "          s: \"MapPartitionsRDD\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  rdd_info {\n",
      "    rdd_id: 36\n",
      "    class_name: \"MapPartitionsRDD\"\n",
      "    repr: \"MapPartitionsRDD[36] at createDataFrame at ExecutionItem.scala:56\"\n",
      "    parents: 35\n",
      "    proto {\n",
      "      name: \"divide3_karps_localpack/MapPartitionsRDD_36\"\n",
      "      op: \"MapPartitionsRDD\"\n",
      "      input: \"divide3_karps_localpack/MapPartitionsRDD_35\"\n",
      "      attr {\n",
      "        key: \"name\"\n",
      "        value {\n",
      "          s: \"MapPartitionsRDD\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  rdd_info {\n",
      "    rdd_id: 37\n",
      "    class_name: \"MapPartitionsRDD\"\n",
      "    repr: \"MapPartitionsRDD[37] at execute at ExecutionItem.scala:89\"\n",
      "    parents: 36\n",
      "    proto {\n",
      "      name: \"divide3_karps_localpack/MapPartitionsRDD_37\"\n",
      "      op: \"MapPartitionsRDD\"\n",
      "      input: \"divide3_karps_localpack/MapPartitionsRDD_36\"\n",
      "      attr {\n",
      "        key: \"name\"\n",
      "        value {\n",
      "          s: \"MapPartitionsRDD\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parsed {\n",
      "    node_id: \"LogicalRDD_0\"\n",
      "    full_name: \"LogicalRDD [_1#198, _2#199]\"\n",
      "    proto {\n",
      "      name: \"divide3_karps_localpack/LogicalRDD_0\"\n",
      "      op: \"LogicalRDD\"\n",
      "      input: \"^sum0/LogicalRDD_0\"\n",
      "      input: \"^cast_double2/LogicalRDD_0\"\n",
      "      attr {\n",
      "        key: \"schema\"\n",
      "        value {\n",
      "          s: \"root\\n |-- _1: double (nullable = false)\\n |-- _2: double (nullable = false)\\n\"\n",
      "        }\n",
      "      }\n",
      "      attr {\n",
      "        key: \"simple\"\n",
      "        value {\n",
      "          s: \"LogicalRDD [_1#198, _2#199]\"\n",
      "        }\n",
      "      }\n",
      "      attr {\n",
      "        key: \"verbose\"\n",
      "        value {\n",
      "          s: \"LogicalRDD [_1#198, _2#199]\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  physical {\n",
      "    node_id: \"Scan_ExistingRDD_0\"\n",
      "    full_name: \"Scan ExistingRDD[_1#198,_2#199]\"\n",
      "    proto {\n",
      "      name: \"divide3_karps_localpack/Scan_ExistingRDD_0\"\n",
      "      op: \"Scan_ExistingRDD\"\n",
      "      input: \"^sum0/Scan_ExistingRDD_0\"\n",
      "      input: \"^cast_double2/Scan_ExistingRDD_0\"\n",
      "      attr {\n",
      "        key: \"schema\"\n",
      "        value {\n",
      "          s: \"root\\n |-- _1: double (nullable = false)\\n |-- _2: double (nullable = false)\\n\"\n",
      "        }\n",
      "      }\n",
      "      attr {\n",
      "        key: \"simple\"\n",
      "        value {\n",
      "          s: \"Scan ExistingRDD[_1#198,_2#199]\"\n",
      "        }\n",
      "      }\n",
      "      attr {\n",
      "        key: \"verbose\"\n",
      "        value {\n",
      "          s: \"Scan ExistingRDD[_1#198,_2#199]\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04:14:31 DEBUG:Calling _progress\n",
      "04:14:31 DEBUG:channel: got value <class 'karps.proto.interface_pb2.ComputationStreamResponse'>: session {\n",
      "  id: \"test3\"\n",
      "}\n",
      "computation {\n",
      "  id: \"1\"\n",
      "}\n",
      "results {\n",
      "  results {\n",
      "    local_path {\n",
      "      path: \"divide3\"\n",
      "    }\n",
      "    status: SCHEDULED\n",
      "    spark_stats {\n",
      "      rdd_info {\n",
      "        rdd_id: 38\n",
      "        class_name: \"ParallelCollectionRDD\"\n",
      "        repr: \"ParallelCollectionRDD[38] at javaRDD at ExecutionItem.scala:56\"\n",
      "        proto {\n",
      "          name: \"divide3/ParallelCollectionRDD_38\"\n",
      "          op: \"ParallelCollectionRDD\"\n",
      "          input: \"^divide3_karps_localpack/MapPartitionsRDD_37\"\n",
      "          attr {\n",
      "            key: \"name\"\n",
      "            value {\n",
      "              s: \"ParallelCollectionRDD\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      rdd_info {\n",
      "        rdd_id: 39\n",
      "        class_name: \"MapPartitionsRDD\"\n",
      "        repr: \"MapPartitionsRDD[39] at javaRDD at ExecutionItem.scala:56\"\n",
      "        parents: 38\n",
      "        proto {\n",
      "          name: \"divide3/MapPartitionsRDD_39\"\n",
      "          op: \"MapPartitionsRDD\"\n",
      "          input: \"divide3/ParallelCollectionRDD_38\"\n",
      "          attr {\n",
      "            key: \"name\"\n",
      "            value {\n",
      "              s: \"MapPartitionsRDD\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      rdd_info {\n",
      "        rdd_id: 40\n",
      "        class_name: \"MapPartitionsRDD\"\n",
      "        repr: \"MapPartitionsRDD[40] at javaRDD at ExecutionItem.scala:56\"\n",
      "        parents: 39\n",
      "        proto {\n",
      "          name: \"divide3/MapPartitionsRDD_40\"\n",
      "          op: \"MapPartitionsRDD\"\n",
      "          input: \"divide3/MapPartitionsRDD_39\"\n",
      "          attr {\n",
      "            key: \"name\"\n",
      "            value {\n",
      "              s: \"MapPartitionsRDD\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      rdd_info {\n",
      "        rdd_id: 41\n",
      "        class_name: \"MapPartitionsRDD\"\n",
      "        repr: \"MapPartitionsRDD[41] at javaRDD at ExecutionItem.scala:56\"\n",
      "        parents: 40\n",
      "        proto {\n",
      "          name: \"divide3/MapPartitionsRDD_41\"\n",
      "          op: \"MapPartitionsRDD\"\n",
      "          input: \"divide3/MapPartitionsRDD_40\"\n",
      "          attr {\n",
      "            key: \"name\"\n",
      "            value {\n",
      "              s: \"MapPartitionsRDD\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      rdd_info {\n",
      "        rdd_id: 42\n",
      "        class_name: \"MapPartitionsRDD\"\n",
      "        repr: \"MapPartitionsRDD[42] at createDataFrame at ExecutionItem.scala:56\"\n",
      "        parents: 41\n",
      "        proto {\n",
      "          name: \"divide3/MapPartitionsRDD_42\"\n",
      "          op: \"MapPartitionsRDD\"\n",
      "          input: \"divide3/MapPartitionsRDD_41\"\n",
      "          attr {\n",
      "            key: \"name\"\n",
      "            value {\n",
      "              s: \"MapPartitionsRDD\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      rdd_info {\n",
      "        rdd_id: 43\n",
      "        class_name: \"MapPartitionsRDD\"\n",
      "        repr: \"MapPartitionsRDD[43] at execute at ExecutionItem.scala:89\"\n",
      "        parents: 42\n",
      "        proto {\n",
      "          name: \"divide3/MapPartitionsRDD_43\"\n",
      "          op: \"MapPartitionsRDD\"\n",
      "          input: \"divide3/MapPartitionsRDD_42\"\n",
      "          attr {\n",
      "            key: \"name\"\n",
      "            value {\n",
      "              s: \"MapPartitionsRDD\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      parsed {\n",
      "        node_id: \"LogicalRDD_0\"\n",
      "        full_name: \"LogicalRDD [value#221]\"\n",
      "        proto {\n",
      "          name: \"divide3/LogicalRDD_0\"\n",
      "          op: \"LogicalRDD\"\n",
      "          input: \"^divide3_karps_localpack/LogicalRDD_0\"\n",
      "          attr {\n",
      "            key: \"schema\"\n",
      "            value {\n",
      "              s: \"root\\n |-- value: double (nullable = true)\\n\"\n",
      "            }\n",
      "          }\n",
      "          attr {\n",
      "            key: \"simple\"\n",
      "            value {\n",
      "              s: \"LogicalRDD [value#221]\"\n",
      "            }\n",
      "          }\n",
      "          attr {\n",
      "            key: \"verbose\"\n",
      "            value {\n",
      "              s: \"LogicalRDD [value#221]\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      physical {\n",
      "        node_id: \"Scan_ExistingRDD_0\"\n",
      "        full_name: \"Scan ExistingRDD[value#221]\"\n",
      "        proto {\n",
      "          name: \"divide3/Scan_ExistingRDD_0\"\n",
      "          op: \"Scan_ExistingRDD\"\n",
      "          input: \"^divide3_karps_localpack/Scan_ExistingRDD_0\"\n",
      "          attr {\n",
      "            key: \"schema\"\n",
      "            value {\n",
      "              s: \"root\\n |-- value: double (nullable = true)\\n\"\n",
      "            }\n",
      "          }\n",
      "          attr {\n",
      "            key: \"simple\"\n",
      "            value {\n",
      "              s: \"Scan ExistingRDD[value#221]\"\n",
      "            }\n",
      "          }\n",
      "          attr {\n",
      "            key: \"verbose\"\n",
      "            value {\n",
      "              s: \"Scan ExistingRDD[value#221]\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "04:14:31 DEBUG:channel: received result for /divide3: local_path {\n",
      "  path: \"divide3\"\n",
      "}\n",
      "status: SCHEDULED\n",
      "spark_stats {\n",
      "  rdd_info {\n",
      "    rdd_id: 38\n",
      "    class_name: \"ParallelCollectionRDD\"\n",
      "    repr: \"ParallelCollectionRDD[38] at javaRDD at ExecutionItem.scala:56\"\n",
      "    proto {\n",
      "      name: \"divide3/ParallelCollectionRDD_38\"\n",
      "      op: \"ParallelCollectionRDD\"\n",
      "      input: \"^divide3_karps_localpack/MapPartitionsRDD_37\"\n",
      "      attr {\n",
      "        key: \"name\"\n",
      "        value {\n",
      "          s: \"ParallelCollectionRDD\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  rdd_info {\n",
      "    rdd_id: 39\n",
      "    class_name: \"MapPartitionsRDD\"\n",
      "    repr: \"MapPartitionsRDD[39] at javaRDD at ExecutionItem.scala:56\"\n",
      "    parents: 38\n",
      "    proto {\n",
      "      name: \"divide3/MapPartitionsRDD_39\"\n",
      "      op: \"MapPartitionsRDD\"\n",
      "      input: \"divide3/ParallelCollectionRDD_38\"\n",
      "      attr {\n",
      "        key: \"name\"\n",
      "        value {\n",
      "          s: \"MapPartitionsRDD\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  rdd_info {\n",
      "    rdd_id: 40\n",
      "    class_name: \"MapPartitionsRDD\"\n",
      "    repr: \"MapPartitionsRDD[40] at javaRDD at ExecutionItem.scala:56\"\n",
      "    parents: 39\n",
      "    proto {\n",
      "      name: \"divide3/MapPartitionsRDD_40\"\n",
      "      op: \"MapPartitionsRDD\"\n",
      "      input: \"divide3/MapPartitionsRDD_39\"\n",
      "      attr {\n",
      "        key: \"name\"\n",
      "        value {\n",
      "          s: \"MapPartitionsRDD\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  rdd_info {\n",
      "    rdd_id: 41\n",
      "    class_name: \"MapPartitionsRDD\"\n",
      "    repr: \"MapPartitionsRDD[41] at javaRDD at ExecutionItem.scala:56\"\n",
      "    parents: 40\n",
      "    proto {\n",
      "      name: \"divide3/MapPartitionsRDD_41\"\n",
      "      op: \"MapPartitionsRDD\"\n",
      "      input: \"divide3/MapPartitionsRDD_40\"\n",
      "      attr {\n",
      "        key: \"name\"\n",
      "        value {\n",
      "          s: \"MapPartitionsRDD\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  rdd_info {\n",
      "    rdd_id: 42\n",
      "    class_name: \"MapPartitionsRDD\"\n",
      "    repr: \"MapPartitionsRDD[42] at createDataFrame at ExecutionItem.scala:56\"\n",
      "    parents: 41\n",
      "    proto {\n",
      "      name: \"divide3/MapPartitionsRDD_42\"\n",
      "      op: \"MapPartitionsRDD\"\n",
      "      input: \"divide3/MapPartitionsRDD_41\"\n",
      "      attr {\n",
      "        key: \"name\"\n",
      "        value {\n",
      "          s: \"MapPartitionsRDD\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  rdd_info {\n",
      "    rdd_id: 43\n",
      "    class_name: \"MapPartitionsRDD\"\n",
      "    repr: \"MapPartitionsRDD[43] at execute at ExecutionItem.scala:89\"\n",
      "    parents: 42\n",
      "    proto {\n",
      "      name: \"divide3/MapPartitionsRDD_43\"\n",
      "      op: \"MapPartitionsRDD\"\n",
      "      input: \"divide3/MapPartitionsRDD_42\"\n",
      "      attr {\n",
      "        key: \"name\"\n",
      "        value {\n",
      "          s: \"MapPartitionsRDD\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parsed {\n",
      "    node_id: \"LogicalRDD_0\"\n",
      "    full_name: \"LogicalRDD [value#221]\"\n",
      "    proto {\n",
      "      name: \"divide3/LogicalRDD_0\"\n",
      "      op: \"LogicalRDD\"\n",
      "      input: \"^divide3_karps_localpack/LogicalRDD_0\"\n",
      "      attr {\n",
      "        key: \"schema\"\n",
      "        value {\n",
      "          s: \"root\\n |-- value: double (nullable = true)\\n\"\n",
      "        }\n",
      "      }\n",
      "      attr {\n",
      "        key: \"simple\"\n",
      "        value {\n",
      "          s: \"LogicalRDD [value#221]\"\n",
      "        }\n",
      "      }\n",
      "      attr {\n",
      "        key: \"verbose\"\n",
      "        value {\n",
      "          s: \"LogicalRDD [value#221]\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  physical {\n",
      "    node_id: \"Scan_ExistingRDD_0\"\n",
      "    full_name: \"Scan ExistingRDD[value#221]\"\n",
      "    proto {\n",
      "      name: \"divide3/Scan_ExistingRDD_0\"\n",
      "      op: \"Scan_ExistingRDD\"\n",
      "      input: \"^divide3_karps_localpack/Scan_ExistingRDD_0\"\n",
      "      attr {\n",
      "        key: \"schema\"\n",
      "        value {\n",
      "          s: \"root\\n |-- value: double (nullable = true)\\n\"\n",
      "        }\n",
      "      }\n",
      "      attr {\n",
      "        key: \"simple\"\n",
      "        value {\n",
      "          s: \"Scan ExistingRDD[value#221]\"\n",
      "        }\n",
      "      }\n",
      "      attr {\n",
      "        key: \"verbose\"\n",
      "        value {\n",
      "          s: \"Scan ExistingRDD[value#221]\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "04:14:31 DEBUG:Calling _progress\n",
      "04:14:32 DEBUG:channel: got value <class 'karps.proto.interface_pb2.ComputationStreamResponse'>: session {\n",
      "  id: \"test3\"\n",
      "}\n",
      "computation {\n",
      "  id: \"1\"\n",
      "}\n",
      "results {\n",
      "  results {\n",
      "    local_path {\n",
      "      path: \"divide3\"\n",
      "    }\n",
      "    status: FINISHED_SUCCESS\n",
      "    final_result {\n",
      "      cell {\n",
      "        double_value: 1.5\n",
      "      }\n",
      "      cell_type {\n",
      "        basic_type: DOUBLE\n",
      "      }\n",
      "    }\n",
      "    spark_stats {\n",
      "      rdd_info {\n",
      "        rdd_id: 38\n",
      "        class_name: \"ParallelCollectionRDD\"\n",
      "        repr: \"ParallelCollectionRDD[38] at javaRDD at ExecutionItem.scala:56\"\n",
      "        proto {\n",
      "          name: \"divide3/ParallelCollectionRDD_38\"\n",
      "          op: \"ParallelCollectionRDD\"\n",
      "          input: \"^divide3_karps_localpack/MapPartitionsRDD_37\"\n",
      "          attr {\n",
      "            key: \"name\"\n",
      "            value {\n",
      "              s: \"ParallelCollectionRDD\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      rdd_info {\n",
      "        rdd_id: 39\n",
      "        class_name: \"MapPartitionsRDD\"\n",
      "        repr: \"MapPartitionsRDD[39] at javaRDD at ExecutionItem.scala:56\"\n",
      "        parents: 38\n",
      "        proto {\n",
      "          name: \"divide3/MapPartitionsRDD_39\"\n",
      "          op: \"MapPartitionsRDD\"\n",
      "          input: \"divide3/ParallelCollectionRDD_38\"\n",
      "          attr {\n",
      "            key: \"name\"\n",
      "            value {\n",
      "              s: \"MapPartitionsRDD\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      rdd_info {\n",
      "        rdd_id: 40\n",
      "        class_name: \"MapPartitionsRDD\"\n",
      "        repr: \"MapPartitionsRDD[40] at javaRDD at ExecutionItem.scala:56\"\n",
      "        parents: 39\n",
      "        proto {\n",
      "          name: \"divide3/MapPartitionsRDD_40\"\n",
      "          op: \"MapPartitionsRDD\"\n",
      "          input: \"divide3/MapPartitionsRDD_39\"\n",
      "          attr {\n",
      "            key: \"name\"\n",
      "            value {\n",
      "              s: \"MapPartitionsRDD\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      rdd_info {\n",
      "        rdd_id: 41\n",
      "        class_name: \"MapPartitionsRDD\"\n",
      "        repr: \"MapPartitionsRDD[41] at javaRDD at ExecutionItem.scala:56\"\n",
      "        parents: 40\n",
      "        proto {\n",
      "          name: \"divide3/MapPartitionsRDD_41\"\n",
      "          op: \"MapPartitionsRDD\"\n",
      "          input: \"divide3/MapPartitionsRDD_40\"\n",
      "          attr {\n",
      "            key: \"name\"\n",
      "            value {\n",
      "              s: \"MapPartitionsRDD\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      rdd_info {\n",
      "        rdd_id: 42\n",
      "        class_name: \"MapPartitionsRDD\"\n",
      "        repr: \"MapPartitionsRDD[42] at createDataFrame at ExecutionItem.scala:56\"\n",
      "        parents: 41\n",
      "        proto {\n",
      "          name: \"divide3/MapPartitionsRDD_42\"\n",
      "          op: \"MapPartitionsRDD\"\n",
      "          input: \"divide3/MapPartitionsRDD_41\"\n",
      "          attr {\n",
      "            key: \"name\"\n",
      "            value {\n",
      "              s: \"MapPartitionsRDD\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      rdd_info {\n",
      "        rdd_id: 43\n",
      "        class_name: \"MapPartitionsRDD\"\n",
      "        repr: \"MapPartitionsRDD[43] at execute at ExecutionItem.scala:89\"\n",
      "        parents: 42\n",
      "        proto {\n",
      "          name: \"divide3/MapPartitionsRDD_43\"\n",
      "          op: \"MapPartitionsRDD\"\n",
      "          input: \"divide3/MapPartitionsRDD_42\"\n",
      "          attr {\n",
      "            key: \"name\"\n",
      "            value {\n",
      "              s: \"MapPartitionsRDD\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      parsed {\n",
      "        node_id: \"LogicalRDD_0\"\n",
      "        full_name: \"LogicalRDD [value#221]\"\n",
      "        proto {\n",
      "          name: \"divide3/LogicalRDD_0\"\n",
      "          op: \"LogicalRDD\"\n",
      "          input: \"^divide3_karps_localpack/LogicalRDD_0\"\n",
      "          attr {\n",
      "            key: \"schema\"\n",
      "            value {\n",
      "              s: \"root\\n |-- value: double (nullable = true)\\n\"\n",
      "            }\n",
      "          }\n",
      "          attr {\n",
      "            key: \"simple\"\n",
      "            value {\n",
      "              s: \"LogicalRDD [value#221]\"\n",
      "            }\n",
      "          }\n",
      "          attr {\n",
      "            key: \"verbose\"\n",
      "            value {\n",
      "              s: \"LogicalRDD [value#221]\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      physical {\n",
      "        node_id: \"Scan_ExistingRDD_0\"\n",
      "        full_name: \"Scan ExistingRDD[value#221]\"\n",
      "        proto {\n",
      "          name: \"divide3/Scan_ExistingRDD_0\"\n",
      "          op: \"Scan_ExistingRDD\"\n",
      "          input: \"^divide3_karps_localpack/Scan_ExistingRDD_0\"\n",
      "          attr {\n",
      "            key: \"schema\"\n",
      "            value {\n",
      "              s: \"root\\n |-- value: double (nullable = true)\\n\"\n",
      "            }\n",
      "          }\n",
      "          attr {\n",
      "            key: \"simple\"\n",
      "            value {\n",
      "              s: \"Scan ExistingRDD[value#221]\"\n",
      "            }\n",
      "          }\n",
      "          attr {\n",
      "            key: \"verbose\"\n",
      "            value {\n",
      "              s: \"Scan ExistingRDD[value#221]\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "04:14:32 DEBUG:channel: received result for /divide3: local_path {\n",
      "  path: \"divide3\"\n",
      "}\n",
      "status: FINISHED_SUCCESS\n",
      "final_result {\n",
      "  cell {\n",
      "    double_value: 1.5\n",
      "  }\n",
      "  cell_type {\n",
      "    basic_type: DOUBLE\n",
      "  }\n",
      "}\n",
      "spark_stats {\n",
      "  rdd_info {\n",
      "    rdd_id: 38\n",
      "    class_name: \"ParallelCollectionRDD\"\n",
      "    repr: \"ParallelCollectionRDD[38] at javaRDD at ExecutionItem.scala:56\"\n",
      "    proto {\n",
      "      name: \"divide3/ParallelCollectionRDD_38\"\n",
      "      op: \"ParallelCollectionRDD\"\n",
      "      input: \"^divide3_karps_localpack/MapPartitionsRDD_37\"\n",
      "      attr {\n",
      "        key: \"name\"\n",
      "        value {\n",
      "          s: \"ParallelCollectionRDD\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  rdd_info {\n",
      "    rdd_id: 39\n",
      "    class_name: \"MapPartitionsRDD\"\n",
      "    repr: \"MapPartitionsRDD[39] at javaRDD at ExecutionItem.scala:56\"\n",
      "    parents: 38\n",
      "    proto {\n",
      "      name: \"divide3/MapPartitionsRDD_39\"\n",
      "      op: \"MapPartitionsRDD\"\n",
      "      input: \"divide3/ParallelCollectionRDD_38\"\n",
      "      attr {\n",
      "        key: \"name\"\n",
      "        value {\n",
      "          s: \"MapPartitionsRDD\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  rdd_info {\n",
      "    rdd_id: 40\n",
      "    class_name: \"MapPartitionsRDD\"\n",
      "    repr: \"MapPartitionsRDD[40] at javaRDD at ExecutionItem.scala:56\"\n",
      "    parents: 39\n",
      "    proto {\n",
      "      name: \"divide3/MapPartitionsRDD_40\"\n",
      "      op: \"MapPartitionsRDD\"\n",
      "      input: \"divide3/MapPartitionsRDD_39\"\n",
      "      attr {\n",
      "        key: \"name\"\n",
      "        value {\n",
      "          s: \"MapPartitionsRDD\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  rdd_info {\n",
      "    rdd_id: 41\n",
      "    class_name: \"MapPartitionsRDD\"\n",
      "    repr: \"MapPartitionsRDD[41] at javaRDD at ExecutionItem.scala:56\"\n",
      "    parents: 40\n",
      "    proto {\n",
      "      name: \"divide3/MapPartitionsRDD_41\"\n",
      "      op: \"MapPartitionsRDD\"\n",
      "      input: \"divide3/MapPartitionsRDD_40\"\n",
      "      attr {\n",
      "        key: \"name\"\n",
      "        value {\n",
      "          s: \"MapPartitionsRDD\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  rdd_info {\n",
      "    rdd_id: 42\n",
      "    class_name: \"MapPartitionsRDD\"\n",
      "    repr: \"MapPartitionsRDD[42] at createDataFrame at ExecutionItem.scala:56\"\n",
      "    parents: 41\n",
      "    proto {\n",
      "      name: \"divide3/MapPartitionsRDD_42\"\n",
      "      op: \"MapPartitionsRDD\"\n",
      "      input: \"divide3/MapPartitionsRDD_41\"\n",
      "      attr {\n",
      "        key: \"name\"\n",
      "        value {\n",
      "          s: \"MapPartitionsRDD\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  rdd_info {\n",
      "    rdd_id: 43\n",
      "    class_name: \"MapPartitionsRDD\"\n",
      "    repr: \"MapPartitionsRDD[43] at execute at ExecutionItem.scala:89\"\n",
      "    parents: 42\n",
      "    proto {\n",
      "      name: \"divide3/MapPartitionsRDD_43\"\n",
      "      op: \"MapPartitionsRDD\"\n",
      "      input: \"divide3/MapPartitionsRDD_42\"\n",
      "      attr {\n",
      "        key: \"name\"\n",
      "        value {\n",
      "          s: \"MapPartitionsRDD\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parsed {\n",
      "    node_id: \"LogicalRDD_0\"\n",
      "    full_name: \"LogicalRDD [value#221]\"\n",
      "    proto {\n",
      "      name: \"divide3/LogicalRDD_0\"\n",
      "      op: \"LogicalRDD\"\n",
      "      input: \"^divide3_karps_localpack/LogicalRDD_0\"\n",
      "      attr {\n",
      "        key: \"schema\"\n",
      "        value {\n",
      "          s: \"root\\n |-- value: double (nullable = true)\\n\"\n",
      "        }\n",
      "      }\n",
      "      attr {\n",
      "        key: \"simple\"\n",
      "        value {\n",
      "          s: \"LogicalRDD [value#221]\"\n",
      "        }\n",
      "      }\n",
      "      attr {\n",
      "        key: \"verbose\"\n",
      "        value {\n",
      "          s: \"LogicalRDD [value#221]\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  physical {\n",
      "    node_id: \"Scan_ExistingRDD_0\"\n",
      "    full_name: \"Scan ExistingRDD[value#221]\"\n",
      "    proto {\n",
      "      name: \"divide3/Scan_ExistingRDD_0\"\n",
      "      op: \"Scan_ExistingRDD\"\n",
      "      input: \"^divide3_karps_localpack/Scan_ExistingRDD_0\"\n",
      "      attr {\n",
      "        key: \"schema\"\n",
      "        value {\n",
      "          s: \"root\\n |-- value: double (nullable = true)\\n\"\n",
      "        }\n",
      "      }\n",
      "      attr {\n",
      "        key: \"simple\"\n",
      "        value {\n",
      "          s: \"Scan ExistingRDD[value#221]\"\n",
      "        }\n",
      "      }\n",
      "      attr {\n",
      "        key: \"verbose\"\n",
      "        value {\n",
      "          s: \"Scan ExistingRDD[value#221]\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(double, double_value: 1.5\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comp.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def my_mean(df):\n",
    "    cached_df = f.autocache(df)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "function"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(my_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.core.framework import graph_pb2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_pb2.GraphDef()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object `_17.node.add` not found.\n"
     ]
    }
   ],
   "source": [
    "_17.node.add?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
